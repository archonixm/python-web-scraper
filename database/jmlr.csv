id,title,authors,journal_num,abs,pdf,bib,code,supplementary,website,blog,abstract,skills,data_skills
1,On the Optimality of Kernel-Embedding Based Goodness-of-Fit Tests,"Krishnakumar Balasubramanian, Tong Li, Ming Yuan","(1):1−45, 2021.",https://jmlr.org/papers/v22/17-570.html,https://jmlr.org/papers/volume22/17-570/17-570.pdf,https://jmlr.org/papers/v22/17-570.bib,,,,,"The reproducing kernel Hilbert space (RKHS) embedding of distributions offers a general and flexible framework for testing problems in arbitrary domains and has attracted considerable amount of attention in recent years. To gain insights into their operating characteristics, we study here the statistical performance of such approaches within a minimax framework. Focusing on the case of goodness-of-fit tests, our analyses show that a vanilla version of the kernel embedding based test could be minimax suboptimal, {when considering $\chi^2$ distance as the separation metric}. Hence we suggest a simple remedy by moderating the embedding. We prove that the moderated approach provides optimal tests for a wide range of deviations from the null and can also be made adaptive over a large collection of interpolation spaces. Numerical experiments are presented to further demonstrate the merits of our approach.",TestNG; Testing,
2,Domain Generalization by Marginal Transfer Learning,"Gilles Blanchard, Aniket Anand Deshmukh, Urun Dogan, Gyemin Lee, Clayton Scott","(2):1−55, 2021.",https://jmlr.org/papers/v22/17-679.html,https://jmlr.org/papers/volume22/17-679/17-679.pdf,https://jmlr.org/papers/v22/17-679.bib,https://github.com/aniketde/DomainGeneralizationMarginal,,,,"In the problem of domain generalization (DG), there are labeled training data sets from several related prediction problems, and the goal is to make accurate predictions on future unlabeled data sets that are not known to the learner. This problem arises in several applications where data distributions fluctuate because of environmental, technical, or other sources of variation. We introduce a formal framework for DG, and argue that it can be viewed as a kind of supervised learning problem by augmenting the original feature space with the marginal distribution of feature vectors. While our framework has several connections to conventional analysis of supervised learning algorithms, several unique aspects of DG require new methods of analysis. This work lays the learning theoretic foundations of domain generalization, building on our earlier conference paper where the problem of DG was introduced. We present two formal models of data generation, corresponding notions of risk, and distribution-free generalization error analysis. By focusing our attention on kernel methods, we also provide more quantitative results and a universally consistent algorithm. An efficient implementation is provided for this algorithm, which is experimentally compared to a pooling strategy on one synthetic and three real-world data sets.",Algorithm; Analysis; Supervised Learning; Training; Unsupervised Learning,
3,Regulating Greed Over Time in Multi-Armed Bandits,"Stefano Tracà, Cynthia Rudin, Weiyu Yan","(3):1−99, 2021.",https://jmlr.org/papers/v22/17-720.html,https://jmlr.org/papers/volume22/17-720/17-720.pdf,https://jmlr.org/papers/v22/17-720.bib,https://github.com/ShrekFelix/Regulating-Greed-Over-Time,,,,"In retail, there are predictable yet dramatic time-dependent patterns in customer behavior, such as periodic changes in the number of visitors, or increases in customers just before major holidays. The current paradigm of multi-armed bandit analysis does not take these known patterns into account. This means that for applications in retail, where prices are fixed for periods of time, current bandit algorithms will not suffice. This work provides a remedy that takes the time-dependent patterns into account, and we show how this remedy is implemented for the UCB, $\varepsilon$-greedy, and UCB-L algorithms, and also through a new policy called the variable arm pool algorithm. In the corrected methods, exploitation (greed) is regulated over time, so that more exploitation occurs during higher reward periods, and more exploration occurs in periods of low reward. In order to understand why regret is reduced with the corrected methods, we present a set of bounds that provide insight into why we would want to exploit during periods of high reward, and discuss the impact on regret. Our proposed methods perform well in experiments, and were inspired by a high-scoring entry in the Exploration and Exploitation 3 contest using data from Yahoo$!$ Front Page. That entry heavily used time-series methods to regulate greed over time, which was substantially more effective than other contextual bandit methods.",Algorithm; Analysis; Exploit; Retail; Sentry; Time Series; Variable,
4,An Empirical Study of Bayesian Optimization: Acquisition Versus Partition,"Erich Merrill, Alan Fern, Xiaoli Fern, Nima Dolatnia","(4):1−25, 2021.",https://jmlr.org/papers/v22/18-220.html,https://jmlr.org/papers/volume22/18-220/18-220.pdf,https://jmlr.org/papers/v22/18-220.bib,https://github.com/Eiii/opt_cmp,,,,"Bayesian optimization (BO) is a popular framework for black-box optimization. Two classes of BO approaches have shown promising empirical performance while providing strong theoretical guarantees. The first class optimizes an acquisition function to select points, which is typically computationally expensive and can only be done approximately. The second class of algorithms use systematic space partitioning, which is much cheaper computationally but the selection is typically less informed. This points to a potential trade-off between the computational complexity and empirical performance of these algorithms. The current literature, however, only provides a sparse sampling of empirical comparison points, giving little insight into this trade-off. The primary contribution of this work is to conduct a comprehensive, repeatable evaluation within a common software framework, which we provide as an open-source package. Our results give strong evidence about the relative performance of these methods and reveal a consistent top performer, even when accounting for overall computation time.",Accounting; Algorithm; Bayesian Optimization; Box; Complexity; LeSS; Literature; Sampling; Selection; Trade,
5,The Decoupled Extended Kalman Filter for Dynamic Exponential-Family Factorization Models,"Carlos A. Gomez-Uribe, Brian Karrer","(5):1−25, 2021.",https://jmlr.org/papers/v22/18-417.html,https://jmlr.org/papers/volume22/18-417/18-417.pdf,https://jmlr.org/papers/v22/18-417.bib,,,,,"Motivated by the needs of online large-scale recommender systems, we specialize the decoupled extended Kalman filter to factorization models, including factorization machines, matrix and tensor factorization, and illustrate the effectiveness of the approach through numerical experiments on synthetic and on real-world data.  Online learning of model parameters through the decoupled extended Kalman filter makes factorization models more broadly useful by (i) allowing for more flexible observations through the entire exponential family, (ii) modeling parameter drift, and (iii) producing parameter uncertainty estimates that can enable explore/exploit and other applications.  We use a different parameter dynamics than the standard decoupled extended Kalman filter, allowing parameter drift while encouraging reasonable values. We also present an alternate derivation of the extended Kalman filter and decoupled extended Kalman filter that highlights the role of the Fisher information matrix in the extended Kalman filter.",Exploit; Modelling; Uncertainty,
6,Consistent estimation of small masses in feature sampling,"Fadhel Ayed, Marco Battiston, Federico Camerlenghi, Stefano Favaro","(6):1−28, 2021.",https://jmlr.org/papers/v22/18-534.html,https://jmlr.org/papers/volume22/18-534/18-534.pdf,https://jmlr.org/papers/v22/18-534.bib,,,,,"Consider an (observable) random sample of size $n$ from an infinite population of individuals, each individual being endowed with a finite set of features from a collection of features $(F_{j})_{j\geq1}$ with unknown probabilities $(p_{j})_{j \geq 1}$, i.e., $p_{j}$ is the probability that an individual displays feature $F_{j}$. Under this feature sampling  framework, in recent years there has been a growing interest in estimating the sum of the probability masses $p_{j}$'s of features observed with frequency $r\geq0$ in the sample, here denoted by $M_{n,r}$. This is the natural feature sampling counterpart of the classical problem of estimating small probabilities in the species sampling framework, where each individual is endowed with only one feature (or “species""). In this paper we study the problem of consistent estimation of the small mass $M_{n,r}$. We first show that there do not exist universally consistent estimators, in the multiplicative sense, of the missing mass $M_{n,0}$. Then, we introduce an estimator of $M_{n,r}$ and identify sufficient conditions under which the estimator is consistent. In particular, we propose a nonparametric estimator $\hat{M}_{n,r}$  of $M_{n,r}$ which has the same analytic form of the celebrated Good--Turing estimator for small probabilities, with the sole difference that the two estimators have different ranges (supports).  Then, we show that $\hat{M}_{n,r}$ is strongly consistent, in the multiplicative sense, under the assumption that  $(p_{j})_{j\geq1}$ has regularly varying heavy tails.",Analytical; Population; Probability; Sampling,
7,Preference-based Online Learning with Dueling Bandits: A Survey,"Viktor Bengs, Róbert Busa-Fekete, Adil El Mesaoudi-Paul, Eyke Hüllermeier","(7):1−108, 2021.",https://jmlr.org/papers/v22/18-546.html,https://jmlr.org/papers/volume22/18-546/18-546.pdf,https://jmlr.org/papers/v22/18-546.bib,,,,,"In machine learning,  the notion of multi-armed bandits refers to a class of online learning problems, in which an agent is supposed to simultaneously explore and exploit a given set of choice alternatives in the course of a sequential decision process. In the standard setting, the agent learns from stochastic feedback in the form of real-valued rewards. In many applications, however, numerical reward signals are not readily available---instead, only weaker information is provided, in particular relative preferences in the form of qualitative comparisons between pairs of alternatives. This observation has motivated the study of variants of the multi-armed bandit problem, in which more general representations are used both for the type of feedback to learn from and the target of prediction.  The aim of this paper is to provide a survey of the state of the art in this field, referred to as preference-based multi-armed bandits or dueling bandits. To this end, we provide an overview of problems that have been considered in the literature as well as methods for tackling them. Our taxonomy is mainly based on the assumptions made by these methods about the data-generating process and, related to this, the properties of the preference-based feedback.",Decision Process; Exploit; Literature; Machine Learning; Sequential Decision,
8,A Unified Framework for Random Forest Prediction Error Estimation,"Benjamin Lu, Johanna Hardin","(8):1−41, 2021.",https://jmlr.org/papers/v22/18-558.html,https://jmlr.org/papers/volume22/18-558/18-558.pdf,https://jmlr.org/papers/v22/18-558.bib,,,,,"We introduce a unified framework for random forest prediction error estimation based on a novel estimator of the conditional prediction error distribution function. Our framework enables simple plug-in estimation of key prediction uncertainty metrics, including conditional mean squared prediction errors, conditional biases, and conditional quantiles, for random forests and many variants. Our approach is especially well-adapted for prediction interval estimation; we show via simulations that our proposed prediction intervals are competitive with, and in some settings outperform, existing methods. To establish theoretical grounding for our framework, we prove pointwise uniform consistency of a more stringent version of our estimator of the conditional prediction error distribution function. The estimators introduced here are implemented in the R package forestError.",Interval Estimation; R; Random Forest; Uncertainty,R programming
9,"Convex Clustering: Model, Theoretical Guarantee and Efficient Algorithm","Defeng Sun, Kim-Chuan Toh, Yancheng Yuan","(9):1−32, 2021.",https://jmlr.org/papers/v22/18-694.html,https://jmlr.org/papers/volume22/18-694/18-694.pdf,https://jmlr.org/papers/v22/18-694.bib,,,,,"Clustering is a fundamental problem in unsupervised learning. Popular methods like K-means, may suffer from poor performance as they are prone to get stuck in its local minima. Recently, the sum-of-norms (SON) model (also known as the convex clustering model) has been proposed by Pelckmans et al. (2005), Lindsten et al. (2011) and Hocking et al. (2011). The perfect recovery properties of the convex clustering model with uniformly weighted all-pairwise-differences regularization have been proved by Zhu et al. (2014)  and Panahi et al. (2017). However,  no theoretical guarantee has been established for the general weighted convex clustering model, where better empirical results have been observed. In the numerical optimization aspect, although algorithms like the alternating direction method of multipliers (ADMM) and the alternating minimization algorithm (AMA) have been proposed to solve the convex clustering model (Chi and Lange, 2015), it still remains  very challenging to solve large-scale problems. In this paper, we establish sufficient conditions for the perfect recovery guarantee of the general weighted convex clustering model, which include and improve existing theoretical results in  (Zhu et al., 2014; Panahi et al., 2017) as special cases. In addition, we develop a semismooth Newton based augmented Lagrangian method for solving large-scale convex clustering problems. Extensive numerical experiments on both simulated and real data demonstrate that our algorithm is  highly efficient and robust for solving large-scale problems. Moreover, the numerical results also show the superior performance and scalability of our algorithm comparing to the existing first-order methods. In particular, our algorithm is able to solve a convex clustering problem with 200,000 points in $\mathbb{R}^3$ in about 6 minutes.",Algorithm; Clustering; Supervised Learning; Unsupervised Learning,
10,Mixing Time of Metropolis-Hastings for Bayesian Community Detection,"Bumeng Zhuo, Chao Gao","(10):1−89, 2021.",https://jmlr.org/papers/v22/18-770.html,https://jmlr.org/papers/volume22/18-770/18-770.pdf,https://jmlr.org/papers/v22/18-770.bib,,,,,We study the computational complexity of a Metropolis-Hastings algorithm for Bayesian community detection. We first establish a posterior strong consistency result for a natural prior distribution on stochastic block models under the optimal signal-to-noise ratio condition in the literature. We then give a set of conditions that guarantee rapidly mixing of a simple Metropolis-Hastings algorithm. The mixing time analysis is based on a careful study of posterior ratios and a canonical path argument to control the spectral gap of the Markov chain.,Algorithm; Analysis; Bayesian; Complexity; Literature,
11,"Unfolding-Model-Based Visualization: Theory, Method and Applications","Yunxiao Chen, Zhiliang Ying, Haoran Zhang","(11):1−51, 2021.",https://jmlr.org/papers/v22/18-846.html,https://jmlr.org/papers/volume22/18-846/18-846.pdf,https://jmlr.org/papers/v22/18-846.bib,https://github.com/hrzhang16/mmdu.,,,,"Multidimensional unfolding methods are widely used for visualizing item response data. Such methods project respondents and items simultaneously onto a low-dimensional Euclidian space, in which respondents and items are represented by ideal points, with person-person, item-item, and person-item similarities being captured by the Euclidian distances between the points. In this paper, we study the visualization of multidimensional unfolding from a statistical perspective. We cast multidimensional unfolding into an estimation problem, where the respondent and item ideal points are treated as parameters to be estimated. An estimator is then proposed for the simultaneous estimation of these parameters. Asymptotic theory is provided for the recovery of the ideal points, shedding lights on the validity of model-based visualization. An alternating projected gradient descent algorithm is proposed for the parameter estimation. We provide two illustrative examples, one on users' movie rating and the other on senate roll call voting.",Algorithm; Gradient Descent; Visualization,Visualizations
12,Global and Quadratic Convergence of Newton Hard-Thresholding Pursuit,"Shenglong Zhou, Naihua Xiu, Hou-Duo Qi","(12):1−45, 2021.",https://jmlr.org/papers/v22/19-026.html,https://jmlr.org/papers/volume22/19-026/19-026.pdf,https://jmlr.org/papers/v22/19-026.bib,,,,,"Algorithms based on the hard thresholding principle have been well studied with sounding theoretical guarantees in the compressed sensing and more general sparsity-constrained optimization. It is widely observed in existing empirical studies that when a restricted Newton step was used (as the debiasing step),  the hard-thresholding algorithms tend to meet halting conditions in a significantly low number of iterations and are very efficient. Hence, the thus obtained Newton hard-thresholding algorithms call for stronger theoretical guarantees than for their simple hard-thresholding counterparts. This paper provides a theoretical justification for the use of the restricted Newton step. We build our theory and algorithm, Newton Hard-Thresholding Pursuit (NHTP), for the sparsity-constrained optimization. Our main result shows that NHTP is quadratically convergent under the standard assumption of restricted strong convexity and smoothness. We also establish its global convergence to a stationary point under a weaker assumption. In the special case of the compressive sensing, NHTP effectively reduces to some of the existing hard-thresholding algorithms with a Newton step.  Consequently, our fast convergence result justifies why those algorithms perform better than without the Newton step. The efficiency of NHTP was demonstrated on both synthetic and real data in compressed sensing and sparse logistic regression.",Algorithm; Convexity; Logistic Regression; Logistics; Regression,Regressions
13,Homogeneity Structure Learning in Large-scale Panel Data with Heavy-tailed Errors,"Di Xiao, Yuan Ke, Runze Li","(13):1−42, 2021.",https://jmlr.org/papers/v22/19-1018.html,https://jmlr.org/papers/volume22/19-1018/19-1018.pdf,https://jmlr.org/papers/v22/19-1018.bib,,,,,"Large-scale panel data is ubiquitous in many modern data science applications. Conventional panel data analysis methods fail to address the new challenges, like individual impacts of covariates, endogeneity, embedded low-dimensional structure, and heavy-tailed errors, arising from the innovation of data collection platforms on which applications operate. In response to these challenges, this paper studies large-scale panel data with an interactive effects model. This model takes into account the individual impacts of covariates on each spatial node and removes the exogenous condition by allowing latent factors to affect both covariates and errors. Besides, we waive the sub-Gaussian assumption and allow the errors to be heavy-tailed. Further, we propose a data-driven procedure to learn a parsimonious yet flexible homogeneity structure embedded in high-dimensional individual impacts of covariates. The homogeneity structure assumes that there exists a partition of regression coefficients where the coefficients are the same within each group but different between the groups. The homogeneity structure is flexible as it contains many widely assumed low-dimensional structures (sparsity, global impact, etc.) as its special cases. Non-asymptotic properties are established to justify the proposed learning procedure. Extensive numerical experiments demonstrate the advantage of the proposed learning procedure over conventional methods especially when the data are generated from heavy-tailed distributions.",Data Analysis; Data Science; Innovation; Node.js; Platform; Regression,Regressions
14,On Multi-Armed Bandit Designs for Dose-Finding Trials,"Maryam Aziz, Emilie Kaufmann, Marie-Karelle Riviere","(14):1−38, 2021.",https://jmlr.org/papers/v22/19-228.html,https://jmlr.org/papers/volume22/19-228/19-228.pdf,https://jmlr.org/papers/v22/19-228.bib,,,,,"We study the problem of finding the optimal dosage in early stage clinical trials through the multi-armed bandit lens. We advocate the use of the Thompson Sampling principle, a flexible algorithm that can accommodate different types of monotonicity assumptions on the toxicity and efficacy of the doses. For the simplest version of Thompson Sampling, based on a uniform prior distribution for each dose, we provide finite-time upper bounds on the number of sub-optimal dose selections, which is unprecedented for dose-finding algorithms. Through a large simulation study, we then show that variants of Thompson Sampling based on more sophisticated prior distributions outperform state-of-the-art dose identification algorithms in different types of dose-finding studies that occur in phase I or phase I/II trials.",Algorithm; Design; Selection; Thompson Sampling,
15,Simple and Fast Algorithms for Interactive Machine Learning with Random Counter-examples,Jagdeep Singh Bhatia,"(15):1−30, 2021.",https://jmlr.org/papers/v22/19-372.html,https://jmlr.org/papers/volume22/19-372/19-372.pdf,https://jmlr.org/papers/v22/19-372.bib,,,,,"This work describes simple and efficient algorithms for interactively learning non-binary concepts in the learning from random counter-examples (LRC) model. Here, learning takes place from random counter-examples that the learner receives in response to their proper equivalence queries, and the learning time is the number of counter-examples needed by the learner to identify the target concept. Such learning is particularly suited for online ranking, classification, clustering, etc., where machine learning models must be used before they are fully trained. We provide two simple LRC algorithms, deterministic and randomized, for exactly learning concepts from any concept class $H$. We show that both these algorithms have an $\mathcal{O}(\log{}|H|)$ asymptotically optimal average learning time. This solves an open problem on the existence of an efficient LRC randomized algorithm while also simplifying previous results and improving their computational efficiency. We also show that the expected learning time of any Arbitrary LRC algorithm can be upper bounded by $\mathcal{O}(\frac{1}{\epsilon}\log{\frac{|H|}{\delta}})$, where $\epsilon$ and $\delta$ are the allowed learning error and failure probability respectively. This shows that LRC interactive learning is at least as efficient as non-interactive Probably Approximately Correct (PAC) learning. Our simulations also show that these algorithms outperform their theoretical bounds.",Algorithm; Classification; Clustering; Machine Learning; Probability; Probably Approximately Correct (PAC) Learning,
16,Pykg2vec: A Python Library for Knowledge Graph Embedding,"Shih-Yuan Yu, Sujit Rokka Chhetri, Arquimedes Canedo, Palash Goyal, Mohammad Abdullah Al Faruque","(16):1−6, 2021.  (Machine Learning Open Source Software Paper)",https://jmlr.org/papers/v22/19-433.html,https://jmlr.org/papers/volume22/19-433/19-433.pdf,https://jmlr.org/papers/v22/19-433.bib,https://github.com/Sujit-O/pykg2vec,,,,"Pykg2vec is a Python library for learning the representations of the entities and relations in knowledge graphs. Pykg2vec's flexible and modular software architecture currently implements 25 state-of-the-art knowledge graph embedding algorithms, and is designed to easily incorporate new algorithms.The goal of pykg2vec is to provide a practical and educational platform to accelerate research in knowledge graph representation learning. Pykg2vec is built on top of PyTorch and Python's multiprocessing framework and provides modules for batch generation, Bayesian hyperparameter optimization, evaluation of KGE tasks, embedding, and result visualization. Pykg2vec is released under the MIT License and is also available in the Python Package Index (PyPI). The source code of pykg2vec is available at https://github.com/Sujit-O/pykg2vec.",Algorithm; Bayesian; Github; Graph; Hyperparameter Optimization; Multiprocessing; Platform; Presentation; PyPI; PyTorch; Python; Research; Software Architecture; Visualization,Github; Presentation Skill; Python Programming; Visualizations
17,Continuous Time Analysis of Momentum Methods,"Nikola B. Kovachki, Andrew M. Stuart","(17):1−40, 2021.",https://jmlr.org/papers/v22/19-466.html,https://jmlr.org/papers/volume22/19-466/19-466.pdf,https://jmlr.org/papers/v22/19-466.bib,,https://jmlr.org/papers/volume22/19-466/supplementary.pdf,,,"Gradient descent-based optimization methods underpin the parameter training of neural networks, and hence comprise a significant component in the impressive test results found in a number of applications. Introducing stochasticity is key to their success in practical problems, and there is some understanding of the role of stochastic gradient descent in this context. Momentum modifications of gradient descent such as Polyak's Heavy Ball method (HB) and Nesterov's method of accelerated gradients (NAG), are also widely adopted. In this work our focus is on understanding the role of momentum in the training of neural networks, concentrating on the common situation in which the momentum contribution is fixed at each step of the algorithm. To expose the ideas simply we work in the deterministic setting. Our approach is to derive continuous time approximations of the discrete algorithms; these continuous time approximations provide insights into the mechanisms at play within the discrete algorithms. We prove three such approximations. Firstly we show that standard implementations of fixed momentum methods approximate a time-rescaled gradient descent flow, asymptotically as the learning rate shrinks to zero; this result does not distinguish momentum methods from pure gradient descent, in the limit of vanishing learning rate. We then proceed to prove two results aimed at understanding the observed practical advantages of fixed momentum methods over gradient descent, when implemented in the non-asymptotic regime with fixed small, but non-zero, learning rate.  We achieve this by proving approximations to continuous time limits in which the small but fixed learning rate appears as a parameter; this is known as the method of modified equations in the numerical analysis literature, recently rediscovered as the high resolution ODE approximation in the machine learning context. In our second result we show that the momentum method is approximated by a continuous time gradient flow,  with an additional momentum-dependent second order time-derivative correction, proportional to the learning rate; this may be used to explain the stabilizing effect of momentum algorithms in their transient phase. Furthermore in a third result we show that the momentum methods admit an exponentially attractive invariant manifold  on which the dynamics reduces, approximately, to a gradient flow with respect to a modified loss function, equal to the original loss function plus a small perturbation proportional to the learning rate; this small correction provides convexification of the loss function and encodes additional robustness present in momentum methods, beyond the transient phase.",Algorithm; Approximation; Derivative; Gradient Descent; Literature; Machine Learning; Neural Network; Numerical Analysis; Play; Training,
18,A Unified Sample Selection Framework for Output Noise Filtering: An Error-Bound Perspective,"Gaoxia Jiang, Wenjian Wang, Yuhua Qian, Jiye Liang","(18):1−66, 2021.",https://jmlr.org/papers/v22/19-498.html,https://jmlr.org/papers/volume22/19-498/19-498.pdf,https://jmlr.org/papers/v22/19-498.bib,,,,,"The existence of output noise will bring difficulties to supervised learning. Noise filtering, aiming to detect and remove polluted samples, is one of the main ways to deal with the noise on outputs. However, most of the filters are heuristic and could not explain the filtering influence on the generalization error (GE) bound. The hyper-parameters in various filters are specified manually or empirically, and they are usually unable to adapt to the data environment. The filter with an improper hyper-parameter may overclean, leading to a weak generalization ability. This paper proposes a unified framework of optimal sample selection (OSS) for the output noise filtering from the perspective of error bound. The covering distance filter (CDF) under the framework is presented to deal with noisy outputs in regression and ordinal classification problems. Firstly, two necessary and sufficient conditions for a fixed goodness of fit in regression are deduced from the perspective of GE bound. They provide the unified theoretical framework for determining the filtering effectiveness and optimizing the size of removed samples. The optimal sample size has the adaptability to the environmental changes in the sample size, the noise ratio, and noise variance. It offers a choice of tuning the hyper-parameter and could prevent filters from overcleansing. Meanwhile, the OSS framework can be integrated with any noise estimator and produces a new filter. Then the covering interval is proposed to separate low-noise and high-noise samples, and the effectiveness is proved in regression. The covering distance is introduced as an unbiased estimator of high noises. Further, the CDF algorithm is designed by integrating the cover distance with the OSS framework. Finally, it is verified that the CDF not only recognizes noise labels correctly but also brings down the prediction errors on real apparent age data set. Experimental results on benchmark regression and ordinal classification data sets demonstrate that the CDF outperforms the state-of-the-art filters in terms of prediction ability, noise recognition, and efficiency.",Adaptability; Algorithm; CSS Framework; Classification; Regression; Selection; Supervised Learning; Unsupervised Learning,Regressions
19,Ranking and synchronization from pairwise measurements via SVD,"Alexandre d'Aspremont, Mihai Cucuringu, Hemant Tyagi","(19):1−63, 2021.",https://jmlr.org/papers/v22/19-542.html,https://jmlr.org/papers/volume22/19-542/19-542.pdf,https://jmlr.org/papers/v22/19-542.bib,,,,,"Given a measurement graph $G= (V,E)$ and an unknown signal $r \in \mathbb{R}^n$, we investigate algorithms for recovering $r$ from pairwise measurements of the form $r_i - r_j$; $\{i,j\} \in E$. This problem arises in a variety of applications, such as ranking teams in sports data and time synchronization of distributed networks. Framed in the context of ranking, the task is to  recover the ranking of $n$ teams (induced by $r$) given a small subset of noisy pairwise rank offsets. We propose a simple SVD-based algorithmic pipeline for both the problem of time synchronization and ranking. We provide a detailed theoretical analysis in terms of robustness against both sampling sparsity and noise perturbations with outliers, using results from matrix perturbation and random matrix theory. Our theoretical findings are complemented by a detailed set of numerical experiments on both synthetic and real data, showcasing the competitiveness of our proposed algorithms with other  state-of-the-art methods.",Algorithm; Analysis; Graph; Network; Outliers; Sampling; Sports,
20,Aggregated Hold-Out,"Guillaume Maillard, Sylvain Arlot, Matthieu Lerasle","(20):1−55, 2021.",https://jmlr.org/papers/v22/19-624.html,https://jmlr.org/papers/volume22/19-624/19-624.pdf,https://jmlr.org/papers/v22/19-624.bib,,,,,"Aggregated hold-out (agghoo) is a method which averages learning rules selected by hold-out (that is, cross-validation with a single split). We provide the first theoretical guarantees on agghoo, ensuring that it can be used safely: Agghoo performs at worst like the hold-out when the risk is convex. The same holds true in classification with the 0--1 risk, with an additional constant factor. For the hold-out, oracle inequalities are known for bounded losses, as in binary classification. We show that similar results can be proved, under appropriate assumptions, for other risk-minimization problems. In particular, we obtain an oracle inequality for regularized kernel regression with a Lipschitz loss, without requiring that the $Y$ variable or the regressors be bounded. Numerical experiments show that aggregation brings a significant improvement over the hold-out and that agghoo is competitive with cross-validation.",Classification; Cross Validation; Oracle; Regression; Variable,Regressions
21,A Fast Globally Linearly Convergent Algorithm for the Computation of Wasserstein Barycenters,"Lei Yang, Jia Li, Defeng Sun, Kim-Chuan Toh","(21):1−37, 2021.",https://jmlr.org/papers/v22/19-629.html,https://jmlr.org/papers/volume22/19-629/19-629.pdf,https://jmlr.org/papers/v22/19-629.bib,,,,,"We consider the problem of computing a Wasserstein barycenter for a set of discrete probability distributions with finite supports, which finds many applications in areas such as statistics, machine learning and image processing. When the support points of the barycenter are pre-specified, this problem can be modeled as a linear programming (LP) problem whose size can be extremely large. To handle this large-scale LP, we analyse the structure of its dual problem, which is conceivably more tractable and can be reformulated as a well-structured convex problem with 3 kinds of block variables and a coupling linear equality constraint. We then adapt a symmetric Gauss-Seidel based alternating direction method of multipliers (sGS-ADMM) to solve the resulting dual problem and establish its global convergence and global linear convergence rate. As a critical component for efficient computation, we also show how all the subproblems involved can be solved exactly and efficiently. This makes our method suitable for computing a Wasserstein barycenter on a large-scale data set, without introducing an entropy regularization term as is commonly practiced. In addition, our sGS-ADMM can be used as a subroutine in an alternating minimization method to compute a barycenter when its support points are not pre-specified. Numerical results on synthetic data sets and image data sets demonstrate that our method is highly competitive for solving large-scale Wasserstein barycenter problems, in comparison to two existing representative methods and the commercial software Gurobi.",Algorithm; Gurobi; Image Processing; Linear Programming; Machine Learning; Probability Distribution; R; Soft Computing; Statistics; Variable,R programming; Statistics
22,When random initializations help: a study of variational inference for community detection,"Purnamrita Sarkar, Y. X. Rachel Wang, Soumendu S. Mukherjee","(22):1−46, 2021.",https://jmlr.org/papers/v22/19-630.html,https://jmlr.org/papers/volume22/19-630/19-630.pdf,https://jmlr.org/papers/v22/19-630.bib,,,,,"Variational approximation has been widely used in large-scale Bayesian inference recently, the simplest kind of which involves imposing a mean field assumption to approximate complicated latent structures. Despite the computational scalability of mean field, theoretical studies of its loss function surface and the convergence behavior of iterative updates for optimizing the loss are far from complete. In this paper, we focus on the problem of community detection for a simple two-class Stochastic Blockmodel (SBM) with equal class sizes. Using batch co-ordinate ascent (BCAVI) for updates, we show different convergence behavior with respect to different initializations. When the parameters are known or estimated within a reasonable range and held fixed, we characterize conditions under which an initialization can converge to the ground truth. On the other hand, when the parameters need to be estimated iteratively, a random initialization will converge to an uninformative local optimum.",Approximation; Bayesian Inference,
23,A Two-Level Decomposition Framework Exploiting First and Second Order Information for SVM Training Problems,"Giulio Galvan, Matteo Lapucci, Chih-Jen Lin, Marco Sciandrone","(23):1−38, 2021.",https://jmlr.org/papers/v22/19-632.html,https://jmlr.org/papers/volume22/19-632/19-632.pdf,https://jmlr.org/papers/v22/19-632.bib,,,,,"In this work we present a novel way to solve the sub-problems that originate when using decomposition algorithms to train Support Vector Machines (SVMs). State-of-the-art Sequential Minimization Optimization (SMO) solvers reduce the original problem to a sequence of sub-problems of two variables for which the solution is analytical. Although considering more than two variables at a time usually results in a lower number of iterations needed to train an SVM model, solving the sub-problem becomes much harder and the overall computational gains are limited, if any. We propose to apply the two-variables decomposition method to solve the sub-problems themselves and experimentally show that it is a viable and efficient way to deal with sub-problems of up to 50 variables. As a second contribution we explore different ways to select the working set and its size, combining first-order and second-order working set selection rules together with a strategy for exploiting cached elements of the Hessian matrix. An extensive numerical comparison shows that the method performs considerably better than state-of-the-art software.",Algorithm; Analytical; Selection; Sequence; Support Vector Machine (SVM); Training; Variable,
24,Entangled Kernels - Beyond Separability,"Riikka Huusari, Hachem Kadri","(24):1−40, 2021.",https://jmlr.org/papers/v22/19-665.html,https://jmlr.org/papers/volume22/19-665/19-665.pdf,https://jmlr.org/papers/v22/19-665.bib,https://github.com/RiikkaHuu/EKL,,,,"We consider the problem of operator-valued kernel learning and investigate the possibility of going beyond the well-known separable kernels. Borrowing tools and concepts from the field of quantum computing, such as partial trace and entanglement, we propose a new view on operator-valued kernels and define a general family of kernels that encompasses previously known operator-valued kernels, including separable and transformable kernels. Within this framework, we introduce another novel class of operator-valued kernels called entangled kernels that are not separable. We propose an efficient two-step algorithm for this framework, where the entangled kernel is learned based on a novel extension of kernel alignment to operator-valued kernels. We illustrate our algorithm with an application to supervised dimensionality reduction, and demonstrate its effectiveness with both artificial and real data for multi-output regression.",Algorithm; Computing; Dimensionality Reduction; Regression,Regressions
25,Generalization Performance of Multi-pass Stochastic Gradient Descent with Convex Loss Functions,"Yunwen Lei, Ting Hu, Ke Tang","(25):1−41, 2021.",https://jmlr.org/papers/v22/19-716.html,https://jmlr.org/papers/volume22/19-716/19-716.pdf,https://jmlr.org/papers/v22/19-716.bib,,,,,"Stochastic gradient descent (SGD) has become the method of choice to tackle large-scale datasets due to its low computational cost and good practical performance. Learning rate analysis, either capacity-independent or capacity-dependent, provides a unifying viewpoint to study the computational and statistical properties of SGD, as well as the implicit regularization by tuning the number of passes. Existing capacity-independent learning rates require a nontrivial bounded subgradient assumption and a smoothness assumption to be optimal. Furthermore, existing capacity-dependent learning rates are only established for the specific least squares loss with a special structure. In this paper, we provide both optimal capacity-independent and capacity-dependent learning rates for SGD with general convex loss functions. Our results require neither bounded subgradient assumptions nor smoothness assumptions, and are stated with high probability. We achieve this improvement by a refined estimate on the norm of SGD iterates based on a careful martingale analysis and concentration inequalities on empirical processes.",Analysis; Dataset; Gradient Descent; Probability,
26,Finite Time LTI System Identification,"Tuhin Sarkar, Alexander Rakhlin, Munther A. Dahleh","(26):1−61, 2021.",https://jmlr.org/papers/v22/19-725.html,https://jmlr.org/papers/volume22/19-725/19-725.pdf,https://jmlr.org/papers/v22/19-725.bib,,,,,"We address the problem of learning the parameters of a stable linear time invariant (LTI) system with unknown latent space dimension, or order, from a single time--series of noisy input-output data. We focus on learning the best lower order approximation allowed by finite data. Motivated by subspace algorithms in systems theory, where the doubly infinite system Hankel matrix captures both order and good lower order approximations, we construct a Hankel-like matrix from noisy finite data using ordinary least squares. This circumvents the non-convexities that arise in system identification, and allows accurate estimation of the underlying LTI system. Our results rely on careful analysis of self-normalized martingale difference terms that helps bound identification error up to logarithmic factors of the lower bound. We provide a data-dependent scheme for order selection and find an accurate realization of system parameters, corresponding to that order, by an approach that is closely related to the Ho-Kalman subspace algorithm. We demonstrate that the proposed model order selection procedure is not overly conservative, i.e., for the given data length it is not possible to estimate higher order models or find higher order approximations with reasonable accuracy.",Accuracy; Algorithm; Analysis; Approximation; Ordinary Least Squares; Scheme; Selection; Systems Theory; Table; Time Series,
27,Inference In High-dimensional Single-Index Models Under Symmetric Designs,"Hamid Eftekhari, Moulinath Banerjee, Ya'acov Ritov","(27):1−63, 2021.",https://jmlr.org/papers/v22/19-744.html,https://jmlr.org/papers/volume22/19-744/19-744.pdf,https://jmlr.org/papers/v22/19-744.bib,https://github.com/ehamid/sim_debiasing,,,,"The problem of statistical inference for regression coefficients in a high-dimensional single-index model is considered. Under elliptical symmetry, the single index model can be reformulated as a proxy linear model whose regression parameter is identifiable. We construct estimates of the regression coefficients of interest that are similar to the debiased lasso estimates in the standard linear model and exhibit similar properties: $\sqrt{n}$-consistency and asymptotic normality. The procedure completely bypasses the estimation of the unknown link function, which can be extremely challenging depending on the underlying structure of the problem. Furthermore, under Gaussianity, we propose more efficient estimates of the coefficients by expanding the link function in the Hermite polynomial basis. Finally, we illustrate our approach via carefully designed simulation experiments.",Design; Inference; Lasso; Regression,Regressions
28,Tsallis-INF: An Optimal Algorithm for Stochastic and Adversarial Bandits,"Julian Zimmert, Yevgeny Seldin","(28):1−49, 2021.",https://jmlr.org/papers/v22/19-753.html,https://jmlr.org/papers/volume22/19-753/19-753.pdf,https://jmlr.org/papers/v22/19-753.bib,,,,,"We derive an algorithm that achieves the optimal (within constants) pseudo-regret in both adversarial and stochastic multi-armed bandits without prior knowledge of the regime and time horizon. The algorithm is based on online mirror descent (OMD) with Tsallis entropy regularization with power $\alpha=1/2$ and reduced-variance loss estimators. More generally, we define an adversarial regime with a self-bounding constraint, which includes stochastic regime, stochastically constrained adversarial regime, and stochastic regime with adversarial corruptions as special cases, and show that the algorithm achieves logarithmic regret guarantee in this regime and all of its special cases simultaneously with the optimal regret guarantee in the adversarial regime. The algorithm also achieves adversarial and stochastic optimality in the utility-based dueling bandit setting. We provide empirical evaluation of the algorithm demonstrating that it significantly outperforms UCB1 and EXP3 in stochastic environments. We also provide examples of adversarial environments, where UCB1 and Thompson Sampling exhibit almost linear regret, whereas our algorithm suffers only logarithmic regret. To the best of our knowledge, this is the first example demonstrating vulnerability of Thompson Sampling in adversarial environments. Last but not least, we present a general stochastic analysis and a general adversarial analysis of OMD algorithms with Tsallis entropy regularization for $\alpha\in[0,1]$ and explain the reason why $\alpha=1/2$ works best.",Algorithm; Analysis; Thompson Sampling; Utility; Vulnerability,
29,Single and Multiple Change-Point Detection with Differential Privacy,"Wanrong Zhang, Sara Krehbiel, Rui Tuo, Yajun Mei, Rachel Cummings","(29):1−36, 2021.",https://jmlr.org/papers/v22/19-770.html,https://jmlr.org/papers/volume22/19-770/19-770.pdf,https://jmlr.org/papers/v22/19-770.bib,,,,,"The change-point detection problem seeks to identify distributional changes at an unknown change-point $k^*$ in a stream of data. This problem appears in many important practical settings involving personal data, including biosurveillance,  fault detection, finance, signal detection, and security systems. The field of differential privacy offers data analysis tools that provide powerful worst-case privacy guarantees. We study the statistical problem of change-point detection through the lens of differential privacy. We give private algorithms for both online and offline change-point detection, analyze these algorithms theoretically, and provide empirical validation of our results.",Algorithm; Data Analysis; Finance; Privacy; Security,
30,"A Review of Robot Learning for Manipulation: Challenges, Representations, and Algorithms","Oliver Kroemer, Scott Niekum, George Konidaris","(30):1−82, 2021.",https://jmlr.org/papers/v22/19-804.html,https://jmlr.org/papers/volume22/19-804/19-804.pdf,https://jmlr.org/papers/v22/19-804.bib,,,,,"A key challenge in intelligent robotics is creating robots that are capable of directly interacting with the world around them to achieve their goals. The last decade has seen substantial growth in research on the problem of robot manipulation, which aims to exploit the increasing availability of affordable robot arms and grippers to create robots capable of directly interacting with the world to achieve their goals. Learning will be central to such autonomous systems, as the real world contains too much variation for a robot to expect to have an accurate model of its environment,  the objects in it, or the skills required to manipulate them, in advance. We aim to survey a representative subset of that research which uses machine learning for manipulation. We describe a formalization of the robot manipulation learning problem that synthesizes existing research into a single coherent framework and highlight the many remaining research opportunities and challenges.",Algorithm; Exploit; Machine Learning; Research; Robot; Robotics,
31,FLAME: A Fast Large-scale Almost Matching Exactly Approach to Causal Inference,"Tianyu Wang, Marco Morucci, M. Usaid Awan, Yameng Liu, Sudeepa Roy, Cynthia Rudin, Alexander Volfovsky","(31):1−41, 2021.",https://jmlr.org/papers/v22/19-853.html,https://jmlr.org/papers/volume22/19-853/19-853.pdf,https://jmlr.org/papers/v22/19-853.bib,,,https://almost-matching-exactly.github.io/,,"A classical problem in causal inference is that of matching, where treatment units need to be matched to control units based on covariate information. In this work, we propose a method that computes high quality almost-exact matches for high-dimensional categorical datasets. This method, called FLAME (Fast Large-scale Almost Matching Exactly), learns a distance metric for matching using a hold-out  training data set. In order to perform matching efficiently for large datasets, FLAME leverages techniques that are natural for query processing in the area of database management, and two implementations of FLAME are provided: the first uses SQL queries and the second uses bit-vector techniques. The algorithm starts by constructing matches of the highest quality (exact matches on all covariates), and successively eliminates variables in order to match exactly on as many variables as possible, while still maintaining interpretable high-quality matches and balance between treatment and control groups. We leverage these  high quality matches to estimate conditional average treatment effects (CATEs).   Our experiments show that FLAME scales to huge datasets with millions of observations where existing state-of-the-art methods fail, and that it achieves significantly better performance than other matching methods.",Algorithm; Construction; Database; Dataset; Inference; Management; Processing; Sales; Structured Query Language (SQL); Training; Variable; jQuery,SQL
32,Learning interaction kernels in heterogeneous systems of agents from multiple trajectories,"Fei Lu, Mauro Maggioni, Sui Tang","(32):1−67, 2021.",https://jmlr.org/papers/v22/19-861.html,https://jmlr.org/papers/volume22/19-861/19-861.pdf,https://jmlr.org/papers/v22/19-861.bib,https://github.com/MingZhongCodes/LearningDynamics.git,,,,"Systems of interacting particles, or agents, have wide applications in many disciplines, including Physics, Chemistry, Biology and Economics.  These systems are governed by interaction laws, which are often unknown: estimating them from observation data is a fundamental task that can provide meaningful insights and accurate predictions of the behaviour of the agents. In this paper, we consider the inverse problem of learning interaction laws given data  from multiple trajectories, in a nonparametric fashion, when the interaction kernels depend on pairwise distances. We establish a condition for learnability of interaction kernels, and construct an estimator based on the minimization of a suitably regularized least squares functional, that is guaranteed to converge, in a suitable $L^2$ space, at the optimal min-max rate for 1-dimensional nonparametric regression.  We propose an efficient learning algorithm to construct such estimator,  which can be implemented in parallel for multiple trajectories and is therefore well-suited for the high dimensional, big data regime.  Numerical simulations on a variety examples, including opinion dynamics, predator-prey and swarm dynamics and heterogeneous particle dynamics, suggest that the learnability condition is satisfied in models used in practice, and the rate of convergence of our estimator is consistent with the theory. These simulations also suggest that our estimators are robust to noise in the observations, and can produce accurate predictions of trajectories in large time intervals, even when they are learned from observations in short time intervals.",Algorithm; Big Data; Biology; Chemistry; Economics; Physics; Regression,Regressions
33,Asynchronous Online Testing of Multiple Hypotheses,"Tijana Zrnic, Aaditya Ramdas, Michael I. Jordan","(33):1−39, 2021.",https://jmlr.org/papers/v22/19-910.html,https://jmlr.org/papers/volume22/19-910/19-910.pdf,https://jmlr.org/papers/v22/19-910.bib,,,,,"We consider the problem of asynchronous online testing, aimed at providing control of the false discovery rate (FDR) during a continual stream of data collection and testing, where each test may be a sequential test that can start and stop at arbitrary times. This setting increasingly characterizes real-world applications in science and industry, where teams of researchers across large organizations may conduct tests of hypotheses in a decentralized manner. The overlap in time and space also tends to induce dependencies among test statistics, a challenge for classical methodology, which either assumes (overly optimistically) independence or (overly pessimistically) arbitrary dependence between test statistics. We present a general framework that addresses both of these issues via a unified computational abstraction that we refer to as “conflict sets.” We show how this framework yields algorithms with formal FDR guarantees under a more intermediate, local notion of dependence. We illustrate our algorithms in simulations by comparing to existing algorithms for online FDR control.",Algorithm; Methodology; Statistics; TestNG; Testing,Statistics
34,Neighborhood Structure Assisted Non-negative Matrix Factorization and Its Application in Unsupervised Point-wise Anomaly Detection,"Imtiaz Ahmed, Xia Ben Hu, Mithun P. Acharya, Yu Ding","(34):1−32, 2021.",https://jmlr.org/papers/v22/19-924.html,https://jmlr.org/papers/volume22/19-924/19-924.pdf,https://jmlr.org/papers/v22/19-924.bib,https://urldefense.com/v3/__https://tamucs-my.sharepoint.com/:u:/g/personal/yu-ding_tamu_edu/EdeIKFF07H1KlB0vIeGxtrABbs9DcQnL8Bf8_cNjNQeR3g?e=exOuZm__;!!KwNVnqRv!VnN480fumwOmmgvIA_xcK58wt1ax4nXdi2iYfu_pqjzo3-xnLb955YhS_HGh5pFUyQ$,,,,"Dimensionality reduction is considered as an important step for ensuring competitive performance in unsupervised learning such as anomaly detection. Non-negative matrix factorization (NMF) is a widely used method to accomplish this goal. But NMF do not have the provision to include the neighborhood structure information and, as a result, may fail to provide satisfactory performance in presence of nonlinear manifold structure. To address this shortcoming, we propose to consider the neighborhood structural similarity information within the NMF framework and do so by modeling the data through a minimum spanning tree. We label the resulting method as the neighborhood structure-assisted NMF. We further develop both offline and online algorithms for implementing the proposed method. Empirical comparisons using twenty benchmark data sets as well as an industrial data set extracted from a hydropower plant demonstrate the superiority of the neighborhood structure-assisted NMF. Looking closer into the formulation and properties of the proposed NMF method and comparing it with several NMF variants reveal that inclusion of the MST-based neighborhood structure plays a key role in attaining the enhanced performance in anomaly detection.",Algorithm; Anomaly Detection; Dimensionality Reduction; Modelling; Non-negative Matrix Factorization (NMF); Supervised Learning; Tree; Unsupervised Learning,
35,Learning and Planning for Time-Varying MDPs Using Maximum Likelihood Estimation,"Melkior Ornik, Ufuk Topcu","(35):1−40, 2021.",https://jmlr.org/papers/v22/20-006.html,https://jmlr.org/papers/volume22/20-006/20-006.pdf,https://jmlr.org/papers/v22/20-006.bib,,,,,"This paper proposes a formal approach to online learning and planning for agents operating in a priori unknown, time-varying environments. The proposed method computes the maximally likely model of the environment, given the observations about the environment made by an agent earlier in the system run and assuming knowledge of a bound on the maximal rate of change of system dynamics. Such an approach generalizes the estimation method commonly used in learning algorithms for unknown Markov decision processes with time-invariant transition probabilities, but is also able to quickly and correctly identify the system dynamics following a change. Based on the proposed method, we generalize the exploration bonuses used in learning for time-invariant Markov decision processes by introducing a notion of uncertainty in a learned time-varying model, and develop a control policy for time-varying Markov decision processes based on the exploitation and exploration trade-off. We demonstrate the proposed methods on four numerical examples: a patrolling task with a change in system dynamics, a two-state MDP with periodically changing outcomes of actions, a wind flow estimation task, and a multi-armed bandit problem with periodically changing probabilities of different rewards.",Algorithm; Decision Process; Trade; Uncertainty,
36,Multi-class Gaussian Process Classification with Noisy Inputs,"Carlos Villacampa-Calvo, Bryan Zaldívar, Eduardo C. Garrido-Merchán, Daniel Hernández-Lobato","(36):1−52, 2021.",https://jmlr.org/papers/v22/20-107.html,https://jmlr.org/papers/volume22/20-107/20-107.pdf,https://jmlr.org/papers/v22/20-107.bib,https://github.com/cvillacampa/GPInputNoise,,,,"It is a common practice in the machine learning community to assume that the observed data are noise-free in the input attributes. Nevertheless, scenarios with input noise are common in real problems, as measurements are never perfectly accurate. If this input noise is not taken into account, a supervised machine learning method is expected to perform sub-optimally. In this paper, we focus on multi-class classification problems and use Gaussian processes (GPs) as the underlying classifier. Motivated by a data set coming from the astrophysics domain, we hypothesize that the observed data may contain noise in the inputs. Therefore, we devise several multi-class GP classifiers that can account for input noise. Such classifiers can be efficiently trained using variational inference to approximate the posterior distribution of the latent variables of the model. Moreover, in some situations, the amount of noise can be known before-hand. If this is the case, it can be readily introduced in the proposed methods. This prior information is expected to lead to better performance results. We have evaluated the proposed methods by carrying out several experiments, involving synthetic and real data. These include several data sets from the UCI repository, the MNIST data set and a data set coming from astrophysics. The results obtained show that, although the classification error is similar across methods, the predictive distribution of the proposed methods is better, in terms of the test log-likelihood, than the predictive distribution of a classifier based on GPs that ignores input noise.",Classification; Gaussian Process; Inference; Semi-supervised Machine Learning; Supervised Machine Learning; Unsupervised Machine Learning; Variable,Supervised Machine Learning; Unsupervised Machine Learning
37,A Bayesian Contiguous Partitioning Method for Learning Clustered Latent Variables,"Zhao Tang Luo, Huiyan Sang, Bani Mallick","(37):1−52, 2021.",https://jmlr.org/papers/v22/20-136.html,https://jmlr.org/papers/volume22/20-136/20-136.pdf,https://jmlr.org/papers/v22/20-136.bib,,,,,"This article develops a Bayesian partitioning prior model from spanning trees of a graph, by first assigning priors on spanning trees, and then the number and the positions of removed edges given a spanning tree. The proposed method guarantees contiguity in clustering and allows to detect clusters with arbitrary shapes and sizes, whereas most existing partition models such as binary trees and Voronoi tessellations do not possess such properties. We embed this partition model within a hierarchical modeling framework to detect a clustered pattern in latent variables.  We focus on illustrating the method through a clustered regression coefficient model for spatial data and propose extensions to other hierarchical models. We prove Bayesian posterior concentration results under an asymptotic framework with random graphs. We design an efficient collapsed Reversible Jump Markov chain Monte Carlo (RJ-MCMC) algorithm to estimate the clustered coefficient values and their uncertainty measures. Finally, we illustrate the performance of the model with simulation studies and a real data analysis of detecting the temperature-salinity relationship from  water masses in the Atlantic Ocean.",Algorithm; Bayesian; Binary Tree; Clustering; Data Analysis; Graph; Modelling; Regression; Uncertainty; Variable; Web Design,Regressions
38,Risk-Averse Learning by Temporal Difference Methods with Markov Risk Measures,"Umit Köse, Andrzej Ruszczyński","(38):1−34, 2021.",https://jmlr.org/papers/v22/20-168.html,https://jmlr.org/papers/volume22/20-168/20-168.pdf,https://jmlr.org/papers/v22/20-168.bib,,,,,We propose a novel reinforcement learning methodology where the system performance is evaluated by a Markov coherent dynamic risk measure with the use of linear value function approximations. We construct projected risk-averse dynamic programming equations and study their properties. We propose new risk-averse counterparts of the basic and multi-step methods of temporal differences and we prove their convergence with probability one. We also perform an empirical study on a complex transportation problem.,Approximation; Methodology; Probability; Programming; Reinforcement Learning; Transportation,Reinforcement
39,giotto-tda: : A Topological Data Analysis Toolkit for Machine Learning and Data Exploration,"Guillaume Tauzin, Umberto Lupo, Lewis Tunstall, Julian Burella Pérez, Matteo Caorsi, Anibal M. Medina-Mardones, Alberto Dassatti, Kathryn Hess","(39):1−6, 2021.  (Machine Learning Open Source Software Paper)",https://jmlr.org/papers/v22/20-325.html,https://jmlr.org/papers/volume22/20-325/20-325.pdf,https://jmlr.org/papers/v22/20-325.bib,https://github.com/giotto-ai/giotto-tda,,,,"We introduce giotto-tda, a Python library that integrates high-performance topological data analysis with machine learning via a scikit-learn-compatible API and state-of-the-art C++ implementations. The library's ability to handle various types of data is rooted in a wide range of preprocessing techniques, and its strong focus on data exploration and interpretability is aided by an intuitive plotting API. Source code, binaries, examples, and documentation can be found at https://github.com/giotto-ai/giotto-tda.",Application Programming Interface (API); Artificial Intelligence (AI); C++; Data Analysis; Documentation; Github; Machine Learning; Python; Scikit-learn,AI; C++; Github; Python Programming
40,Residual Energy-Based Models for Text,"Anton Bakhtin, Yuntian Deng, Sam Gross, Myle Ott, Marc'Aurelio Ranzato, Arthur Szlam","(40):1−41, 2021.",https://jmlr.org/papers/v22/20-326.html,https://jmlr.org/papers/volume22/20-326/20-326.pdf,https://jmlr.org/papers/v22/20-326.bib,,,,,"Current large-scale auto-regressive language models display impressive fluency and can generate convincing text. In this work we start by asking the question: Can the generations of these models be reliably distinguished from  real text by statistical discriminators? We find experimentally that the answer is affirmative when we have access to the training data for the model, and guardedly affirmative even if we do not. This suggests that the auto-regressive models can be improved by incorporating the (globally normalized) discriminators into the generative process. We give a formalism for this using the Energy-Based Model framework, and show that it indeed improves the results of the generative models, measured both in terms of perplexity and in terms of human evaluation.",Microsoft Access; Training,
41,From Fourier to Koopman: Spectral Methods for Long-term Time Series Prediction,"Henning Lange, Steven L. Brunton, J. Nathan Kutz","(41):1−38, 2021.",https://jmlr.org/papers/v22/20-406.html,https://jmlr.org/papers/volume22/20-406/20-406.pdf,https://jmlr.org/papers/v22/20-406.bib,https://github.com/helange23/from_fourier_to_koopman,,,,"We propose spectral methods for long-term forecasting of temporal signals stemming from linear and nonlinear quasi-periodic dynamical systems. For linear signals, we introduce an algorithm with similarities to the Fourier transform but which does not rely on periodicity assumptions, allowing for forecasting given potentially arbitrary sampling intervals. We then extend this algorithm to handle nonlinearities by leveraging Koopman theory. The resulting algorithm performs a spectral decomposition in a nonlinear, data-dependent basis. The optimization objective for both algorithms is highly non-convex.  However, expressing the objective in the frequency domain allows us to compute global optima of the error surface in a scalable and efficient manner, partially by exploiting the computational properties of the Fast Fourier Transform. Because of their close relation to Bayesian Spectral Analysis, uncertainty quantification metrics are a natural byproduct of the spectral forecasting methods. We extensively benchmark these algorithms against other leading forecasting methods on a range of synthetic experiments as well as in the context of real-world power systems and fluid flows.",Algorithm; Bayesian; Forecasting; Objective-C; Sampling; Spectral Analysis; Stemming; Time Series; Transformer; Uncertainty,
42,High-Order Langevin Diffusion Yields an Accelerated MCMC Algorithm,"Wenlong Mou, Yi-An Ma, Martin J. Wainwright, Peter L. Bartlett, Michael I. Jordan","(42):1−41, 2021.",https://jmlr.org/papers/v22/20-576.html,https://jmlr.org/papers/volume22/20-576/20-576.pdf,https://jmlr.org/papers/v22/20-576.bib,,,,,"We propose a Markov chain Monte Carlo (MCMC) algorithm based on third-order Langevin dynamics for sampling from distributions with smooth, log-concave densities.  The higher-order dynamics allow for more flexible discretization schemes, and we develop a specific method that combines splitting with more accurate integration.  For a broad class of $d$-dimensional distributions arising from generalized linear models, we prove that the resulting third-order algorithm produces samples from a distribution that is at most $\varepsilon > 0$ in Wasserstein distance from the target distribution in $O\left(\frac{d^{1/4}}{ \varepsilon^{1/2}} \right)$ steps. This result requires only Lipschitz conditions on the gradient.  For general strongly convex potentials with $\alpha$-th order smoothness, we prove that the mixing time scales as $O \left( \frac{d^{1/4}}{\varepsilon^{1/2}} + \frac{d^{1/2}}{ \varepsilon^{1/(\alpha - 1)}} \right)$.",Algorithm; Generalized Linear Model (GLM); Sales; Sampling; Scheme,
43,Banach Space Representer Theorems for Neural Networks and Ridge Splines,"Rahul Parhi, Robert D. Nowak","(43):1−40, 2021.",https://jmlr.org/papers/v22/20-583.html,https://jmlr.org/papers/volume22/20-583/20-583.pdf,https://jmlr.org/papers/v22/20-583.bib,,,,,"We develop a variational framework to understand the properties of the functions learned by neural networks fit to data. We propose and study a family of continuous-domain linear inverse problems with total variation-like regularization in the Radon domain subject to data fitting constraints. We derive a representer theorem showing that finite-width, single-hidden layer neural networks are solutions to these inverse problems. We draw on many techniques from variational spline theory and so we propose the notion of polynomial ridge splines, which correspond to single-hidden layer neural networks with truncated power functions as the activation function. The representer theorem is reminiscent of the classical reproducing kernel Hilbert space representer theorem, but we show that the neural network problem is posed over a non-Hilbertian Banach space. While the learning problems are posed in the continuous-domain, similar to kernel methods, the problems can be recast as finite-dimensional neural network training problems. These neural network training problems have regularizers which are related to the well-known weight decay and path-norm regularizers.  Thus, our result gives insight into functional characteristics of trained neural networks and also into the design neural network regularizers. We also show that these regularizers promote neural network solutions with desirable generalization properties.",Design; Neural Network; Training,
44,Wasserstein barycenters can be computed in polynomial time in fixed dimension,"Jason M Altschuler, Enric Boix-Adsera","(44):1−19, 2021.",https://jmlr.org/papers/v22/20-588.html,https://jmlr.org/papers/volume22/20-588/20-588.pdf,https://jmlr.org/papers/v22/20-588.bib,https://github.com/eboix/high_precision_barycenters,,,,"Computing Wasserstein barycenters is a fundamental geometric problem with widespread applications in machine learning, statistics, and computer graphics. However, it is unknown whether Wasserstein barycenters can be computed in polynomial time, either exactly or to high precision (i.e., with $\textrm{polylog}(1/\varepsilon)$ runtime dependence). This paper answers these questions in the affirmative for any fixed dimension. Our approach is to solve an exponential-size linear programming formulation by efficiently implementing the corresponding separation oracle using techniques from computational geometry.",2D Computer Graphics; 3D Computer Graphics; Computational Geometry; Computing; Linear Programming; Machine Learning; Oracle; R; Statistics,R programming; Statistics
45,RaSE: Random Subspace Ensemble Classification,"Ye Tian, Yang Feng","(45):1−93, 2021.",https://jmlr.org/papers/v22/20-600.html,https://jmlr.org/papers/volume22/20-600/20-600.pdf,https://jmlr.org/papers/v22/20-600.bib,https://cran.r-project.org/web/packages/RaSEn/index.html,,,,"We propose a flexible ensemble classification framework, Random Subspace Ensemble (RaSE), for sparse classification. In the RaSE algorithm, we aggregate many weak learners, where each weak learner is a base classifier trained in a subspace optimally selected from a collection of random subspaces. To conduct subspace selection, we propose a new criterion, ratio information criterion (RIC), based on weighted Kullback-Leibler divergence. The theoretical analysis includes the risk and Monte-Carlo variance of the RaSE classifier, establishing the screening consistency and weak consistency of RIC, and providing an upper bound for the misclassification rate of the RaSE classifier. In addition, we show that in a high-dimensional framework, the number of random subspaces needs to be very large to guarantee that a subspace covering signals is selected. Therefore, we propose an iterative version of the RaSE algorithm and prove that under some specific conditions, a smaller number of generated random subspaces are needed to find a desirable subspace through iteration. An array of simulations under various models and real-data applications demonstrate the effectiveness and robustness of the RaSE classifier and its iterative version in terms of low misclassification rate and accurate feature ranking. The RaSE algorithm is implemented in the R package RaSEn on CRAN.",Algorithm; Analysis; Array; Classification; Ensemble; R; Selection,R programming
46,Optimal Structured Principal Subspace Estimation: Metric Entropy and Minimax Rates,"Tony Cai, Hongzhe Li, Rong Ma","(46):1−45, 2021.",https://jmlr.org/papers/v22/20-610.html,https://jmlr.org/papers/volume22/20-610/20-610.pdf,https://jmlr.org/papers/v22/20-610.bib,,,,,"Driven by a wide range of applications, several principal subspace estimation problems have been studied individually under different structural constraints. This paper presents a unified framework for the statistical analysis of a general structured principal subspace estimation problem which includes as special cases sparse PCA/SVD, non-negative PCA/SVD, subspace constrained PCA/SVD, and spectral clustering. General minimax lower and upper bounds are established to characterize the interplay between the information-geometric complexity of the constraint set for the principal subspaces, the signal-to-noise ratio (SNR), and the dimensionality. The results yield interesting phase transition phenomena concerning the rates of convergence as a function of the SNRs and the fundamental limit for consistent estimation. Applying the general results to the specific settings yields the minimax rates of convergence for those problems, including the previous unknown optimal rates for sparse SVD, non-negative PCA/SVD and subspace constrained PCA/SVD.",Complexity; Principal Component Analysis (PCA); Spectral Clustering; Statistical Analysis,
47,Understanding Recurrent Neural Networks Using Nonequilibrium Response Theory,Soon Hoe Lim,"(47):1−48, 2021.",https://jmlr.org/papers/v22/20-620.html,https://jmlr.org/papers/volume22/20-620/20-620.pdf,https://jmlr.org/papers/v22/20-620.bib,,,,,"Recurrent neural networks (RNNs) are brain-inspired models widely used in machine learning for analyzing sequential data. The present work is a contribution towards a deeper understanding of how RNNs process input signals using the response theory from nonequilibrium statistical mechanics. For a class of continuous-time  stochastic RNNs (SRNNs) driven by an input signal,  we derive a Volterra type series representation for their output. This representation is interpretable and disentangles the input signal from the SRNN architecture. The kernels of the series are certain recursively defined correlation functions with respect to the unperturbed  dynamics that completely determine the output. Exploiting connections of this representation and its implications to rough paths theory, we identify a universal feature -- the response feature, which turns out to be the signature of tensor product of the input signal and a natural support basis. In particular, we show that SRNNs, with only the weights in the readout layer optimized and the weights in the hidden layer kept fixed and not optimized, can be viewed as kernel machines operating on a reproducing kernel Hilbert space associated with the response feature",Architecture; Correlation; Machine Learning; Mechanics; Presentation; Recurrent Neural Network (RNN); Statistical Mechanis,Presentation Skill
48,Optimal Feedback Law Recovery by Gradient-Augmented Sparse Polynomial Regression,"Behzad Azmi, Dante Kalise, Karl Kunisch","(48):1−32, 2021.",https://jmlr.org/papers/v22/20-755.html,https://jmlr.org/papers/volume22/20-755/20-755.pdf,https://jmlr.org/papers/v22/20-755.bib,,,,,"A sparse regression approach for the computation of high-dimensional optimal feedback laws arising in deterministic nonlinear control is proposed. The approach exploits the control-theoretical link between Hamilton-Jacobi-Bellman PDEs characterizing the value function of the optimal control problems, and first-order optimality conditions via Pontryagin's Maximum Principle. The latter is used as a representation formula to recover the value function and its gradient at arbitrary points in the space-time domain through the solution of a two-point boundary value problem. After generating a dataset consisting of different state-value pairs, a hyperbolic cross polynomial model for the value function is fitted using a LASSO regression. An extended set of low and high-dimensional numerical tests in nonlinear optimal control reveal that enriching the dataset with gradient information reduces the number of training samples, and that the sparse polynomial regression consistently yields a feedback law of lower complexity.",Complexity; Dataset; Exploit; LASSO Regression; Lasso; Law; Polynomial Regression; Presentation; Regression; Training,Presentation Skill; Regressions
49,From Low Probability to High Confidence in Stochastic Convex Optimization,"Damek Davis, Dmitriy Drusvyatskiy, Lin Xiao, Junyu Zhang","(49):1−38, 2021.",https://jmlr.org/papers/v22/20-821.html,https://jmlr.org/papers/volume22/20-821/20-821.pdf,https://jmlr.org/papers/v22/20-821.bib,,,,,"Standard results in stochastic convex optimization bound the number of samples that an algorithm needs to generate a point with small function value in expectation. More nuanced high probability guarantees are rare, and typically either rely on light-tail noise assumptions or exhibit worse sample complexity. In this work, we show that a wide class of stochastic optimization algorithms for strongly convex problems can be augmented with high confidence bounds at an overhead cost that is only logarithmic in the confidence level and polylogarithmic in the condition number. The procedure we propose, called proxBoost, is elementary and builds on two well-known ingredients: robust distance estimation and the proximal point method. We discuss consequences for both streaming (online) algorithms and offline algorithms based on empirical risk minimization.",Algorithm; Complexity; Probability; Streaming,
50,Structure Learning of Undirected Graphical Models for Count Data,"Nguyen Thi Kim Hue, Monica Chiogna","(50):1−53, 2021.",https://jmlr.org/papers/v22/18-401.html,https://jmlr.org/papers/volume22/18-401/18-401.pdf,https://jmlr.org/papers/v22/18-401.bib,,,,,"Mainly motivated by the problem of modelling biological processes underlying the basic functions of a cell -that typically involve complex  interactions between genes- we present a new algorithm, called PC-LPGM, for learning the structure of undirected graphical models over discrete variables. We prove theoretical consistency of PC-LPGM in the limit of infinite observations and discuss its robustness to model misspecification. To evaluate the performance of PC-LPGM in recovering the true structure of the graphs in situations where relatively moderate sample sizes are available, extensive simulation studies are conducted, that also allow  to compare our proposal with its main competitors. A biological validation of the algorithm is presented through the analysis of two real data sets.",Algorithm; Analysis; Graph; Graphical Model; Modelling; Variable,
51,Projection-free Decentralized Online Learning for Submodular Maximization over Time-Varying Networks,"Junlong Zhu, Qingtao Wu, Mingchuan Zhang, Ruijuan Zheng, Keqin Li","(51):1−42, 2021.",https://jmlr.org/papers/v22/18-407.html,https://jmlr.org/papers/volume22/18-407/18-407.pdf,https://jmlr.org/papers/v22/18-407.bib,,,,,"This paper considers a decentralized online submodular maximization problem over time-varying networks, where each agent only utilizes its own information and the received information from its neighbors. To address the problem, we propose a decentralized Meta-Frank-Wolfe online learning method in the adversarial online setting by using local communication and local computation. Moreover, we show that an expected regret bound of $O(\sqrt{T})$ is achieved with $(1-1/e)$ approximation guarantee, where $T$ is a time horizon. In addition, we also propose a decentralized one-shot Frank-Wolfe online learning method in the stochastic online setting. Furthermore, we also show that an expected regret bound $O(T^{2/3})$ is obtained with $(1-1/e)$ approximation guarantee. Finally, we confirm the theoretical results via various experiments on different datasets.",Approximation; Dataset; Network; Oral Communication,
52,Sparse and Smooth Signal Estimation: Convexification of L0-Formulations,"Alper Atamturk, Andres Gomez, Shaoning Han","(52):1−43, 2021.",https://jmlr.org/papers/v22/18-745.html,https://jmlr.org/papers/volume22/18-745/18-745.pdf,https://jmlr.org/papers/v22/18-745.bib,,,,,"Signal estimation problems with smoothness and sparsity priors can be naturally modeled as quadratic optimization with $\ell_0$-“norm” constraints. Since such problems are non-convex and hard-to-solve, the standard approach is, instead, to tackle their convex surrogates based on $\ell_1$-norm relaxations. In this paper, we propose new iterative (convex) conic quadratic relaxations that exploit not only the $\ell_0$-“norm” terms, but also the fitness and smoothness functions. The iterative convexification approach substantially closes the gap between the $\ell_0$-“norm” and its $\ell_1$ surrogate. These stronger relaxations lead to significantly better estimators than $\ell_1$-norm approaches and also allow one to utilize affine sparsity priors. In addition, the parameters of the model and the resulting estimators are easily interpretable. Experiments with a tailored Lagrangian decomposition method indicate that the proposed iterative convex relaxations yield solutions within 1\% of the exact $\ell_0$-approach, and can tackle instances with up to 100,000 variables under one minute.",Exploit; Variable,
53,Subspace Clustering through Sub-Clusters,"Weiwei Li, Jan Hannig, Sayan Mukherjee","(53):1−37, 2021.",https://jmlr.org/papers/v22/18-780.html,https://jmlr.org/papers/volume22/18-780/18-780.pdf,https://jmlr.org/papers/v22/18-780.bib,,,,,"The problem of dimension reduction is of increasing importance in modern data analysis. In this paper, we consider modeling the collection of points in a high dimensional space as a union of low dimensional subspaces. In particular we propose a  highly scalable sampling based algorithm that clusters the entire data via first spectral clustering of a small random sample followed by classifying or labeling the remaining out-of-sample points. The key idea is that this random subset borrows information across the entire dataset and that the problem of clustering points can be replaced with the more efficient problem of ""clustering sub-clusters"". We provide theoretical guarantees for our procedure. The numerical results indicate that for large datasets the proposed algorithm outperforms other state-of-the-art subspace clustering algorithms with respect to accuracy and speed.",Accuracy; Algorithm; Data Analysis; Dataset; Modelling; Sampling; Spectral Clustering,
54,GemBag: Group Estimation of Multiple Bayesian Graphical Models,"Xinming Yang, Lingrui Gan, Naveen N. Narisetty, Feng Liang","(54):1−48, 2021.",https://jmlr.org/papers/v22/19-1006.html,https://jmlr.org/papers/volume22/19-1006/19-1006.pdf,https://jmlr.org/papers/v22/19-1006.bib,,,,,"In this paper, we propose a novel hierarchical Bayesian model and an efficient estimation method for the problem of joint estimation of multiple graphical models, which have similar but different sparsity structures and signal strength. Our proposed hierarchical Bayesian model is well suited for sharing of sparsity structures, and our procedure, called as GemBag, is shown to enjoy optimal theoretical properties in terms of sup-norm estimation accuracy and correct recovery of the graphical structure even when some of the signals are weak. Although optimization of the posterior distribution required for obtaining our proposed estimator is a non-convex optimization problem, we show that it turns out to be convex in a large constrained space facilitating the use of computationally efficient algorithms. Through extensive simulation studies and an application to a bike sharing data set, we demonstrate that the proposed GemBag procedure has strong empirical performance in comparison with alternative methods.",Accuracy; Algorithm; Bayesian; Graphical Model; Point Estimation,
55,Integrative Generalized Convex Clustering Optimization and Feature Selection for Mixed Multi-View Data,"Minjie Wang, Genevera I. Allen","(55):1−73, 2021.",https://jmlr.org/papers/v22/19-1012.html,https://jmlr.org/papers/volume22/19-1012/19-1012.pdf,https://jmlr.org/papers/v22/19-1012.bib,,,,,"In mixed multi-view data, multiple sets of diverse features are measured on the same set of samples.  By integrating all available data sources, we seek to discover common group structure among the samples that may be hidden in individualistic cluster analyses of a single data view. While several techniques for such integrative clustering have been explored, we propose and develop a convex formalization that enjoys strong empirical performance and inherits the mathematical properties of increasingly popular convex clustering methods. Specifically, our Integrative Generalized Convex Clustering Optimization (iGecco) method employs different convex distances, losses, or divergences for each of the different data views with a joint convex fusion penalty that leads to common groups.  Additionally, integrating mixed multi-view data is often challenging when each data source is high-dimensional.  To perform feature selection in such scenarios, we develop an adaptive shifted group-lasso penalty that selects features by shrinking them towards their loss-specific centers.  Our so-called iGecco+ approach selects features from each data view that are best for determining the groups, often leading to improved integrative clustering.  To solve our problem, we develop a new type of generalized multi-block ADMM algorithm using sub-problem approximations that more efficiently fits our model for big data sets.  Through a series of numerical experiments and real data examples on text mining and genomics, we show that iGecco+ achieves superior empirical performance for high-dimensional mixed multi-view data.",Algorithm; Approximation; Big Data; Cluster Analysis; Clustering; Feature Selection; Genomics; Lasso; Text Mining,
56,Incorporating Unlabeled Data into Distributionally Robust Learning,"Charlie Frogner, Sebastian Claici, Edward Chien, Justin Solomon","(56):1−46, 2021.",https://jmlr.org/papers/v22/19-1023.html,https://jmlr.org/papers/volume22/19-1023/19-1023.pdf,https://jmlr.org/papers/v22/19-1023.bib,,,,,"We study a robust alternative to empirical risk minimization called distributionally robust learning (DRL), in which one learns to perform against an adversary who can choose the data distribution from a specified set of distributions. We illustrate a problem with current DRL formulations, which rely on an overly broad definition of allowed distributions for the adversary, leading to learned classifiers that are unable to predict with any confidence. We propose a solution that incorporates unlabeled data into the DRL problem to further constrain the adversary. We show that this new formulation is tractable for stochastic gradient-based optimization and yields a computable guarantee on the future performance of the learned classifier, analogous to -- but tighter than -- guarantees from conventional DRL. We examine the performance of this new formulation on 14 real data sets and find that it often yields effective classifiers with nontrivial performance guarantees in situations where conventional DRL produces neither. Inspired by these results, we extend our DRL formulation to active learning with a novel, distributionally-robust version of the standard model-change heuristic. Our active learning algorithm often achieves superior learning performance to the original heuristic on real data sets.",Machine Learning Algorithm,
57,Normalizing Flows for Probabilistic Modeling and Inference,"George Papamakarios, Eric Nalisnick, Danilo Jimenez Rezende, Shakir Mohamed, Balaji Lakshminarayanan","(57):1−64, 2021.",https://jmlr.org/papers/v22/19-1028.html,https://jmlr.org/papers/volume22/19-1028/19-1028.pdf,https://jmlr.org/papers/v22/19-1028.bib,,,,,"Normalizing flows provide a general mechanism for defining expressive probability distributions, only requiring the specification of a (usually simple) base distribution and a series of bijective transformations. There has been much recent work on normalizing flows, ranging from improving their expressive power to expanding their application. We believe the field has now matured and is in need of a unified perspective. In this review, we attempt to provide such a perspective by describing flows through the lens of probabilistic modeling and inference. We place special emphasis on the fundamental principles of flow design, and discuss foundational topics such as expressive power and computational trade-offs. We also broaden the conceptual framing of flows by relating them to more general probability transformations. Lastly, we summarize the use of flows for tasks such as generative modeling, approximate inference, and supervised learning.",Design; Inference; Modelling; Probability Distribution; Supervised Learning; Trade; Unsupervised Learning,
58,Estimation and Inference for High Dimensional Generalized Linear Models: A Splitting and Smoothing Approach,"Zhe Fei, Yi Li","(58):1−32, 2021.",https://jmlr.org/papers/v22/19-132.html,https://jmlr.org/papers/volume22/19-132/19-132.pdf,https://jmlr.org/papers/v22/19-132.bib,https://github.com/feizhe/SSHDI,,,,"The focus of modern biomedical studies has gradually shifted to explanation and estimation of joint effects of high dimensional predictors on disease risks. Quantifying uncertainty in these estimates may provide valuable insight into prevention strategies or treatment decisions for both patients and physicians. High dimensional inference, including confidence intervals and hypothesis testing, has sparked much interest. While much work has been done in the linear regression setting, there is lack of literature on inference for high dimensional generalized linear models. We propose a novel and computationally feasible method, which accommodates a variety of outcome types, including normal, binomial, and Poisson data. We use a “splitting and smoothing” approach, which splits samples into two parts, performs variable selection using one part and conducts partial regression with the other part. Averaging the estimates over multiple random splits, we obtain the smoothed estimates, which are numerically stable. We show that the estimates are consistent, asymptotically normal, and construct confidence intervals with proper coverage probabilities for all predictors.  We examine the finite sample performance of our method by comparing it with the existing methods and applying it to analyze a lung cancer cohort study.",Confidence Intervals; Generalized Linear Model (GLM); Hypothesis Testing; Inference; Linear Regression; Literature; Nonlinear Regression; Regression; Selection; Table; TestNG; Uncertainty; Variable,Regressions
59,Predictive Learning on Hidden Tree-Structured Ising Models,"Konstantinos E. Nikolakakis, Dionysios S. Kalogerias, Anand D. Sarwate","(59):1−82, 2021.",https://jmlr.org/papers/v22/19-149.html,https://jmlr.org/papers/volume22/19-149/19-149.pdf,https://jmlr.org/papers/v22/19-149.bib,https://github.com/KonstantinosNikolakakis,,,,"We provide high-probability sample complexity guarantees for exact structure recovery and accurate predictive learning using noise-corrupted samples from an acyclic (tree-shaped) graphical model. The hidden variables follow a tree-structured Ising model distribution, whereas the observable variables are generated by a binary symmetric channel taking the hidden variables as its input (flipping each bit independently with some constant probability $q\in [0,1/2)$). In the absence of noise, predictive learning on Ising models was recently studied by Bresler and Karzand (2020); this paper quantifies how noise in the hidden model impacts the tasks of structure recovery and marginal distribution estimation by proving upper and lower bounds on the sample complexity. Our results generalize state-of-the-art bounds reported in prior work, and they exactly recover the noiseless case ($q=0$). In fact, for any tree with $p$ vertices and probability of incorrect recovery $\delta>0$, the sufficient number of samples remains logarithmic as in the noiseless case, i.e., $\mathcal{O}(\log(p/\delta))$, while the dependence on $q$ is $\mathcal{O}\big( 1/(1-2q)^{4} \big)$, for both aforementioned tasks. We also present a new equivalent of Isserlis' Theorem for sign-valued tree-structured distributions, yielding a new low-complexity algorithm for higher-order moment estimation.",Algorithm; Complexity; Graphical Model; Probability; Tree; Variable,
60,A Distributed Method for Fitting Laplacian Regularized Stratified Models,"Jonathan Tuck, Shane Barratt, Stephen Boyd","(60):1−37, 2021.",https://jmlr.org/papers/v22/19-345.html,https://jmlr.org/papers/volume22/19-345/19-345.pdf,https://jmlr.org/papers/v22/19-345.bib,https://github.com/cvxgrp/strat_models,,,,"Stratified models are models that depend in an arbitrary way on a set of selected categorical features, and depend linearly on  the other features. In a basic and traditional formulation a separate model is fit for each value of the categorical feature, using only the data that has the specific categorical value. To this formulation we add Laplacian regularization, which encourages the model parameters for neighboring categorical values to be similar. Laplacian regularization allows us to specify one or more weighted graphs on the stratification feature values. For example, stratifying over the days of the week, we can specify that the Sunday model parameter should be close to the Saturday and Monday model parameters. The regularization improves the performance of the model over the traditional stratified model, since the model for each value of the categorical `borrows strength' from its neighbors. In particular, it produces a model even for categorical values that did not appear in the training data set. We propose an efficient distributed method for fitting stratified models, based on the alternating direction method of multipliers (ADMM).  When the fitting loss functions are convex, the stratified model  fitting problem is convex, and our method computes  the global minimizer of the loss plus regularization;  in other cases it computes a local minimizer. The method is very efficient, and naturally scales to large data sets or numbers of stratified feature values. We illustrate our method with a variety of examples.",Graph; Sales; Training,
61,Stochastic Proximal AUC Maximization,"Yunwen Lei, Yiming Ying","(61):1−45, 2021.",https://jmlr.org/papers/v22/19-418.html,https://jmlr.org/papers/volume22/19-418/19-418.pdf,https://jmlr.org/papers/v22/19-418.bib,,,,,"In this paper we consider the problem of maximizing the Area under the ROC curve (AUC) which is a widely used performance metric in imbalanced classification and anomaly detection. Due to the pairwise nonlinearity of the objective function, classical SGD algorithms do not apply to the task of AUC maximization. We propose a novel stochastic proximal algorithm for AUC maximization which is scalable to large scale streaming data. Our algorithm can accommodate general penalty terms and is easy to implement with favorable $O(d)$ space and per-iteration time complexities. We establish a high-probability convergence rate $O(1/\sqrt{T})$ for the general convex setting, and improve it to a fast convergence rate $O(1/T)$ for the cases of strongly convex regularizers and no regularization term (without strong convexity). Our proof does not need the uniform boundedness assumption on the loss function or the iterates which is more fidelity to the practice. Finally, we perform extensive experiments over various benchmark data sets from real-world application domains which show the superior performance of our algorithm over the existing AUC maximization algorithms.",Algorithm; Anomaly Detection; Classification; Convexity; Objective-C; Probability; Streaming,
62,How to Gain on Power: Novel  Conditional Independence Tests Based on Short Expansion of Conditional Mutual Information,"Mariusz Kubkowski, Jan Mielniczuk, Paweł Teisseyre","(62):1−57, 2021.",https://jmlr.org/papers/v22/19-600.html,https://jmlr.org/papers/volume22/19-600/19-600.pdf,https://jmlr.org/papers/v22/19-600.bib,,,,,"Conditional independence tests play a crucial role in many machine learning procedures such as feature selection, causal discovery, and  structure learning of dependence networks. They are used in   most of the  existing algorithms for Markov Blanket discovery such as Grow-Shrink or Incremental Association Markov Blanket. One of the most frequently used tests for categorical variables is based on the conditional mutual information ($CMI$) and its asymptotic distribution. However, it is known that the power of such test dramatically decreases when the size of the conditioning set grows, i.e. the test fails to detect true significant variables, when the set of already selected variables is large. To overcome this drawback for discrete data, we propose to replace the conditional mutual information by  Short Expansion of Conditional Mutual Information (called $SECMI$), obtained by truncating the Möbius representation of $CMI$. We prove that the distribution of $SECMI$ converges to  either a  normal distribution  or to a distribution of some quadratic form in  normal  random variables. This property is crucial for the construction of a novel  test of conditional independence which uses one of these distributions, chosen in a data dependent way, as a reference under the null hypothesis. The proposed methods have significantly larger power  for discrete data than the standard asymptotic tests of conditional independence based on  $CMI$ while retaining  control  of the probability of  type I error.",Algorithm; Construction; Feature Selection; Log-Normal Distribution; Machine Learning; Network; Play; Presentation; Probability; Property; Random Variable,Presentation Skill
63,Geometric structure of graph Laplacian embeddings,"Nicolás García Trillos, Franca Hoffmann, Bamdad Hosseini","(63):1−55, 2021.",https://jmlr.org/papers/v22/19-683.html,https://jmlr.org/papers/volume22/19-683/19-683.pdf,https://jmlr.org/papers/v22/19-683.bib,,,,,"We analyze the spectral clustering procedure for identifying coarse structure in a data set $\mathbf{x}_1, \dots, \mathbf{x}_n$, and in particular study the geometry of graph Laplacian embeddings which form the basis for spectral clustering algorithms. More precisely, we assume that the data are sampled from a mixture model supported on a manifold $\mathcal{M}$ embedded in $\mathbb{R}^d$, and pick a connectivity length-scale $\varepsilon>0$ to construct a kernelized graph Laplacian. We introduce a notion of a well-separated mixture model which only depends on the model itself, and prove that when the model is well separated, with high probability the embedded data set concentrates on cones that are centered around orthogonal vectors. Our results are meaningful in the regime where $\varepsilon = \varepsilon(n)$ is allowed to decay to zero at a slow enough rate as the number of data points grows. This rate depends on the intrinsic dimension of the manifold on which the data is supported.",Algorithm; Geometry; Graph; Probability Theory; Spectral Clustering,
64,Sparse Tensor Additive Regression,"Botao Hao, Boxiang Wang, Pengyuan Wang, Jingfei Zhang, Jian Yang, Will Wei Sun","(64):1−43, 2021.",https://jmlr.org/papers/v22/19-769.html,https://jmlr.org/papers/volume22/19-769/19-769.pdf,https://jmlr.org/papers/v22/19-769.bib,,,,,"Tensors are becoming prevalent in modern applications such as medical imaging and digital marketing. In this paper, we propose a sparse tensor additive regression (STAR) that models a scalar response as a flexible nonparametric function of tensor covariates. The proposed model effectively exploits the sparse and low-rank structures in the tensor additive regression. We formulate the parameter estimation as a non-convex optimization problem, and propose an efficient penalized alternating minimization algorithm. We establish a non-asymptotic error bound for the estimator obtained from each iteration of the proposed algorithm, which reveals an interplay between the optimization error and the statistical rate of convergence. We demonstrate the efficacy of STAR through extensive comparative simulation studies, and an application to the click-through-rate prediction in online advertising.",Advertising; Algorithm; Digital Marketing; Exploit; Regression; Scala; Scalr,Regressions
65,Dynamic Tensor Recommender Systems,"Yanqing Zhang, Xuan Bi, Niansheng Tang, Annie Qu","(65):1−35, 2021.",https://jmlr.org/papers/v22/19-792.html,https://jmlr.org/papers/volume22/19-792/19-792.pdf,https://jmlr.org/papers/v22/19-792.bib,,,,,"Recommender systems have been extensively used by the entertainment industry, business marketing and the biomedical industry. In addition to its capacity of providing preference based recommendations as an unsupervised learning methodology, it has been also proven useful in sales forecasting, product introduction and other production related businesses. Since some consumers and companies need a recommendation or prediction for future budget, labor and supply chain coordination, dynamic recommender systems for precise forecasting have become extremely necessary. In this article, we propose a new recommendation method, namely the dynamic tensor recommender system (DTRS), which aims particularly at forecasting future recommendation. The proposed method utilizes a tensor-valued function of time to integrate time and contextual information, and creates a time-varying coefficient model for temporal tensor factorization through a polynomial spline approximation. Major advantages of the proposed method include competitive future recommendation predictions and effective prediction interval estimations. In theory, we establish the convergence rate of the proposed tensor factorization and asymptotic normality of the spline coefficient estimator. The proposed method is applied to simulations, IRI marketing data and Last.fm data. Numerical studies demonstrate that the proposed method outperforms existing methods in terms of future time forecasting.",Approximation; Budget; Entertainment; Forecasting; Interval Estimation; Marketing; Methodology; Recommendations AI; Sales; Supervised Learning; Unsupervised Learning,
66,Approximate Newton Methods,"Haishan Ye, Luo Luo, Zhihua Zhang","(66):1−41, 2021.",https://jmlr.org/papers/v22/19-870.html,https://jmlr.org/papers/volume22/19-870/19-870.pdf,https://jmlr.org/papers/v22/19-870.bib,,,,,"Many machine learning models involve solving optimization problems. Thus, it is important to address  a large-scale optimization problem in big data applications.  Recently, subsampled Newton methods have emerged to attract much attention due to their efficiency at each iteration, rectified a weakness in the ordinary Newton method of suffering a high cost in each iteration while commanding a high convergence rate.   Other efficient stochastic second order methods have been also proposed.  However, the convergence properties of these methods are still not well understood. There are also several important gaps between the current convergence theory and the empirical performance in real applications. In this paper, we aim to fill these gaps. We propose a unifying framework to analyze both local and global convergence properties of second order methods. Accordingly, we present our theoretical results which match the empirical performance in real applications well.",Big Data; Machine Learning,
67,A General Framework for Empirical Bayes Estimation in Discrete Linear Exponential Family,"Trambak Banerjee, Qiang Liu, Gourab Mukherjee, Wengunag Sun","(67):1−46, 2021.",https://jmlr.org/papers/v22/19-873.html,https://jmlr.org/papers/volume22/19-873/19-873.pdf,https://jmlr.org/papers/v22/19-873.bib,,,,,"We develop a Nonparametric Empirical Bayes (NEB) framework for compound estimation in the discrete linear exponential family, which includes a wide class of discrete distributions frequently arising from modern big data applications. We propose to directly estimate the Bayes shrinkage factor in the generalized Robbins' formula via solving a convex program, which is carefully developed based on a RKHS representation of the Stein's discrepancy measure. The new NEB estimation framework is  flexible for incorporating various structural constraints into the data driven rule, and provides a unified approach to compound estimation with both regular and scaled squared error losses. We develop theory to show that the class of NEB estimators enjoys strong asymptotic properties. Comprehensive simulation studies as well as analyses of real data examples are carried out to demonstrate the superiority of the NEB estimator over competing methods.",Big Data; Presentation; Web Framework,Presentation Skill
68,Path Length Bounds for Gradient Descent and Flow,"Chirag Gupta, Sivaraman Balakrishnan, Aaditya Ramdas","(68):1−63, 2021.",https://jmlr.org/papers/v22/19-979.html,https://jmlr.org/papers/volume22/19-979/19-979.pdf,https://jmlr.org/papers/v22/19-979.bib,,,,https://blog.ml.cmu.edu/2019/10/25/path-length-bounds-for-gradient-descent/,"We derive bounds on the path length $\zeta$ of gradient descent (GD) and gradient flow (GF) curves for various classes of smooth convex and nonconvex functions. Among other results, we prove that: (a) if the iterates are linearly convergent with factor $(1-c)$, then $\zeta$ is at most $\mathcal{O}(1/c)$; (b) under the Polyak-Kurdyka-\L ojasiewicz (PKL) condition, $\zeta$ is at most $\mathcal{O}(\sqrt{\kappa})$, where $\kappa$ is the condition number, and at least $\widetilde\Omega(\sqrt{d} \wedge \kappa^{1/4})$; (c) for quadratics, $\zeta$ is $\Theta(\min\{\sqrt{d},\sqrt{\log \kappa}\})$ and in some cases can be independent of $\kappa$; (d) assuming just convexity, $\zeta$ can be at most $2^{4d\log d}$; (e) for separable quasiconvex functions, $\zeta$ is ${\Theta}(\sqrt{d})$. Thus, we advance current understanding of the properties of GD and GF curves beyond rates of convergence. We expect our techniques to facilitate future studies for other algorithms.",Algorithm; C; Convexity; Gradient Descent,
69,Determining the Number of Communities in Degree-corrected Stochastic Block Models,"Shujie Ma, Liangjun Su, Yichong Zhang","(69):1−63, 2021.",https://jmlr.org/papers/v22/20-037.html,https://jmlr.org/papers/volume22/20-037/20-037.pdf,https://jmlr.org/papers/v22/20-037.bib,,,,,"We propose to estimate the number of communities in degree-corrected stochastic block models based on a pseudo likelihood ratio statistic. To this end, we introduce a method that combines spectral clustering with binary segmentation. This approach guarantees an upper bound for the pseudo likelihood ratio statistic when the model is over-fitted. We also derive its limiting distribution when the model is under-fitted. Based on these properties, we establish the consistency of our estimator for the true number of communities. Developing these theoretical properties require a mild condition on the average degrees - growing at a rate no slower than log(n), where n is the number of nodes. Our proposed method is further illustrated by simulation studies and analysis of real-world networks. The numerical results show that our approach has satisfactory performance when the network is semi-dense.",Analysis; Network; Spectral Clustering; Statistics,Statistics
70,Testing Conditional Independence via Quantile Regression Based Partial Copulas,"Lasse Petersen, Niels Richard Hansen","(70):1−47, 2021.",https://jmlr.org/papers/v22/20-1074.html,https://jmlr.org/papers/volume22/20-1074/20-1074.pdf,https://jmlr.org/papers/v22/20-1074.bib,https://github.com/lassepetersen/partial-copula-CI-test,,,,"The partial copula provides a method for describing the dependence between two random variables $X$ and $Y$ conditional on a third random vector $Z$ in terms of nonparametric residuals $U_1$ and $U_2$. This paper develops a nonparametric test for conditional independence by combining the partial copula with a quantile regression based method for estimating the nonparametric residuals. We consider a test statistic based on generalized correlation between $U_1$ and $U_2$ and derive its large sample properties under consistency assumptions on the quantile regression procedure. We demonstrate through a simulation study that the resulting test is sound under complicated data generating distributions. Moreover, in the examples considered the test is competitive to other state-of-the-art conditional independence tests in terms of level and power, and it has superior power in cases with conditional variance heterogeneity of $X$ and $Y$ given $Z$.",Copula; Correlation; Parametric Test; Random Variable; Regression; Statistics; TestNG; Testing,Regressions; Statistics
71,Phase Diagram for Two-layer ReLU Neural Networks at Infinite-width Limit,"Tao Luo, Zhi-Qin John Xu, Zheng Ma, Yaoyu Zhang","(71):1−47, 2021.",https://jmlr.org/papers/v22/20-1123.html,https://jmlr.org/papers/volume22/20-1123/20-1123.pdf,https://jmlr.org/papers/v22/20-1123.bib,https://github.com/xuzhiqin1990/phasediagram_twolayerNN,,,,"How neural network behaves during the training over different choices of hyperparameters is an important question in the study of neural networks. In this work, inspired by the phase diagram in statistical mechanics, we draw the phase diagram for the two-layer ReLU neural network at the infinite-width limit for a complete characterization of its dynamical regimes and their dependence on hyperparameters related to initialization. Through both experimental and theoretical approaches, we identify three regimes in the phase diagram, i.e., linear regime, critical regime and condensed regime, based on the relative change of input weights as the width approaches infinity, which tends to $0$, $O(1)$ and $+\infty$, respectively. In the linear regime, NN training dynamics is approximately linear similar to a random feature model with an exponential loss decay. In the condensed regime, we demonstrate through experiments that active neurons are condensed at several discrete orientations. The critical regime serves as the boundary between above two regimes, which exhibits an intermediate nonlinear behavior with the mean-field model as a typical example. Overall, our phase diagram for the two-layer ReLU NN serves as a map for the future studies and is a first step towards a more systematical investigation of the training behavior and the implicit regularization of NNs of different structures.",Mechanics; Neural Network; Statistical Mechanis; Training,
72,Prediction against a limited adversary,"Erhan Bayraktar, Ibrahim Ekren, Xin Zhang","(72):1−33, 2021.",https://jmlr.org/papers/v22/20-1234.html,https://jmlr.org/papers/volume22/20-1234/20-1234.pdf,https://jmlr.org/papers/v22/20-1234.bib,,,,,"We study the problem of prediction with expert advice with adversarial corruption where the adversary can at most corrupt one expert. Using tools from viscosity theory, we characterize the long-time behavior of the value function of the game between the forecaster and the adversary. We provide lower and upper bounds for the growth rate of regret without relying on a comparison result. We show that depending on the description of regret, the limiting behavior of the game can significantly differ.",,
73,"Optimization with Momentum: Dynamical, Control-Theoretic, and Symplectic Perspectives","Michael Muehlebach, Michael I. Jordan","(73):1−50, 2021.",https://jmlr.org/papers/v22/20-207.html,https://jmlr.org/papers/volume22/20-207/20-207.pdf,https://jmlr.org/papers/v22/20-207.bib,,,,,"We analyze the convergence rate of various momentum-based optimization algorithms from a dynamical systems point of view. Our analysis exploits fundamental topological properties, such as the continuous dependence of iterates on their initial conditions, to provide a simple characterization of convergence rates. In many cases, closed-form expressions are obtained that relate algorithm parameters to the convergence rate. The analysis encompasses discrete time and continuous time, as well as time-invariant and time-variant formulations, and is not limited to a convex or Euclidean setting. In addition, the article rigorously establishes why symplectic discretization schemes are important for momentum-based optimization algorithms, and provides a characterization of algorithms that exhibit accelerated convergence.",Algorithm; Analysis; Exploit; Scheme,
74,"Kernel Operations on the GPU, with Autodiff, without Memory Overflows","Benjamin Charlier, Jean Feydy, Joan Alexis Glaunès, François-David Collin, Ghislain Durif","(74):1−6, 2021.  (Machine Learning Open Source Software Paper)",https://jmlr.org/papers/v22/20-275.html,https://jmlr.org/papers/volume22/20-275/20-275.pdf,https://jmlr.org/papers/v22/20-275.bib,https://github.com/getkeops/keops/,,,,"The KeOps library provides a fast and memory-efficient GPU support for tensors whose entries are given by a mathematical formula, such as kernel and distance matrices. KeOps alleviates the main bottleneck of tensor-centric libraries for kernel and geometric applications: memory consumption. It also supports automatic differentiation and outperforms standard GPU baselines, including PyTorch CUDA tensors or the Halide and TVM libraries. KeOps combines optimized C++/CUDA schemes with binders for high-level languages: Python (Numpy and PyTorch), Matlab and GNU R. As a result, high-level “quadratic” codes can now scale up to large data sets with millions of samples processed in seconds. KeOps brings graphics-like performances for kernel methods and is freely available on standard repositories (PyPi, CRAN). To showcase its versatility, we provide tutorials in a wide range of settings online at www.kernel-operations.io.",C++; Differentiation; Graphics Processing Unit (GPU); MATLAB; NumPy; PyPI; PyTorch; Python; Scheme,C++; MATLAB; Python Programming
75,Attention is Turing-Complete,"Jorge Pérez, Pablo Barceló, Javier Marinkovic","(75):1−35, 2021.",https://jmlr.org/papers/v22/20-302.html,https://jmlr.org/papers/volume22/20-302/20-302.pdf,https://jmlr.org/papers/v22/20-302.bib,,,,,"Alternatives to recurrent neural networks, in particular, architectures based on self-attention,  are gaining momentum for processing input sequences. In spite of their relevance, the computational properties of such networks have not yet been fully explored.We study the computational power of the Transformer, one of the most paradigmatic architectures exemplifying self-attention. We show that the Transformer with hard-attention is Turing complete exclusively based on their capacity to compute and access internal dense representations of the data.Our study also reveals some minimal sets of elements needed to obtain this completeness result.",Architecture; Microsoft Access; Processing; Recurrent Neural Network (RNN); Sequence; Sprite; Transformer,
76,Analyzing the discrepancy principle for kernelized spectral filter learning algorithms,"Alain Celisse, Martin Wahl","(76):1−59, 2021.",https://jmlr.org/papers/v22/20-358.html,https://jmlr.org/papers/volume22/20-358/20-358.pdf,https://jmlr.org/papers/v22/20-358.bib,,,,,"We investigate the construction of early stopping rules in the nonparametric regression problem where iterative learning algorithms are used and the optimal iteration number is unknown. More precisely, we study the discrepancy principle, as well as modifications based on smoothed residuals, for kernelized spectral filter learning algorithms including Tikhonov regularization and gradient descent. Our main theoretical bounds are oracle inequalities established for the empirical estimation error (fixed design), and for the prediction error (random design). From these finite-sample bounds it follows that the classical discrepancy principle is statistically adaptive for slow rates occurring in the hard learning scenario, while the smoothed discrepancy principles are adaptive over ranges of faster rates (resp. higher smoothness parameters). Our approach relies on deviation inequalities for the stopping rules in the fixed design setting, combined with change-of-norm arguments to deal with the random design setting.",Algorithm; Construction; Design; Gradient Descent; Oracle; Regression,Regressions
77,ChainerRL: A Deep Reinforcement Learning Library,"Yasuhiro Fujita, Prabhat Nagarajan, Toshiki Kataoka, Takahiro Ishikawa","(77):1−14, 2021.  (Machine Learning Open Source Software Paper)",https://jmlr.org/papers/v22/20-376.html,https://jmlr.org/papers/volume22/20-376/20-376.pdf,https://jmlr.org/papers/v22/20-376.bib,https://github.com/chainer/chainerrl,,,,"In this paper, we introduce ChainerRL, an open-source deep reinforcement learning (DRL) library built using Python and the Chainer deep learning framework. ChainerRL implements a comprehensive set of DRL algorithms and techniques drawn from state-of-the-art research in the field. To foster reproducible research, and for instructional purposes, ChainerRL provides scripts that closely replicate the original papers' experimental settings and reproduce published benchmark results for several algorithms. Lastly, ChainerRL offers a visualization tool that enables the qualitative inspection of trained agents. The ChainerRL source code can be found on GitHub: https://github.com/chainer/chainerrl.",Algorithm; Data Visualization; Deep Learning; Github; Python; Reinforcement Learning; Research; Visualization,Deep Learning; Github; Python Programming; Reinforcement; Visualizations
78,POT: Python Optimal Transport,"Rémi Flamary, Nicolas Courty, Alexandre Gramfort, Mokhtar Z. Alaya, Aurélie Boisbunon, Stanislas Chambon, Laetitia Chapel, Adrien Corenflos, Kilian Fatras, Nemo Fournier, Léo Gautheron, Nathalie T.H. Gayraud, Hicham Janati, Alain Rakotomamonjy, Ievgen Redko, Antoine Rolet, Antony Schutz, Vivien Seguy, Danica J. Sutherland, Romain Tavenard, Alexander Tong, Titouan Vayer","(78):1−8, 2021.  (Machine Learning Open Source Software Paper)",https://jmlr.org/papers/v22/20-451.html,https://jmlr.org/papers/volume22/20-451/20-451.pdf,https://jmlr.org/papers/v22/20-451.bib,https://github.com/PythonOT/POT,,,,"Optimal  transport  has  recently  been  reintroduced  to  the  machine  learning  community thanks in part to novel efficient optimization procedures allowing for medium to large scale applications.  We propose a Python toolbox that implements several key optimal transport ideas  for  the  machine  learning  community.   The  toolbox  contains  implementations  of  a number  of  founding  works  of  OT  for  machine  learning  such  as  Sinkhorn  algorithm  and Wasserstein barycenters, but also provides generic solvers that can be used for conducting novel fundamental research.  This toolbox, named POT for Python Optimal Transport, is open source with an MIT license.",Algorithm; Machine Learning; Medium; Python; Research,Python Programming
79,"Is SGD a Bayesian sampler? Well, almost","Chris Mingard, Guillermo Valle-Pérez, Joar Skalse, Ard A. Louis","(79):1−64, 2021.",https://jmlr.org/papers/v22/20-676.html,https://jmlr.org/papers/volume22/20-676/20-676.pdf,https://jmlr.org/papers/v22/20-676.bib,,,,,"Deep neural networks (DNNs) generalise remarkably well in the overparameterised regime, suggesting a strong inductive bias towards functions with low generalisation error. We empirically investigate this bias by calculating, for a range of architectures and datasets, the probability $P_{SGD}(f\mid S)$ that an overparameterised DNN, trained with stochastic gradient descent (SGD) or one of its variants, converges on a function $f$ consistent with a training set $S$. We also use Gaussian processes to estimate the Bayesian posterior probability $P_{B}(f\mid S)$ that the DNN expresses $f$ upon random sampling of its parameters, conditioned on $S$. Our main findings are that $P_{SGD}(f\mid S)$ correlates remarkably well with $P_{B}(f\mid S)$ and that $P_{B}(f\mid S)$ is strongly biased towards low-error and low complexity functions. These results imply that strong inductive bias in the parameter-function map (which determines $P_{B}(f\mid S)$), rather than a special property of SGD, is the primary explanation for why DNNs generalise so well in the overparameterised regime. While our results suggest that the Bayesian posterior $P_{B}(f\mid S)$ is the first order determinant of $P_{SGD}(f\mid S)$, there remain second order differences that are sensitive to hyperparameter tuning. A function probability picture, based on $P_{SGD}(f\mid S)$ and/or $P_{B}(f\mid S)$, can shed light on the way that variations in architecture or hyperparameter settings such as batch size, learning rate, and optimiser choice, affect DNN performance.",Architecture; Bayesian; Complexity; Dataset; Gaussian Process; Gradient Descent; Neural Network; Probability; Property; Sampling; Training,
80,"Communication-Efficient Distributed Covariance Sketch, with Application to Distributed PCA","Zengfeng Huang, Xuemin Lin, Wenjie Zhang, Ying Zhang","(80):1−38, 2021.",https://jmlr.org/papers/v22/20-705.html,https://jmlr.org/papers/volume22/20-705/20-705.pdf,https://jmlr.org/papers/v22/20-705.bib,,,,,"A sketch of a large data set captures vital properties of the original data while typically occupying much less space. In this paper, we consider the problem of computing a sketch of a massive data  matrix $A\in\mathbb{R}^{n\times d}$ that is distributed across $s$ machines.   Our goal is to output a matrix $B\in\mathbb{R}^{\ell\times d}$ which is significantly smaller than but still approximates $A$ well in terms of {covariance error}, i.e., $\|{A^TA-B^TB}\|_2$. Such a matrix $B$ is called a covariance sketch of $A$.  We are mainly focused on minimizing the communication cost, which is arguably the most valuable resource in distributed computations. We show that there is a nontrivial gap between deterministic and randomized communication complexity for computing a covariance sketch. More specifically, we first prove an almost tight deterministic communication lower bound, then provide a new randomized algorithm with communication cost smaller than the deterministic lower bound.   Based on a well-known connection between covariance sketch and approximate principle component analysis, we obtain better communication bounds for the distributed PCA problem. Moreover, we also give an improved distributed PCA algorithm for sparse input matrices, which uses our distributed sketching algorithm as a key building block.",Algorithm; Communication; Complexity; Covariance; LeSS; Principal Component Analysis (PCA); Sketch; Soft Computing,
81,Knowing what You Know: valid and validated confidence sets in multiclass and multilabel prediction,"Maxime Cauchois, Suyash Gupta, John C. Duchi","(81):1−42, 2021.",https://jmlr.org/papers/v22/20-753.html,https://jmlr.org/papers/volume22/20-753/20-753.pdf,https://jmlr.org/papers/v22/20-753.bib,,,,,"We develop conformal prediction methods for constructing valid predictive  confidence sets in multiclass and multilabel problems without assumptions on the data generating distribution. A challenge here is that typical conformal prediction methods---which give marginal validity (coverage) guarantees---provide uneven coverage, in that they address easy examples at the expense of essentially ignoring difficult examples.  By leveraging ideas from quantile regression, we build methods that always guarantee correct coverage but additionally provide (asymptotically consistent) conditional coverage for both multiclass and multilabel prediction problems. To address the potential challenge of exponentially large confidence sets in multilabel prediction, we build tree-structured classifiers that efficiently account for interactions between labels.  Our methods can be bolted on top of any classification model---neural network, random forest, boosted tree---to guarantee its validity.  We also provide an empirical evaluation, simultaneously providing new validation methods, that suggests the more robust coverage of our confidence sets.",Classification; Construction; Neural Network; Random Forest; Regression; Tree,Regressions
82,PyKEEN 1.0: A Python Library for Training and Evaluating Knowledge Graph Embeddings,"Mehdi Ali, Max Berrendorf, Charles Tapley Hoyt, Laurent Vermue, Sahand Sharifzadeh, Volker Tresp, Jens Lehmann","(82):1−6, 2021.",https://jmlr.org/papers/v22/20-825.html,https://jmlr.org/papers/volume22/20-825/20-825.pdf,https://jmlr.org/papers/v22/20-825.bib,,,,,"Recently, knowledge graph embeddings (KGEs) have received significant attention, and several software libraries have been developed for training and evaluation. While each of them addresses specific needs, we report on a  community effort to a re-design and re-implementation of  PyKEEN, one of the early KGE libraries.  PyKEEN 1.0 enables users to compose knowledge graph embedding models based on a wide range of interaction models, training approaches, loss functions, and permits the explicit modeling of inverse relations. It allows users to measure each component's influence individually on the model's performance. Besides, an automatic memory optimization has been realized in order to optimally exploit the provided hardware. Through the integration of Optuna, extensive hyper-parameter optimization (HPO) functionalities are provided.",Design; Exploit; Graph; Hardware; Modelling; Python; Training,Python Programming
83,Statistical Query Lower Bounds for Tensor PCA,"Rishabh Dudeja, Daniel Hsu","(83):1−51, 2021.",https://jmlr.org/papers/v22/20-837.html,https://jmlr.org/papers/volume22/20-837/20-837.pdf,https://jmlr.org/papers/v22/20-837.bib,,,,,"In the Tensor PCA problem introduced by Richard and Montanari (2014), one is given a dataset consisting of $n$ samples $\mathbf{T}_{1:n}$ of i.i.d. Gaussian tensors of order $k$ with the promise that $\mathbb{E}\mathbf{T}_1$ is a rank-1 tensor and $\|\mathbb{E} \mathbf{T}_1\| = 1$. The goal is to estimate $\mathbb{E} \mathbf{T}_1$. This problem exhibits a large conjectured hard phase when $k>2$: When $d \lesssim n \ll d^{\frac{k}{2}}$ it is information theoretically possible to estimate $\mathbb{E} \mathbf{T}_1$, but no polynomial time estimator is known. We provide a sharp analysis of the optimal sample complexity in the Statistical Query (SQ) model and show that SQ algorithms with polynomial query complexity not only fail to solve Tensor PCA in the conjectured hard phase, but also have a strictly sub-optimal sample complexity compared to some polynomial time estimators such as the Richard-Montanari spectral estimator. Our analysis reveals that the optimal sample complexity in the SQ model depends on whether $\mathbb{E} \mathbf{T}_1$ is symmetric or not. For symmetric, even order tensors, we also isolate a sample size regime in which it is possible to test if $\mathbb{E} \mathbf{T}_1 = \mathbf{0}$ or $\mathbb{E}\mathbf{T}_1 \neq \mathbf{0}$ with polynomially many queries but not estimate $\mathbb{E}\mathbf{T}_1$. Our proofs rely on the Fourier analytic approach of Feldman, Perkins and Vempala (2018) to prove sharp SQ lower bounds.",Algorithm; Analytical; Complexity; Dataset; Principal Component Analysis (PCA); jQuery,
84,Variance Reduced Median-of-Means Estimator for Byzantine-Robust Distributed Inference,"Jiyuan Tu, Weidong Liu, Xiaojun Mao, Xi Chen","(84):1−67, 2021.",https://jmlr.org/papers/v22/20-950.html,https://jmlr.org/papers/volume22/20-950/20-950.pdf,https://jmlr.org/papers/v22/20-950.bib,,,,,"This paper develops an efficient distributed inference algorithm,  which is robust against a moderate fraction of Byzantine nodes, namely arbitrary and possibly adversarial machines in a distributed learning system. In robust statistics, the median-of-means (MOM) has been a popular approach to hedge against Byzantine failures due to its ease of implementation and computational efficiency. However, the MOM estimator has the shortcoming in terms of statistical efficiency. The first main contribution of the paper is to propose a variance reduced median-of-means (VRMOM) estimator, which improves the statistical efficiency over the vanilla MOM estimator and is computationally as efficient as the MOM. Based on the proposed VRMOM estimator, we develop a general distributed inference algorithm that is robust against Byzantine failures.  Theoretically, our distributed algorithm achieves a fast convergence rate with only a constant number of rounds of communications. We also provide the asymptotic normality result for the purpose of statistical inference. To the best of our knowledge, this is the first normality result in the setting of Byzantine-robust distributed learning. The simulation results are also presented to illustrate the effectiveness of our method.",Algorithm; Communication; Fraction; Inference; Media; Statistics,Statistics
85,Gradient Methods Never Overfit On Separable Data,Ohad Shamir,"(85):1−20, 2021.",https://jmlr.org/papers/v22/20-997.html,https://jmlr.org/papers/volume22/20-997/20-997.pdf,https://jmlr.org/papers/v22/20-997.bib,,,,,"A line of recent works established that when training linear predictors over separable data, using gradient methods and exponentially-tailed losses, the predictors asymptotically converge in direction to the max-margin predictor. As a consequence, the predictors asymptotically do not overfit. However, this does not address the question of whether overfitting might occur non-asymptotically, after some bounded number of iterations. In this paper, we formally show that standard gradient methods (in particular, gradient flow, gradient descent and stochastic gradient descent) *never* overfit on separable data: If we run these methods for $T$ iterations on a dataset of size $m$, both the empirical risk and the generalization error decrease at an essentially optimal rate of $\tilde{\mathcal{O}}(1/\gamma^2 T)$ up till $T\approx m$, at which point the generalization error remains fixed at an essentially optimal level of $\tilde{\mathcal{O}}(1/\gamma^2 m)$ regardless of how large $T$ is. Along the way, we present non-asymptotic bounds on the number of margin violations over the dataset, and prove their tightness.",Dataset; Gradient Descent; Overfitting; Training,
86,Multi-view Learning as a Nonparametric Nonlinear Inter-Battery Factor Analysis,"Andreas Damianou, Neil D. Lawrence, Carl Henrik Ek","(86):1−51, 2021.",https://jmlr.org/papers/v22/16-179.html,https://jmlr.org/papers/volume22/16-179/16-179.pdf,https://jmlr.org/papers/v22/16-179.bib,,,,,"Factor analysis aims to determine latent factors, or traits, which summarize a given data set. Inter-battery factor analysis extends this notion to multiple views of the data. In this paper we show how a nonlinear, nonparametric version of these models can be recovered through the Gaussian process latent variable model. This gives us a flexible formalism for multi-view learning where the latent variables can be used both for exploratory purposes and for learning representations that enable efficient inference for ambiguous estimation tasks. Learning is performed in a Bayesian manner through the formulation of a variational compression scheme which gives a rigorous lower bound on the log likelihood. Our Bayesian framework provides strong regularization during training, allowing the structure of the latent space to be determined efficiently and automatically. We demonstrate this by producing the first (to our knowledge) published results of learning from dozens of views, even when data is scarce. We further show experimental results on several different types of multi-view data sets and for different kinds of tasks, including exploratory data analysis, generation, ambiguity modelling through latent priors and classification.",Bayesian; Classification; Exploratory Data Analysis; Factor Analysis; Gaussian Process; Inference; Modelling; Scheme; Training; Variable,
87,On Solving Probabilistic Linear Diophantine Equations,"Patrick Kreitzberg, Oliver Serang","(87):1−24, 2021.",https://jmlr.org/papers/v22/17-474.html,https://jmlr.org/papers/volume22/17-474/17-474.pdf,https://jmlr.org/papers/v22/17-474.bib,https://bitbucket.org/orserang/evergreenforest,,,,"Multiple methods exist for computing marginals involving a linear Diophantine constraint on random variables. Each of these extant methods has some limitation on the dimension and support or on the type of marginal computed (e.g., sum-product inference, max-product inference, maximum a posteriori, etc.). Here, we introduce the ""trimmed $p$-convolution tree'"" an approach that generalizes the applicability of the existing methods and achieves a runtime within a $\log$-factor or better compared to the best existing methods. A second form of trimming we call underflow/overflow trimming is introduced which aggregates events which land outside the supports for a random variable into the nearest support. Trimmed $p$-convolution trees with and without underflow/overflow trimming are used in different protein inference models. Then two different methods of approximating max-convolution using Cartesian product trees are introduced.",Approximation; Computing; Inference; Random Variable,
88,Edge Sampling Using Local Network Information,Can M. Le,"(88):1−29, 2021.",https://jmlr.org/papers/v22/18-240.html,https://jmlr.org/papers/volume22/18-240/18-240.pdf,https://jmlr.org/papers/v22/18-240.bib,,,,,"Edge sampling is an important topic in network analysis. It provides a natural way to reduce network size while retaining desired features of the original network. Sampling methods that only use local information are common in practice as they do not require access to the entire network and can be easily parallelized. Despite promising empirical performances, most of these methods are derived from heuristic considerations and lack theoretical justification. In this paper, we study a simple and efficient edge sampling method that uses local network information. We show that when the local connectivity is sufficiently strong, the sampled network satisfies a strong spectral property. We measure the strength of local connectivity by a global parameter and relate it to more common network statistics such as the clustering coefficient and network curvature. Based on this result, we also provide sufficient conditions under which random networks and hypergraphs can be efficiently sampled.",Clustering; Curvature; Microsoft Access; Network Analysis; Property; Sampling; Statistics,Statistics
89,Bayesian Text Classification and Summarization via A Class-Specified Topic Model,"Feifei Wang, Junni L. Zhang, Yichao Li, Ke Deng, Jun S. Liu","(89):1−48, 2021.",https://jmlr.org/papers/v22/18-332.html,https://jmlr.org/papers/volume22/18-332/18-332.pdf,https://jmlr.org/papers/v22/18-332.bib,,,,,"We propose the class-specified topic model (CSTM) to deal with the tasks of text classification and class-specific text summarization. The model assumes that in addition to a set of latent topics that are shared across classes, there is a set of class-specific latent topics for each class.  Each document is a probabilistic mixture of the class-specific topics associated with its class and the shared topics. Each class-specific or shared topic has its own probability distribution over a given dictionary. We develop a Bayesian inference of CSTM in the semisupervised scenario, with the supervised scenario as a special case. We analyze in detail the 20 Newsgroups dataset, a benchmark dataset for text classification, and demonstrate that CSTM has better performance than a two stage approach based on latent Dirichlet allocation (LDA), several existing supervised extensions of LDA, and an $L^1$ penalized logistic regression. The favorable performance of CSTM is also demonstrated through Monte Carlo simulations and an analysis of the Reuters dataset.",Bayesian Inference; Classification; Dataset; Dictionary; Latent Dirichlet Allocation (LDA); Linear Discriminant Analysis (LDA); Logistic Regression; Logistics; Probability Distribution; Regression,Regressions
90,Risk Bounds for Unsupervised Cross-Domain Mapping with IPMs,"Tomer Galanti, Sagie Benaim, Lior Wolf","(90):1−42, 2021.",https://jmlr.org/papers/v22/18-489.html,https://jmlr.org/papers/volume22/18-489/18-489.pdf,https://jmlr.org/papers/v22/18-489.bib,https://github.com/TomerGalanti/RiskBoundsCrossDomain,,,,"The recent empirical success of unsupervised cross-domain mapping algorithms, in mapping between two domains that share common characteristics, is not well-supported by theoretical justifications. This lacuna is especially troubling, given the clear ambiguity in such mappings. We work with adversarial training methods based on integral probability metrics (IPMs) and derive a novel risk bound, which upper bounds the risk between the learned mapping $h$ and the target mapping $y$, by a sum of three terms: (i) the risk between $h$ and the most distant alternative mapping that was learned by the same cross-domain mapping algorithm, (ii) the minimal discrepancy between the target domain and the domain obtained by applying a hypothesis $h^*$ on the samples of the source domain, where $h^*$ is a hypothesis selectable by the same algorithm, and (iii) an approximation error term that decreases as the capacity of the class of discriminators increases and is empirically shown to be small. The bound is directly related to Occam's razor and encourages the selection of the minimal architecture that supports a small mapping discrepancy. The bound leads to multiple algorithmic consequences, including a method for hyperparameter selection and early stopping in cross-domain mapping.",Algorithm; Approximation; Architecture; Mapping; Probability; Selection; Training,
91,Analysis of high-dimensional Continuous Time Markov Chains using the Local Bouncy Particle Sampler,"Tingting Zhao, Alexandre Bouchard-Côté","(91):1−41, 2021.",https://jmlr.org/papers/v22/18-651.html,https://jmlr.org/papers/volume22/18-651/18-651.pdf,https://jmlr.org/papers/v22/18-651.bib,https://github.com/zhaottcrystal/rejfreePy_main,,,,"Sampling the parameters of high-dimensional Continuous Time Markov Chains (CTMC) is a challenging problem with important applications in many fields of applied statistics. In this work a recently proposed type of non-reversible rejection-free Markov Chain Monte Carlo (MCMC) sampler, the Bouncy Particle Sampler (BPS), is brought to bear to this problem. BPS has demonstrated its favourable computational efficiency compared with state-of-the-art MCMC algorithms, however to date applications to real-data scenario were scarce. An important aspect of practical implementation of BPS is the simulation of event times. Default implementations use conservative thinning bounds. Such bounds can slow down the algorithm and limit the computational performance. Our paper develops an algorithm with exact analytical solution to the random event times in the context of CTMCs. Our local version of BPS algorithm takes advantage of the sparse structure in the target factor graph and we also provide a graph-theoretic tool for assessing the computational complexity of local BPS algorithms.",Algorithm; Analysis; Analytical; Applied Statistics; Complexity; Graph; Sampling,
92,NEU: A Meta-Algorithm for Universal UAP-Invariant Feature Representation,"Anastasis Kratsios, Cody Hyndman","(92):1−51, 2021.",https://jmlr.org/papers/v22/18-803.html,https://jmlr.org/papers/volume22/18-803/18-803.pdf,https://jmlr.org/papers/v22/18-803.bib,https://github.com/AnastasisKratsios/NEU_Non_Euclidean_Upgrading,,,,"Effective feature representation is key to the predictive performance of any algorithm.  This paper introduces a meta-procedure, called Non-Euclidean Upgrading (NEU), which learns feature maps that are expressive enough to embed the universal approximation property (UAP) into most model classes while only outputting feature maps that preserve any model class's UAP.  We show that NEU can learn any feature map with these two properties if that feature map is asymptotically deformable into the identity.   We also find that the feature-representations learned by NEU are always submanifolds of the feature space.   NEU's properties are derived from a new deep neural model that is universal amongst all orientation-preserving homeomorphisms on the input space.  We derive qualitative and quantitative approximation guarantees for this architecture.  We quantify the number of parameters required for this new architecture to memorize any set of input-output pairs while simultaneously fixing every point of the input space lying outside some compact set, and we quantify the size of this set as a function of our model's depth.  Moreover, we show that deep feedforward networks with most commonly used activation functions typically do not have all these properties.  NEU's performance is evaluated against competing machine learning methods on various regression and dimension reduction tasks both with financial and simulated data.",Algorithm; Approximation; Architecture; Machine Learning; Network; Presentation; Property; Regression,Presentation Skill; Regressions
93,Flexible Signal Denoising via Flexible Empirical Bayes Shrinkage,"Zhengrong Xing, Peter Carbonetto, Matthew Stephens","(93):1−28, 2021.",https://jmlr.org/papers/v22/19-042.html,https://jmlr.org/papers/volume22/19-042/19-042.pdf,https://jmlr.org/papers/v22/19-042.bib,https://www.github.com/stephenslab/smashr,,,,"Signal denoising—also known as non-parametric regression—is often performed through shrinkage estimation in a transformed (e.g., wavelet) domain; shrinkage in the transformed domain corresponds to smoothing in the original domain. A key question in such applications is how much to shrink, or, equivalently, how much to smooth. Empirical Bayes shrinkage methods provide an attractive solution to this problem; they use the data to estimate a distribution of underlying ""effects,"" hence automatically select an appropriate amount of shrinkage. However, most existing implementations of empirical Bayes shrinkage are less flexible than they could be—both in their assumptions on the underlying distribution of effects, and in their ability to handle heteroskedasticity—which limits their signal denoising applications. Here we address this by adopting a particularly flexible, stable and computationally convenient empirical Bayes shrinkage method and applying it to several signal denoising problems. These applications include smoothing of Poisson data and heteroskedastic Gaussian data. We show through empirical comparisons that the results are competitive with other methods, including both simple thresholding rules and purpose-built empirical Bayes procedures. Our methods are implemented in the R package smashr, ""SMoothing by Adaptive SHrinkage in R,"" available at https://www.github.com/stephenslab/smashr.",Github; LeSS; R; Regression; Table; Transformer,Github; R programming; Regressions
94,Consistent Semi-Supervised Graph Regularization for High Dimensional Data,"Xiaoyi Mai, Romain Couillet","(94):1−48, 2021.",https://jmlr.org/papers/v22/19-081.html,https://jmlr.org/papers/volume22/19-081/19-081.pdf,https://jmlr.org/papers/v22/19-081.bib,,,,,"Semi-supervised Laplacian regularization, a standard graph-based approach for learning from both labelled and unlabelled data, was recently demonstrated to have an insignificant high dimensional learning efficiency with respect to unlabelled data, causing it to be outperformed by its unsupervised counterpart, spectral clustering, given sufficient unlabelled data. Following a detailed discussion on the origin of this inconsistency problem, a novel regularization approach involving centering operation is proposed as solution, supported by both theoretical analysis and empirical results.",Analysis; Graph; Spectral Clustering,
95,Histogram Transform Ensembles for Large-scale Regression,"Hanyuan Hang, Zhouchen Lin, Xiaoyu Liu, Hongwei Wen","(95):1−87, 2021.",https://jmlr.org/papers/v22/19-1004.html,https://jmlr.org/papers/volume22/19-1004/19-1004.pdf,https://jmlr.org/papers/v22/19-1004.bib,,,,,"In this paper, we propose a novel algorithm for large-scale regression problems named Histogram Transform Ensembles (HTE), composed of random rotations, stretchings, and translations. Our HTE method first implements a histogram transformed partition to the random affine mapped data, then adaptively leverages constant functions or SVMs to obtain the individual regression estimates, and eventually builds the ensemble predictor through an average strategy. First of all, in this paper, we investigate the theoretical properties of HTE when the regression function lies in the H\""{o}lder space $C^{k,\alpha}$, $k \in \mathbb{N}_0$, $\alpha \in (0,1]$. In the case that $k=0, 1$, we adopt the constant regressors and develop the na\""{i}ve histogram transforms (NHT). Within the space $C^{0,\alpha}$, although almost optimal convergence rates can be derived for both single and ensemble NHT, we fail to show the benefits of ensembles over single estimators theoretically. In contrast, in the subspace $C^{1,\alpha}$, we prove that if $d \geq 2(1+\alpha)/\alpha$, the lower bound of the convergence rates for single NHT turns out to be worse than the upper bound of the convergence rates for ensemble NHT. In the other case when $k \geq 2$, the NHT may no longer be appropriate in predicting smoother regression functions. Instead, we circumvent this issue by applying kernel histogram transforms (KHT) equipped with smoother regressors, such as support vector machines (SVMs). Accordingly, it turns out that both single and ensemble KHT  enjoy almost optimal convergence rates. Then, we validate the above theoretical results with extensive numerical experiments. On the one hand, simulations are conducted to elucidate that ensemble NHT outperforms single NHT. On the other hand, the effects of bin sizes on the accuracy of both NHT and KHT are also in accord with the theoretical analysis. Last but not least, in the real-data experiments, comparisons between the ensemble KHT, equipped with adaptive histogram transforms, and other state-of-the-art large-scale regression estimators verify the effectiveness and precision of the proposed algorithm.",Accuracy; Algorithm; Analysis; Ensemble; Histogram; Regression; Support Vector Machine (SVM); Transformer; Translation,Regressions
96,Guided Visual Exploration of Relations in Data Sets,"Kai Puolamäki, Emilia Oikarinen, Andreas Henelius","(96):1−32, 2021.",https://jmlr.org/papers/v22/19-364.html,https://jmlr.org/papers/volume22/19-364/19-364.pdf,https://jmlr.org/papers/v22/19-364.bib,https://github.com/edahelsinki/corand,,,,"Efficient explorative data analysis systems must take into account both what a user knows and wants to know. This paper proposes a principled framework for interactive visual exploration of relations in data, through views most informative given the user's current knowledge and objectives. The user can input pre-existing knowledge of relations in the data and also formulate specific exploration interests, which are then taken into account in the exploration. The idea is to steer the exploration process towards the interests of the user, instead of showing uninteresting or already known relations. The user's knowledge is modelled by a distribution over data sets parametrised by subsets of rows and columns of data, called tile constraints. We provide a computationally efficient implementation of this concept based on constrained randomisation. Furthermore, we describe a novel dimensionality reduction method for finding the views most informative to the user, which at the limit of no background knowledge and with generic objectives reduces to PCA. We show that the method is suitable for interactive use and is robust to noise, outperforms standard projection pursuit visualisation methods, and gives understandable and useful results in analysis of real-world data. We provide an open-source implementation of the framework.",Data Analysis; Dimensionality Reduction; Principal Component Analysis (PCA); Visualization,Visualizations
97,Safe Policy Iteration: A Monotonically Improving Approximate Policy Iteration Approach,"Alberto Maria Metelli, Matteo Pirotta, Daniele Calandriello, Marcello Restelli","(97):1−83, 2021.",https://jmlr.org/papers/v22/19-707.html,https://jmlr.org/papers/volume22/19-707/19-707.pdf,https://jmlr.org/papers/v22/19-707.bib,,,,,"This paper presents a study of the policy improvement step that can be usefully exploited by approximate policy-iteration algorithms. When either the policy evaluation step or the policy improvement step returns an approximated result, the sequence of policies produced by policy iteration may not be monotonically increasing, and oscillations may occur. To address this issue, we consider safe policy improvements, i.e., at each iteration, we search for a policy that maximizes a lower bound to the policy improvement w.r.t. the current policy, until no improving policy can be found. We propose three safe policy-iteration schemas that differ in the way the next policy is chosen w.r.t. the estimated greedy policy. Besides being theoretically derived and discussed, the proposed algorithms are empirically evaluated and compared on some chain-walk domains, the prison domain, and on the Blackjack card game.",Algorithm; R; Sequence,R programming
98,"On the Theory of Policy Gradient Methods: Optimality, Approximation, and Distribution Shift","Alekh Agarwal, Sham M. Kakade, Jason D. Lee, Gaurav Mahajan","(98):1−76, 2021.",https://jmlr.org/papers/v22/19-736.html,https://jmlr.org/papers/volume22/19-736/19-736.pdf,https://jmlr.org/papers/v22/19-736.bib,,,,,"Policy gradient methods are among the most effective methods in challenging reinforcement learning problems with large state and/or action spaces. However, little is known about even their most basic theoretical convergence properties, including: if and how fast they converge to a globally optimal solution or how they cope with approximation error due to using a restricted class of parametric policies. This work provides provable characterizations of the computational, approximation, and sample size properties of policy gradient methods in the context of discounted Markov Decision Processes (MDPs). We focus on both: ""tabular"" policy parameterizations, where the optimal policy is contained in the class and where we show global convergence to the optimal policy; and parametric policy classes (considering both log-linear and neural policy classes), which may not contain the optimal policy and where we provide agnostic learning results. One central contribution of this work is in providing approximation guarantees that are average case --- which avoid explicit worst-case dependencies on the size of state space --- by making a formal connection to supervised learning under distribution shift. This characterization shows an important interplay between estimation error, approximation error, and exploration (as characterized through a precisely defined condition number).",Approximation; Decision Process; Reinforcement Learning; Supervised Learning; Unsupervised Learning,Reinforcement
99,Adaptive estimation of nonparametric functionals,"Lin Liu, Rajarshi Mukherjee, James M. Robins, Eric Tchetgen Tchetgen","(99):1−66, 2021.",https://jmlr.org/papers/v22/19-892.html,https://jmlr.org/papers/volume22/19-892/19-892.pdf,https://jmlr.org/papers/v22/19-892.bib,,,,,We provide general adaptive upper bounds for estimating nonparametric functionals based on second-order U-statistics arising from finite-dimensional approximation of the infinite-dimensional models. We then provide examples of functionals for which the theory produces rate optimally matching adaptive upper and lower bounds. Our results are automatically adaptive in both parametric and nonparametric regimes of estimation and are automatically adaptive and semiparametric efficient in the regime of parametric convergence rate.,Approximation; Statistics,Statistics
100,OpenML-Python: an extensible Python API for OpenML,"Matthias Feurer, Jan N. van Rijn, Arlind Kadra, Pieter Gijsbers, Neeratyoy Mallik, Sahithya Ravi, Andreas Müller, Joaquin Vanschoren, Frank Hutter","(100):1−5, 2021.  (Machine Learning Open Source Software Paper)",https://jmlr.org/papers/v22/19-920.html,https://jmlr.org/papers/volume22/19-920/19-920.pdf,https://jmlr.org/papers/v22/19-920.bib,https://github.com/openml/openml-python/,,,,"OpenML is an online platform for open science collaboration in machine learning, used to share datasets and results of machine learning experiments. In this paper, we introduce OpenML-Python, a client API for Python, which opens up the OpenML platform for a wide range of Python-based machine learning tools. It provides easy access to all datasets, tasks and experiments on OpenML from within Python. It also provides functionality to conduct machine learning experiments, upload the results to OpenML, and reproduce results which are stored on OpenML. Furthermore, it comes with a scikit-learn extension and an extension mechanism to easily integrate other machine learning libraries written in Python into the OpenML ecosystem. Source code and documentation are available at https://github.com/openml/openml-python/.",Application Programming Interface (API); Collaboration; Dataset; Documentation; Github; Machine Learning; Microsoft Access; Platform; Python; Scikit-learn,Github; Python Programming
101,LocalGAN: Modeling Local Distributions for Adversarial Response Generation,"Baoxun Wang, Zhen Xu, Huan Zhang, Kexin Qiu, Deyuan Zhang, Chengjie Sun","(101):1−29, 2021.",https://jmlr.org/papers/v22/20-052.html,https://jmlr.org/papers/volume22/20-052/20-052.pdf,https://jmlr.org/papers/v22/20-052.bib,https://github.com/dreasysnail/converse_GAN,,,,"This paper presents a new methodology for modeling the local semantic distribution of responses to a given query in the human-conversation corpus, and on this basis, explores a specified adversarial learning mechanism for training Neural Response Generation (NRG) models to build conversational agents. Our investigation begins with the thorough discus- sions upon the objective function of general Generative Adversarial Nets (GAN) architectures, and the training instability problem is proved to be highly relative with the special local distributions of conversational corpora. Consequently, an energy function is employed to estimate the status of a local area restricted by the query and its responses in the semantic space, and the mathematical approximation of this energy-based distribution is finally found. Building on this foundation, a local distribution oriented objective is proposed and combined with the original objective, working as a hybrid loss for the adversarial training of response generation models, named as LocalGAN. Our experimental results demonstrate that the reasonable local distribution modeling of the query-response corpus is of great importance to adversarial NRG, and our proposed LocalGAN is promising for improving both the training stability and the quality of generated results.",Approximation; Architecture; Generative Adversarial Network (GAN); Methodology; Modelling; Objective-C; Semantics; Training; jQuery,
102,Learning a High-dimensional Linear Structural Equation Model via l1-Regularized Regression,"Gunwoong Park, Sang Jun Moon, Sion Park, Jong-June Jeon","(102):1−41, 2021.",https://jmlr.org/papers/v22/20-1005.html,https://jmlr.org/papers/volume22/20-1005/20-1005.pdf,https://jmlr.org/papers/v22/20-1005.bib,,,,,"This paper develops a new approach to learning high-dimensional linear structural equation models (SEMs) without the commonly assumed faithfulness, Gaussian error distribution, and equal error distribution conditions. A key component of the algorithm is component-wise ordering and parent estimations, where both problems can be efficiently addressed using l1-regularized regression. This paper proves that sample sizes n = Omega( d^{2} \log p) and n = \Omega( d^2 p^{2/m} ) are sufficient for the proposed algorithm to recover linear SEMs with sub-Gaussian and (4m)-th bounded-moment error distributions, respectively, where p is the number of nodes and d is the maximum degree of the moralized graph. Further shown is the worst-case computational complexity O(n (p^3 + p^2 d^2 ) ), and hence, the proposed algorithm is statistically consistent and computationally feasible for learning a high-dimensional linear SEM when its moralized graph is sparse.	Through simulations, we verify that the proposed algorithm is statistically consistent and computationally feasible, and it performs well compared to the state-of-the-art US, GDS, LISTEN and TD algorithms with our settings. We also demonstrate through real COVID-19 data that the proposed algorithm is well-suited to estimating a virus-spread map in China.",Algorithm; Computational Complexity Theory; Graph; Regression; Search Engine Marketing (SEM); Temporal Difference (TD) Learning,Regressions
103,A Unified Analysis of First-Order Methods for Smooth Games via Integral Quadratic Constraints,"Guodong Zhang, Xuchan Bao, Laurent Lessard, Roger Grosse","(103):1−39, 2021.",https://jmlr.org/papers/v22/20-1068.html,https://jmlr.org/papers/volume22/20-1068/20-1068.pdf,https://jmlr.org/papers/v22/20-1068.bib,https://github.com/gd-zhang/IQC-Game,,,,"The theory of integral quadratic constraints (IQCs) allows the certification of exponential convergence of interconnected systems containing nonlinear or uncertain elements. In this work, we adapt the IQC theory to study first-order methods for smooth and strongly-monotone games and show how to design tailored quadratic constraints to get tight upper bounds of convergence rates. Using this framework, we recover the existing bound for the gradient method~(GD), derive sharper bounds for the proximal point method~(PPM) and optimistic gradient method~(OG), and provide for the first time a global convergence rate for the negative momentum method~(NM) with an iteration complexity $\mathcal{O}(\kappa^{1.5})$, which matches its known lower bound. In addition, for time-varying systems, we prove that the gradient method with optimal step size achieves the fastest provable worst-case convergence rate with quadratic Lyapunov functions. Finally, we further extend our analysis to stochastic games and study the impact of multiplicative noise on different algorithms. We show that it is impossible for an algorithm with one step of memory to achieve acceleration if it only queries the gradient once per batch (in contrast with the stochastic strongly-convex optimization setting, where such acceleration has been demonstrated). However, we exhibit an algorithm which achieves acceleration with two gradient queries per batch.",Algorithm; Analysis; Complexity; Design; Uncertainty,
104,Explaining Explanations: Axiomatic Feature Interactions for Deep Networks,"Joseph D. Janizek, Pascal Sturmfels, Su-In Lee","(104):1−54, 2021.",https://jmlr.org/papers/v22/20-1223.html,https://jmlr.org/papers/volume22/20-1223/20-1223.pdf,https://jmlr.org/papers/v22/20-1223.bib,https://github.com/suinleelab/path_explain,,,,"Recent work has shown great promise in explaining neural network behavior. In particular, feature attribution methods explain the features that are important to a model's prediction on a given input. However, for many tasks, simply identifying significant features may be insufficient for understanding model behavior. The interactions between features within the model may better explain not only the model, but why certain features outrank others in importance. In this work, we present Integrated Hessians, an extension of Integrated Gradients that explains pairwise feature interactions in neural networks. Integrated Hessians overcomes several theoretical limitations of previous methods, and unlike them, is not limited to a specific architecture or class of neural network. Additionally, we find that our method is faster than existing methods when the number of features is large, and outperforms previous methods on existing quantitative benchmarks.",Architecture; Neural Network,
105,Pathwise Conditioning of Gaussian Processes,"James T. Wilson, Viacheslav Borovitskiy, Alexander Terenin, Peter Mostowsky, Marc Peter Deisenroth","(105):1−47, 2021.",https://jmlr.org/papers/v22/20-1260.html,https://jmlr.org/papers/volume22/20-1260/20-1260.pdf,https://jmlr.org/papers/v22/20-1260.bib,https://github.com/j-wilson/GPflowSampling,,,,"As Gaussian processes are used to answer increasingly complex questions, analytic solutions become scarcer and scarcer. Monte Carlo methods act as a convenient bridge for connecting intractable mathematical expressions with actionable estimates via sampling. Conventional approaches for simulating Gaussian process posteriors view samples as draws from marginal distributions of process values at finite sets of input locations. This distribution-centric characterization leads to generative strategies that scale cubically in the size of the desired random vector. These methods are prohibitively expensive in cases where we would, ideally, like to draw high-dimensional vectors or even continuous sample paths. In this work, we investigate a different line of reasoning: rather than focusing on distributions, we articulate Gaussian conditionals at the level of random variables. We show how this pathwise interpretation of conditioning gives rise to a general family of approximations that lend themselves to efficiently sampling Gaussian process posteriors. Starting from first principles, we derive these methods and analyze the approximation errors they introduce. We, then, ground these results by exploring the practical implications of pathwise conditioning in various applied settings, such as global optimization and reinforcement learning.",Analytical; Approximation; Gaussian Process; Monte Carlo Method; Random Variable; Reasoning; Reinforcement Learning; Sampling,Reinforcement
106,Online stochastic gradient descent on non-convex losses from high-dimensional inference,"Gerard Ben Arous, Reza Gheissari, Aukosh Jagannath","(106):1−51, 2021.",https://jmlr.org/papers/v22/20-1288.html,https://jmlr.org/papers/volume22/20-1288/20-1288.pdf,https://jmlr.org/papers/v22/20-1288.bib,,,,,"Stochastic gradient descent (SGD) is a popular algorithm for optimization problems arising in high-dimensional inference tasks. Here one produces an estimator of an unknown parameter from independent samples of data by iteratively optimizing a loss function. This loss function is random and often non-convex. We study the performance of the simplest version of SGD, namely online SGD, from a random start in the setting where the parameter space is high-dimensional. We develop nearly sharp thresholds for the number of samples needed for consistent estimation as one varies the dimension. Our thresholds depend only on an intrinsic property of the population loss which we call the information exponent. In particular, our results do not assume uniform control on the loss itself, such as convexity or uniform derivative bounds. The thresholds we obtain are polynomial in the dimension and the precise exponent depends explicitly on the information exponent. As a consequence of our results, we find that except for the simplest tasks, almost all of the data is used simply in the initial search phase to obtain non-trivial correlation with the ground truth. Upon attaining non-trivial correlation, the descent is rapid and exhibits law of large numbers type behavior. We illustrate our approach by applying it to a wide set of inference tasks such as phase retrieval, and  parameter estimation for generalized linear models, online PCA, and spiked tensor models, as well as to supervised learning for single-layer networks with general activation functions.",Algorithm; Convexity; Correlation; Derivative; Generalized Linear Model (GLM); Gradient Descent; Inference; Law; Network; Population; Principal Component Analysis (PCA); Property; Supervised Learning; Unsupervised Learning,
107,Beyond English-Centric Multilingual Machine Translation,"Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Michael Auli, Armand Joulin","(107):1−48, 2021.",https://jmlr.org/papers/v22/20-1307.html,https://jmlr.org/papers/volume22/20-1307/20-1307.pdf,https://jmlr.org/papers/v22/20-1307.bib,https://github.com/pytorch/fairseq/tree/master/examples/m2m_100,,,,"Existing work in translation demonstrated the potential of massively multilingual machine translation by training a single model able to translate between any pair of languages. However, much of this work is English-Centric, training only on data which was translated from or to English.While this is supported by large sources of training data, it does not reflect translation needs worldwide. In this work, we create a true Many-to-Many multilingual translation model that can translate directly between any pair of 100 languages. We build and open-source a training data set that covers thousands of language directions with parallel data, created through large-scale mining. Then, we explore how to effectively increase model capacity through a combination of dense scaling and language-specific sparse parameters to create high quality models. Our focus on non-English-Centric models brings gains of more than 10 BLEU when directly translating between non-English directions while performing competitively to the best single systems from the Workshop  on Machine Translation (WMT). We open-source our scripts so that others may reproduce the data, evaluation, and final M2M-100 model.",English; Machine Translation; Mining; Training,
108,Towards a Unified Analysis of Random Fourier Features,"Zhu Li, Jean-Francois Ton, Dino Oglic, Dino Sejdinovic","(108):1−51, 2021.",https://jmlr.org/papers/v22/20-1369.html,https://jmlr.org/papers/volume22/20-1369/20-1369.pdf,https://jmlr.org/papers/v22/20-1369.bib,,,,,"Random Fourier features is a widely used, simple, and effective technique for scaling up kernel methods. The existing theoretical analysis of the approach, however, remains focused on specific learning tasks and typically gives pessimistic bounds which are at odds with the empirical results. We tackle these problems and provide the first unified risk analysis of learning with random Fourier features using the squared error and Lipschitz continuous loss functions. In our bounds, the trade-off between the computational cost and the learning risk convergence rate is problem specific and expressed in terms of the regularization parameter and the number of effective degrees of freedom. We study both the standard random Fourier features method for which we improve the existing bounds on the number of features required to guarantee the corresponding minimax risk convergence rate of kernel ridge regression, as well as a data-dependent modification which samples features proportional to ridge leverage scores and further reduces the required number of features. As ridge leverage scores are expensive to compute, we devise a simple approximation scheme which provably reduces the computational cost without loss of statistical efficiency. Our empirical results illustrate the effectiveness of the proposed scheme relative to the standard random Fourier features method.",Approximation; Degree of Freedom; Regression; Ridge Regression; Risk Analysis; Scheme; Trade,Regressions
109,mvlearn: Multiview Machine Learning in Python,"Ronan Perry, Gavin Mischler, Richard Guo, Theodore Lee, Alexander Chang, Arman Koul, Cameron Franz, Hugo Richard, Iain Carmichael, Pierre Ablin, Alexandre Gramfort, Joshua T. Vogelstein","(109):1−7, 2021.  (Machine Learning Open Source Software Paper)",https://jmlr.org/papers/v22/20-1370.html,https://jmlr.org/papers/volume22/20-1370/20-1370.pdf,https://jmlr.org/papers/v22/20-1370.bib,https://github.com/mvlearn/mvlearn,,,,"As data are generated more and more from multiple disparate sources, multiview data sets, where each sample has features in distinct views, have grown in recent years. However, no comprehensive package exists that enables non-specialists to use these methods easily. mvlearn is a Python library which implements the leading multiview machine learning methods. Its simple API closely follows that of scikit-learn for increased ease-of-use. The package can be installed from Python Package Index (PyPI) and the conda package manager and is released under the MIT open-source license. The documentation, detailed examples, and all releases are available at https://mvlearn.github.io/.",Application Programming Interface (API); Conda; Documentation; Github; Machine Learning; Package Manager; PyPI; Python; Scikit-learn,Github; Python Programming
110,River: machine learning for streaming data in Python,"Jacob Montiel, Max Halford, Saulo Martiello Mastelini, Geoffrey Bolmier, Raphael Sourty, Robin Vaysse, Adil Zouitine, Heitor Murilo Gomes, Jesse Read, Talel Abdessalem, Albert Bifet","(110):1−8, 2021.  (Machine Learning Open Source Software Paper)",https://jmlr.org/papers/v22/20-1380.html,https://jmlr.org/papers/volume22/20-1380/20-1380.pdf,https://jmlr.org/papers/v22/20-1380.bib,https://github.com/online-ml/river,,,,"River is a machine learning library for dynamic data streams and continual learning. It provides multiple state-of-the-art learning methods, data generators/transformers, performance metrics and evaluators for different stream learning problems. It is the result from the merger of two popular packages for stream learning in Python: Creme and scikit-multiflow. River introduces a revamped architecture based on the lessons learnt from the seminal packages. River's ambition is to be the go-to library for doing machine learning on streaming data. Additionally, this open source package brings under the same umbrella a large community of practitioners and researchers. The source code is available at https://github.com/online-ml/river.",Architecture; Azure Machine Learning; Github; Golang; Python; Scikit-learn; Streaming; Transformer,Github; Python Programming
111,Non-parametric Quantile Regression via the K-NN Fused Lasso,"Steven Siwei Ye, Oscar Hernan Madrid Padilla","(111):1−38, 2021.",https://jmlr.org/papers/v22/20-1462.html,https://jmlr.org/papers/volume22/20-1462/20-1462.pdf,https://jmlr.org/papers/v22/20-1462.bib,https://github.com/stevenysw/qt_knnfl,,,,"Quantile regression is a statistical method for estimating conditional quantiles of a response variable. In addition, for mean estimation, it is well known that quantile regression is more robust to outliers than $l_2$-based methods. By using the fused lasso penalty over a $K$-nearest neighbors graph, we propose an adaptive quantile estimator in a non-parametric setup. We show that the estimator attains optimal rate of $n^{-1/d}$ up to a logarithmic factor, under mild assumptions on the data generation mechanism of the $d$-dimensional data. We develop algorithms to compute the estimator and discuss methodology for model selection. Numerical experiments on simulated and real data demonstrate clear advantages of the proposed estimator over state of the art methods.",Algorithm; Graph; Lasso; Methodology; Model Selection; Outliers; Regression; Variable,Regressions
112,L-SVRG and L-Katyusha with Arbitrary Sampling,"Xun Qian, Zheng Qu, Peter Richtárik","(112):1−47, 2021.",https://jmlr.org/papers/v22/20-156.html,https://jmlr.org/papers/volume22/20-156/20-156.pdf,https://jmlr.org/papers/v22/20-156.bib,,,,,"We develop and analyze a new family of nonaccelerated and accelerated loopless variance-reduced methods for finite-sum optimization problems. Our convergence analysis relies on a novel expected smoothness condition which upper bounds the variance of the stochastic gradient estimation by a constant times a distance-like function. This allows us to handle with ease arbitrary sampling schemes as well as the nonconvex case. We perform an in-depth estimation of these expected smoothness parameters and propose new importance samplings which allow linear speedup when the expected minibatch size is in a certain range. Furthermore, a connection between these expected smoothness parameters and expected separable overapproximation (ESO) is established, which allows us to exploit data sparsity as well. Our general methods and results recover as special cases the loopless SVRG and loopless Katyusha methods.",Analysis; Exploit; Sampling; Scheme,
113,A Lyapunov Analysis of Accelerated Methods in Optimization,"Ashia C. Wilson, Ben Recht, Michael I. Jordan","(113):1−34, 2021.",https://jmlr.org/papers/v22/20-195.html,https://jmlr.org/papers/volume22/20-195/20-195.pdf,https://jmlr.org/papers/v22/20-195.bib,,,,,"Accelerated optimization methods, such as Nesterov's accelerated gradient method, play a significant role in optimization. Several accelerated methods are provably optimal under standard oracle models. Such optimality results are obtained using a technique known as ""estimate sequences,"" which yields upper bounds on convergence properties.  The technique of estimate sequences has long been considered difficult to understand and deploy, leading many researchers to generate alternative, more intuitive methods and analyses. We show there is an equivalence between the technique of estimate sequences and a family of Lyapunov functions in both continuous and discrete time. This connection allows us to develop a unified analysis of many existing accelerated algorithms, introduce new algorithms, and strengthen the connection between accelerated algorithms and continuous-time dynamical systems.",Algorithm; Analysis; Oracle; Play; Sequence,
114,NUQSGD: Provably Communication-efficient Data-parallel SGD via Nonuniform Quantization,"Ali Ramezani-Kebrya, Fartash Faghri, Ilya Markov, Vitalii Aksenov, Dan Alistarh, Daniel M. Roy","(114):1−43, 2021.",https://jmlr.org/papers/v22/20-255.html,https://jmlr.org/papers/volume22/20-255/20-255.pdf,https://jmlr.org/papers/v22/20-255.bib,,,,,"As the size and complexity of models and datasets grow, so does the need for communication-efficient variants of stochastic gradient descent that can be deployed to perform parallel model training. One popular communication-compression method for data-parallel SGD is QSGD (Alistarh et al., 2017), which quantizes and encodes gradients to reduce communication costs. The baseline variant of QSGD provides strong theoretical guarantees, however, for practical purposes, the authors proposed a heuristic variant which we call QSGDinf, which demonstrated impressive empirical gains for distributed training of large neural networks. In this paper, we build on this work to propose a new gradient quantization scheme, and show that it has both stronger theoretical guarantees than QSGD, and matches and exceeds the empirical performance of the QSGDinf heuristic and of other compression methods.",Complexity; Dataset; Gradient Descent; Neural Network; Oral Communication; Scheme; Training,
115,Stochastic Proximal Methods for Non-Smooth Non-Convex Constrained Sparse Optimization,"Michael R. Metel, Akiko Takeda","(115):1−36, 2021.",https://jmlr.org/papers/v22/20-287.html,https://jmlr.org/papers/volume22/20-287/20-287.pdf,https://jmlr.org/papers/v22/20-287.bib,,,,,"This paper focuses on stochastic proximal gradient methods for optimizing a smooth non-convex loss function with a non-smooth non-convex regularizer and convex constraints. To the best of our knowledge we present the first non-asymptotic convergence bounds for this class of problem. We present two simple stochastic proximal gradient algorithms, for general stochastic and finite-sum optimization problems. In a numerical experiment we compare our algorithms with the current state-of-the-art deterministic algorithm and find our algorithms to exhibit superior convergence.",Algorithm,
116,An Importance Weighted Feature Selection Stability Measure,"Victor Hamer, Pierre Dupont","(116):1−57, 2021.",https://jmlr.org/papers/v22/20-366.html,https://jmlr.org/papers/volume22/20-366/20-366.pdf,https://jmlr.org/papers/v22/20-366.bib,,,,,"Current feature selection methods, especially applied to high dimensional data, tend to suffer from instability since marginal modifications in the data may result in largely distinct selected feature sets. Such instability strongly limits a sound interpretation of the selected variables by domain experts. Defining an adequate stability measure is also a research question. In this work, we propose to incorporate into the stability measure the importances of the selected features in predictive models. Such feature importances are directly proportional to feature weights in a linear model. We also consider the generalization to a non-linear setting. We illustrate, theoretically and experimentally, that current stability measures are subject to undesirable behaviors, for example, when they are jointly optimized with predictive accuracy. Results on micro-array and mass-spectrometric data show that our novel stability measure corrects for overly optimistic stability estimates in such a bi-objective context, which leads to improved decision-making. It is also shown to be less prone to the under- or over-estimation of the stability value in feature spaces with groups of highly correlated variables.",Accuracy; Array; Decision Making; Feature Selection; LeSS; Objective-C; Predictive Model; Research; Variable,
117,"Strong Consistency, Graph Laplacians, and the Stochastic Block Model","Shaofeng Deng, Shuyang Ling, Thomas Strohmer","(117):1−44, 2021.",https://jmlr.org/papers/v22/20-391.html,https://jmlr.org/papers/volume22/20-391/20-391.pdf,https://jmlr.org/papers/v22/20-391.bib,,,,,"Spectral clustering has become one of the most popular algorithms in data clustering and community detection. We study the performance of classical two-step spectral clustering via the graph Laplacian to learn the stochastic block model. Our aim is to answer the following question: when is spectral clustering via the graph Laplacian able to achieve strong consistency, i.e., the exact recovery of the underlying hidden communities? Our work provides an entrywise analysis (an $\ell_{\infty}$-norm perturbation bound) of the Fiedler eigenvector of both the unnormalized and the normalized Laplacian associated with the adjacency matrix sampled from the stochastic block model. We prove that spectral clustering is able to achieve exact recovery of the planted community structure under conditions that match the information-theoretic limits.",Algorithm; Analysis; Graph; Spectral Clustering,
118,A General Framework for Adversarial Label Learning,"Chidubem Arachie, Bert Huang","(118):1−33, 2021.",https://jmlr.org/papers/v22/20-537.html,https://jmlr.org/papers/volume22/20-537/20-537.pdf,https://jmlr.org/papers/v22/20-537.bib,https://github.com/VTCSML/Adversarial-Label-Learning,,,,We consider the task of training classifiers without fully labeled data. We propose a weakly supervised method---adversarial label learning---that trains classifiers to perform well when noisy and possibly correlated labels are provided. Our framework allows users to provide different weak labels and multiple constraints on these labels. Our model then attempts to learn parameters for the data by solving a zero-sum game for the binary problems and a non-zero sum game optimization for multi-class problems. The game is between an adversary that chooses labels for the data and a model that minimizes the error made by the adversarial labels. The weak supervision constrains what labels the adversary can choose. The method therefore minimizes an upper bound of the classifier's error rate using projected primal-dual subgradient descent. Minimizing this bound protects against bias and dependencies in the weak supervision. We first show the performance of our framework on binary classification tasks then we extend our algorithm to show its performance on multiclass datasets. Our experiments show that our method can train without labels and outperforms other approaches for weakly supervised learning.,Algorithm; Classification; Dataset; Gradient Descent; Supervised Learning; Training; Unsupervised Learning,
119,Some Theoretical Insights into Wasserstein GANs,"Gérard Biau, Maxime Sangnier, Ugo Tanielian","(119):1−45, 2021.",https://jmlr.org/papers/v22/20-553.html,https://jmlr.org/papers/volume22/20-553/20-553.pdf,https://jmlr.org/papers/v22/20-553.bib,,,,,"Generative Adversarial Networks (GANs) have been successful in producing outstanding results in areas as diverse as image, video, and text generation. Building on these successes, a large number of empirical studies have validated the benefits of the cousin approach called Wasserstein GANs (WGANs), which brings stabilization in the training process. In the present paper, we add a new stone to the edifice by proposing some theoretical advances in the properties of WGANs. First, we properly define the architecture of WGANs in the context of integral probability metrics parameterized by neural networks and highlight some of their basic mathematical features. We stress in particular interesting optimization properties arising from the use of a parametric 1-Lipschitz discriminator. Then, in a statistically-driven approach, we study the convergence of empirical WGANs as the sample size tends to infinity, and clarify the adversarial effects of the generator and the discriminator by underlining some trade-off properties. These features are finally illustrated with experiments using both synthetic and real-world datasets.",Architecture; Dataset; Generative Adversarial Network (GAN); Image; Neural Network; Probability; Trade; Training; Video,
120,Empirical Bayes Matrix Factorization,"Wei Wang, Matthew Stephens","(120):1−40, 2021.",https://jmlr.org/papers/v22/20-589.html,https://jmlr.org/papers/volume22/20-589/20-589.pdf,https://jmlr.org/papers/v22/20-589.bib,https://github.com/stephenslab/flashr,,,,"Matrix factorization methods, which include Factor analysis (FA) and Principal Components Analysis (PCA), are widely used for inferring and summarizing structure in multivariate data.  Many such methods use a penalty or prior distribution to achieve sparse representations (“Sparse FA/PCA""), and a key question is how much sparsity to induce. Here we introduce a general Empirical Bayes approach to matrix factorization (EBMF), whose key feature is that it estimates the appropriate amount of sparsity by estimating prior distributions from the observed data. The approach is very flexible: it allows for a wide range of different prior families and allows that each component of the matrix factorization may exhibit a different amount of sparsity. The key to this flexibility is the use of a variational approximation, which we show effectively reduces fitting the EBMF model to solving a simpler problem, the so-called “normal means"" problem.  We demonstrate the benefits of EBMF with sparse priors through both numerical comparisons with competing methods and through analysis of data from the GTEx (Genotype Tissue Expression) project on genetic associations across 44 human tissues. In numerical comparisons EBMF often provides more accurate inferences than other methods. In the GTEx data, EBMF identifies interpretable structure that agrees with known relationships among human tissues. Software implementing our approach is available at https://github.com/stephenslab/flashr.",Approximation; Factor Analysis; Github; Inference; Principal Component Analysis (PCA),Github
121,Langevin Dynamics for Adaptive Inverse Reinforcement Learning of Stochastic Gradient Algorithms,"Vikram Krishnamurthy, George Yin","(121):1−49, 2021.",https://jmlr.org/papers/v22/20-625.html,https://jmlr.org/papers/volume22/20-625/20-625.pdf,https://jmlr.org/papers/v22/20-625.bib,,,,,"Inverse reinforcement learning (IRL) aims to  estimate the reward function of optimizing agents by observing their response (estimates or actions). This paper  considers IRL  when noisy estimates of the gradient of a reward  function  generated by multiple stochastic gradient agents are observed. We  present a generalized Langevin dynamics algorithm to estimate the reward function $R(\theta)$; specifically, the resulting Langevin algorithm asymptotically generates samples from the distribution proportional to $\exp(R(\theta))$. The proposed adaptive IRL algorithms use  kernel-based passive learning schemes. We also construct multi-kernel passive Langevin algorithms for IRL which are suitable for high dimensional data. The performance of the proposed IRL algorithms are illustrated on examples in adaptive Bayesian learning, logistic regression (high dimensional problem) and constrained Markov decision processes.  We prove weak convergence of the proposed IRL algorithms using martingale averaging methods. We also analyze the tracking performance of the IRL algorithms in non-stationary environments where the utility function $R(\theta)$ has a hyper-parameter that jump changes over time as a slow Markov chain which is not known to the inverse learner. In this case, martingale averaging yields a Markov switched diffusion limit as the asymptotic behavior of the IRL algorithm.",Algorithm; Bayesian; Decision Process; Logistic Regression; Logistics; R; Regression; Reinforcement Learning; Scheme; Utility,R programming; Regressions; Reinforcement
122,Sparse Convex Optimization via Adaptively Regularized Hard Thresholding,"Kyriakos Axiotis, Maxim Sviridenko","(122):1−47, 2021.",https://jmlr.org/papers/v22/20-661.html,https://jmlr.org/papers/volume22/20-661/20-661.pdf,https://jmlr.org/papers/v22/20-661.bib,,,,,"The goal of Sparse Convex Optimization is to optimize a convex function f under a sparsity constraint s <= s* γ, where s* is the target number of non-zero entries in a feasible solution (sparsity) and γ >= 1 is an approximation factor. There has been a lot of work to analyze the sparsity guarantees of various algorithms (LASSO, Orthogonal Matching Pursuit (OMP), Iterative Hard Thresholding (IHT)) in terms of the Restricted Condition Number κ. The best known algorithms guarantee to find an approximate solution of value f(x*)+ε with the sparsity bound of γ = O(κ min{log ((f(x0)-f(x*)) / ε), κ}), where x* is the target solution. We present a new Adaptively Regularized Hard Thresholding (ARHT) algorithm that makes significant progress on this problem by bringing the bound down to γ=O(κ), which has been shown to be tight for a general class of algorithms including LASSO, OMP, and IHT. This is achieved without significant sacrifice in the runtime efficiency compared to the fastest known algorithms. We also provide a new analysis of OMP with Replacement (OMPR) for general f, under the condition s > s* κ^2 / 4, which yields compressed sensing bounds under the Restricted Isometry Property (RIP). When compared to other compressed sensing approaches, it has the advantage of providing a strong tradeoff between the RIP condition and the solution sparsity, while working for any general function f that meets the RIP condition.",Algorithm; Analysis; Approximation; Lasso; Property,
123,Convergence Guarantees for Gaussian Process Means With  Misspecified Likelihoods and Smoothness,"George Wynne, François-Xavier Briol, Mark Girolami","(123):1−40, 2021.",https://jmlr.org/papers/v22/20-662.html,https://jmlr.org/papers/volume22/20-662/20-662.pdf,https://jmlr.org/papers/v22/20-662.bib,,,,,"Gaussian processes are ubiquitous in machine learning, statistics, and applied mathematics. They provide a flexible modelling framework for approximating functions, whilst simultaneously quantifying uncertainty. However, this is only true when the model is well-specified, which is often not the case in practice. In this paper, we study the properties of Gaussian process means when the smoothness of the model and the likelihood function are misspecified. In this setting, an important theoretical question of practical relevance is how accurate the Gaussian process approximations will be given the chosen model and the extent of the misspecification. The answer to this problem is particularly useful since it can inform our choice of model and experimental design. In particular, we describe how the experimental design and choice of kernel and kernel hyperparameters can be adapted to alleviate model misspecification.",Applied Mathematics; Approximation; Design; Gaussian Process; Machine Learning; Modelling; Statistics; Uncertainty,Statistics
124,A flexible model-free prediction-based framework for feature ranking,"Jingyi Jessica Li, Yiling Elaine Chen, Xin Tong","(124):1−54, 2021.",https://jmlr.org/papers/v22/20-673.html,https://jmlr.org/papers/volume22/20-673/20-673.pdf,https://jmlr.org/papers/v22/20-673.bib,https://github.com/JSB-UCLA/frc,,,,"Despite the availability of numerous statistical and machine learning tools for joint feature modeling, many scientists investigate features marginally, i.e., one feature at a time. This is partly due to training and convention but also roots in scientists' strong interests in simple visualization and interpretability. As such, marginal feature ranking for some predictive tasks, e.g., prediction of cancer driver genes, is widely practiced in the process of scientific discoveries. In this work, we focus on marginal ranking for binary classification, one of the most common predictive tasks.  We argue that the most widely used marginal ranking criteria, including the Pearson correlation, the two-sample $t$ test, and two-sample Wilcoxon rank-sum test, do not fully take feature distributions and prediction objectives into account. To address this gap in practice, we propose two ranking criteria corresponding to two prediction objectives: the classical criterion (CC) and the Neyman-Pearson criterion (NPC), both of which use model-free nonparametric implementations to accommodate diverse feature distributions. Theoretically, we show that under regularity conditions, both criteria achieve sample-level ranking that is consistent with their population-level counterpart with high probability. Moreover, NPC is robust to sampling bias when the two class proportions in a sample deviate from those in the population. This property endows NPC good potential in biomedical research where sampling biases are ubiquitous. We demonstrate the use and relative advantages of CC and NPC in simulation and real data studies. Our model-free objective-based ranking idea is extendable to ranking feature subsets and generalizable to other prediction tasks and learning objectives.",Classification; Correlation; Machine Learning; Modelling; Objective-C; Population; Probability; Property; Research; Sampling; Training; Visualization,Visualizations
125,Bandit Convex Optimization in Non-stationary Environments,"Peng Zhao, Guanghui Wang, Lijun Zhang, Zhi-Hua Zhou","(125):1−45, 2021.",https://jmlr.org/papers/v22/20-763.html,https://jmlr.org/papers/volume22/20-763/20-763.pdf,https://jmlr.org/papers/v22/20-763.bib,,,,,"Bandit Convex Optimization (BCO) is a fundamental framework for modeling sequential decision-making with partial information, where the only feedback available to the player is the one-point or two-point function values. In this paper, we investigate BCO in non-stationary environments and choose the dynamic regret as the performance measure, which is defined as the difference between the cumulative loss incurred by the algorithm and that of any feasible comparator sequence. Let $T$ be the time horizon and $P_T$ be the path-length of the comparator sequence that reflects the non-stationarity of environments. We propose a novel algorithm that achieves $O(T^{3/4}(1+P_T)^{1/2})$ and $O(T^{1/2}(1+P_T)^{1/2})$ dynamic regret respectively for the one-point and two-point feedback models. The latter result is optimal, matching the $\Omega(T^{1/2}(1+P_T)^{1/2})$ lower bound established in this paper. Notably, our algorithm is  adaptive to the non-stationary environments since it does not require prior knowledge of the path-length $P_T$ ahead of time, which is generally unknown. We further extend the algorithm to an anytime version that does not require to know the time horizon $T$ in advance. Moreover, we study the adaptive regret, another widely used performance measure for online learning in non-stationary environments, and design an algorithm that provably enjoys the adaptive regret guarantees for BCO problems. Finally, we present empirical studies to validate the effectiveness of the proposed approach.",Ad Design; Algorithm; Decision Making; Modelling; Sequence; Sequential Decision,
126,Integrative High Dimensional Multiple Testing with Heterogeneity under Data Sharing Constraints,"Molei Liu, Yin Xia, Kelly Cho, Tianxi Cai","(126):1−26, 2021.",https://jmlr.org/papers/v22/20-774.html,https://jmlr.org/papers/volume22/20-774/20-774.pdf,https://jmlr.org/papers/v22/20-774.bib,,,,,"Identifying informative predictors in a high-dimensional regression model is a critical step for association analysis and predictive modeling. Signal detection in the high dimensional setting often fails due to the limited sample size. One approach to improving power is through meta-analyzing multiple studies which address the same scientific question. However, integrative analysis of high dimensional data from multiple studies is challenging in the presence of between-study heterogeneity. The challenge is even more pronounced with additional data sharing constraints under which only summary data can be shared across different sites. In this paper, we propose a novel data shielding integrative large--scale testing (DSILT) approach to signal detection allowing between-study heterogeneity and not requiring the sharing of individual-level data. Assuming the underlying high dimensional regression models of the data differ across studies yet share similar support, the proposed method incorporates proper integrative estimation and debiasing procedures to construct test statistics for the overall effects of specific covariates. We also develop a multiple testing procedure to identify significant effects while controlling the false discovery rate (FDR) and false discovery proportion (FDP). Theoretical comparisons of the new testing procedure with the ideal individual-level meta-analysis (ILMA) approach and other distributed inference methods are investigated. Simulation studies demonstrate that the proposed testing procedure performs well in both controlling false discovery and attaining power. The new method is applied to a real example detecting interaction effects of the genetic variants for statins and obesity on the risk for type II diabetes.",Analysis; Data Sharing; Inference; Predictive Model; Predictive Modelling; Regression; Statistics; TestNG; Testing,Regressions; Statistics
127,LassoNet: A Neural Network with Feature Sparsity,"Ismael Lemhadri, Feng Ruan, Louis Abraham, Robert Tibshirani","(127):1−29, 2021.",https://jmlr.org/papers/v22/20-848.html,https://jmlr.org/papers/volume22/20-848/20-848.pdf,https://jmlr.org/papers/v22/20-848.bib,https://github.com/lasso-net/,,,,"Much work has been done recently to make neural networks more interpretable, and one approach is to arrange for the network to use only a subset of the available features. In linear models, Lasso (or $\ell_1$-regularized) regression assigns zero weights to the most irrelevant or redundant features, and is widely used in data science. However the Lasso only applies to linear models. Here we introduce LassoNet, a neural network framework with global feature selection. Our approach achieves feature sparsity by adding a skip (residual) layer and allowing a feature to participate in any hidden layer only if its skip-layer representative is active. Unlike other approaches to feature selection for neural nets, our method uses a modified objective function with constraints, and so integrates feature selection with the parameter learning directly. As a result, it delivers an entire regularization path of solutions with a range of feature sparsity. We apply LassoNet to a number of real-data problems and find that it significantly outperforms state-of-the-art methods for feature selection and regression. LassoNet uses projected proximal gradient descent, and generalizes directly to deep networks. It can be implemented by adding just a few lines of code to a standard neural network.",Data Science; Feature Selection; Gradient Descent; Lasso; Neural Network; Objective-C; Regression,Regressions
128,Optimal Bounds between f-Divergences and Integral Probability Metrics,"Rohit Agrawal, Thibaut Horel","(128):1−59, 2021.",https://jmlr.org/papers/v22/20-867.html,https://jmlr.org/papers/volume22/20-867/20-867.pdf,https://jmlr.org/papers/v22/20-867.bib,,,,,"The families of $f$-divergences (e.g. the Kullback-Leibler divergence) and Integral Probability Metrics (e.g. total variation distance or maximum mean discrepancies) are widely used to quantify the similarity between probability distributions. In this work, we systematically study the relationship between these two families from the perspective of convex duality.  Starting from a tight variational representation of the $f$-divergence, we derive a generalization of the moment-generating function, which we show exactly characterizes the best lower bound of the $f$-divergence as a function of a given IPM. Using this characterization, we obtain new bounds while also recovering in a unified manner well-known results, such as Hoeffding's lemma, Pinsker's inequality and its extension to subgaussian functions, and the Hammersley-Chapman-Robbins bound. This characterization also allows us to prove new results on topological properties of the divergence which may be of independent interest.",Presentation; Probability Distribution,Presentation Skill
129,Finite-sample Analysis of Interpolating Linear Classifiers in the Overparameterized Regime,"Niladri S. Chatterji, Philip M. Long","(129):1−30, 2021.",https://jmlr.org/papers/v22/20-974.html,https://jmlr.org/papers/volume22/20-974/20-974.pdf,https://jmlr.org/papers/v22/20-974.bib,,,,,"We prove bounds on the population risk of the maximum margin algorithm for two-class linear classification. For linearly separable training data, the maximum margin algorithm has been shown in previous work to be equivalent to a limit of training with logistic loss using gradient descent, as the training error is driven to zero. We analyze this algorithm applied to random data including misclassification noise. Our assumptions on the clean data include the case in which the class-conditional distributions are standard normal distributions. The misclassification noise may be chosen by an adversary, subject to a limit on the fraction of corrupted labels. Our bounds show that, with sufficient over-parameterization, the maximum margin algorithm trained on noisy data can achieve nearly optimal population risk.",Algorithm; Analysis; Classification; Fraction; Gradient Descent; Logistics; Normal Distribution; Population; Training,
130,Learning Whenever Learning is Possible: Universal Learning under General Stochastic Processes,Steve Hanneke,"(130):1−116, 2021.",https://jmlr.org/papers/v22/17-298.html,https://jmlr.org/papers/volume22/17-298/17-298.pdf,https://jmlr.org/papers/v22/17-298.bib,,,,,"This work initiates a general study of learning and generalization without the i.i.d. assumption, starting from first principles.  While the traditional approach to statistical learning theory typically relies on standard assumptions from probability theory (e.g., i.i.d. or stationary ergodic), in this work we are interested in developing a theory of learning based only on the most fundamental and necessary assumptions implicit in the requirements of the learning problem itself.  We specifically study universally consistent function learning, where the objective is to obtain low long-run average loss for any target function, when the data follow a given stochastic process.  We are then interested in the question of whether there exist learning rules guaranteed to be universally consistent given only the assumption that universally consistent learning is possible for the given data process.  The reasoning that motivates this criterion emanates from a kind of optimist's decision theory, and so we refer to such learning rules as being optimistically universal.  We study this question in three natural learning settings: inductive, self-adaptive, and online.  Remarkably, as our strongest positive result, we find that optimistically universal learning rules do indeed exist in the self-adaptive learning setting.  Establishing this fact requires us to develop new approaches to the design of learning algorithms.  Along the way, we also identify concise characterizations of the family of processes under which universally consistent learning is possible in the inductive and self-adaptive settings.  We additionally pose a number of enticing open problems, particularly for the online learning setting.",Algorithm; Decision Theory; Design; Objective-C; Probability Theory; Reasoning; Stochastic Process,
131,MushroomRL: Simplifying Reinforcement Learning Research,"Carlo D'Eramo, Davide Tateo, Andrea Bonarini, Marcello Restelli, Jan Peters","(131):1−5, 2021.  (Machine Learning Open Source Software Paper)",https://jmlr.org/papers/v22/18-056.html,https://jmlr.org/papers/volume22/18-056/18-056.pdf,https://jmlr.org/papers/v22/18-056.bib,https://github.com/MushroomRL/mushroom-rl,,,,"MushroomRL is an open-source Python library developed to simplify the process of implementing and running Reinforcement Learning (RL) experiments. Compared to other available libraries, MushroomRL has been created with the purpose of providing a comprehensive and flexible framework to minimize the effort in implementing and testing novel RL methodologies. The architecture of MushroomRL is built in such a way that every component of a typical RL experiment is already provided, and most of the time users can only focus on the implementation of their own algorithms. MushroomRL is accompanied by a benchmarking suite collecting experimental results of state-of-the-art deep RL algorithms, and allowing to benchmark new ones. The result is a library from which RL researchers can significantly benefit in the critical phase of the empirical analysis of their works. MushroomRL stable code, tutorials, and documentation can be found at https://github.com/MushroomRL/mushroom-rl.",Algorithm; Analysis; Architecture; Benchmarking; Documentation; Github; Google Workspace; Python; Reinforcement Learning; Research; Table; TestNG; Testing,Github; Python Programming; Reinforcement
132,Locally Differentially-Private Randomized Response for Discrete Distribution Learning,"Adriano Pastore, Michael Gastpar","(132):1−56, 2021.",https://jmlr.org/papers/v22/18-726.html,https://jmlr.org/papers/volume22/18-726/18-726.pdf,https://jmlr.org/papers/v22/18-726.bib,,,,,"We consider a setup in which confidential i.i.d. samples $X_1,\dotsc,X_n$ from an unknown finite-support distribution $\boldsymbol{p}$ are passed through $n$ copies of a discrete privatization channel (a.k.a. mechanism) producing outputs $Y_1,\dotsc,Y_n$. The channel law guarantees a local differential privacy of $\epsilon$. Subject to a prescribed privacy level $\epsilon$, the optimal channel should be designed such that an estimate of the source distribution based on the channel outputs $Y_1,\dotsc,Y_n$ converges as fast as possible to the exact value $\boldsymbol{p}$. For this purpose we study the convergence to zero of three distribution distance metrics: $f$-divergence, mean-squared error and total variation. We derive the respective normalized first-order terms of convergence (as $n \to \infty$), which for a given target privacy $\epsilon$ represent a rule-of-thumb factor by which the sample size must be augmented so as to achieve the same estimation accuracy as that of a non-randomizing channel. We formulate the privacy-fidelity trade-off problem as being that of minimizing said first-order term under a privacy constraint $\epsilon$. We further identify a scalar quantity that captures the essence of this trade-off, and prove bounds and data-processing inequalities on this quantity. For some specific instances of the privacy-fidelity trade-off problem, we derive inner and outer bounds on the optimal trade-off curve.",Accuracy; Law; Privacy; Processing; Router; Scala; Scalr; Trade,
133,A Contextual Bandit Bake-off,"Alberto Bietti, Alekh Agarwal, John Langford","(133):1−49, 2021.",https://jmlr.org/papers/v22/18-863.html,https://jmlr.org/papers/volume22/18-863/18-863.pdf,https://jmlr.org/papers/v22/18-863.bib,https://github.com/albietz/cb_bakeoff,,,,"Contextual bandit algorithms are essential for solving many real-world interactive machine learning problems. Despite multiple recent successes on statistically optimal and computationally efficient methods, the practical behavior of these algorithms is still poorly understood. We leverage the availability of large numbers of supervised learning datasets to empirically evaluate contextual bandit algorithms, focusing on practical methods that learn by relying on optimization oracles from supervised learning. We find that a recent method (Foster et al., 2018) using optimism under uncertainty works the best overall. A surprisingly close second is a simple greedy baseline that only explores implicitly through the diversity of contexts, followed by a variant of Online Cover (Agarwal et al., 2014) which tends to be more conservative but robust to problem specification by design. Along the way, we also evaluate various components of contextual bandit algorithm design such as loss estimators. Overall, this is a thorough study and review of contextual bandit methodology.",Algorithm Design; Dataset; Machine Learning; Methodology; Oracle; Supervised Learning; Uncertainty; Unsupervised Learning,
134,An Inertial Newton Algorithm for Deep Learning,"Camille Castera, Jérôme Bolte, Cédric Févotte, Edouard Pauwels","(134):1−31, 2021.",https://jmlr.org/papers/v22/19-1024.html,https://jmlr.org/papers/volume22/19-1024/19-1024.pdf,https://jmlr.org/papers/v22/19-1024.bib,https://github.com/camcastera/INNA-for-DeepLearning,,,,"We introduce a new second-order inertial optimization method for machine learning called INNA. It exploits the geometry of the loss function while only requiring stochastic approximations of the function values and the generalized gradients. This makes INNA fully implementable and adapted to large-scale optimization problems such as the training of deep neural networks. The algorithm combines both gradient-descent and Newton-like behaviors as well as inertia. We prove the convergence of INNA for most deep learning problems. To do so, we provide a well-suited framework to analyze deep learning loss functions involving tame optimization in which we study a continuous dynamical system together with its discrete stochastic approximations.  We prove sublinear convergence for the continuous-time differential inclusion which underlies our algorithm. Additionally, we also show how standard optimization mini-batch methods applied to non-smooth non-convex problems can yield a certain type of spurious stationary points never discussed before. We address this issue by providing a theoretical framework around the new idea of $D$-criticality; we then give a simple asymptotic analysis of INNA. Our algorithm allows for using an aggressive learning rate of $o(1/\log k)$. From an empirical viewpoint, we show that INNA returns competitive results with respect to state of the art (stochastic gradient descent, ADAGRAD, ADAM) on popular deep learning benchmark problems.",Algorithm; Analysis; Approximation; Deep Learning; Exploit; Geometry; Gradient Descent; Machine Learning; Neural Network; Training,Deep Learning
135,Learning Sparse Classifiers: Continuous and Mixed Integer Optimization Perspectives,"Antoine Dedieu, Hussein Hazimeh, Rahul Mazumder","(135):1−47, 2021.",https://jmlr.org/papers/v22/19-1049.html,https://jmlr.org/papers/volume22/19-1049/19-1049.pdf,https://jmlr.org/papers/v22/19-1049.bib,https://github.com/hazimehh/L0Learn,,,,"We consider a discrete optimization formulation for learning sparse classifiers, where the outcome depends upon a linear combination of a small subset of features. Recent work has shown that mixed integer programming (MIP) can be used to solve (to optimality) $\ell_0$-regularized regression problems at scales much larger than what was conventionally considered possible. Despite their usefulness, MIP-based global optimization approaches are significantly slower than the relatively mature algorithms for $\ell_1$-regularization and heuristics for nonconvex regularized problems. We aim to bridge this gap in computation times by developing new MIP-based algorithms for $\ell_0$-regularized classification. We propose two classes of scalable algorithms: an exact algorithm that can handle $p\approx 50,000$ features in a few minutes, and approximate algorithms that can address instances with $p\approx 10^6$ in times comparable to the fast $\ell_1$-based algorithms. Our exact algorithm is based on the novel idea of \textsl{integrality generation}, which solves the original problem (with $p$ binary variables) via a sequence of mixed integer programs that involve a small number of binary variables. Our approximate algorithms are based on coordinate descent and local combinatorial search. In addition, we present new estimation error bounds for a class of $\ell_0$-regularized estimators. Experiments on real and synthetic data demonstrate that our approach leads to models with considerably improved statistical performance (especially variable selection) compared to competing methods.",Algorithm; Classification; Integer; R; Regression; Sales; Selection; Sequence; Variable,R programming; Regressions
136,Implicit Langevin Algorithms for Sampling From Log-concave Densities,"Liam Hodgkinson, Robert Salomone, Fred Roosta","(136):1−30, 2021.",https://jmlr.org/papers/v22/19-292.html,https://jmlr.org/papers/volume22/19-292/19-292.pdf,https://jmlr.org/papers/v22/19-292.bib,,,,,"For sampling from a log-concave density, we study implicit integrators resulting from $\theta$-method discretization of the overdamped Langevin diffusion stochastic differential equation. Theoretical and algorithmic properties of the resulting sampling methods for $ \theta \in [0,1] $ and a range of step sizes are established. Our results generalize and extend prior works in several directions. In particular, for $\theta\ge 1/2$, we prove geometric ergodicity and stability of the resulting methods for all step sizes. We show that obtaining subsequent samples amounts to solving a strongly-convex optimization problem, which is readily achievable using one of numerous existing methods. Numerical examples supporting our theoretical analysis are also presented.",Algorithm; Analysis; Sampling,
137,Hybrid Predictive Models: When an Interpretable Model Collaborates with a Black-box Model,"Tong Wang, Qihang Lin","(137):1−38, 2021.",https://jmlr.org/papers/v22/19-325.html,https://jmlr.org/papers/volume22/19-325/19-325.pdf,https://jmlr.org/papers/v22/19-325.bib,https://github.com/wangtongada/HyRS,,,,"Interpretable machine learning has become a strong competitor for black-box models. However, the possible loss of the predictive performance for gaining understandability is often inevitable, especially when it needs to satisfy users with diverse backgrounds or high standards for what is considered interpretable. This tension puts practitioners in a dilemma of choosing between high accuracy (black-box models) and interpretability (interpretable models).  In this work, we propose a novel framework for building a Hybrid Predictive Model that integrates an interpretable model with any pre-trained black-box model to combine their strengths. The interpretable model substitutes the black-box model on a subset of data where the interpretable model is most competent, gaining transparency at a low cost of the predictive accuracy. We design a principled objective function that considers predictive accuracy, model interpretability, and model transparency (defined as the percentage of data processed by the interpretable substitute.) Under this framework, we propose two hybrid models, one substituting with association rules and the other with linear models, and design customized training algorithms for both models. We test the hybrid models on structured data and text data where interpretable models collaborate with various state-of-the-art black-box models. Results show that hybrid models obtain an efficient trade-off between transparency and predictive performance, characterized by pareto frontiers. Finally, we apply the proposed model on a real-world patients dataset for predicting cardiovascular disease and propose multi-model Pareto frontiers to assist model selection in real applications.",Accuracy; Ad Design; Algorithm; Box; Dataset; Machine Learning; Model Selection; Objective-C; Predictive Model; Trade; Training; Web Design,
138,An algorithmic view of L2 regularization and some path-following algorithms,"Yunzhang Zhu, Renxiong Liu","(138):1−62, 2021.",https://jmlr.org/papers/v22/19-477.html,https://jmlr.org/papers/volume22/19-477/19-477.pdf,https://jmlr.org/papers/v22/19-477.bib,,,,,"We establish an equivalence between the $\ell_2$-regularized solution path for a convex loss function, and the solution of an ordinary differentiable equation (ODE). Importantly, this equivalence reveals that the solution path can be viewed as the flow of a hybrid of gradient descent and Newton method applying to the empirical loss, which is similar to a widely used optimization technique called trust region method. This provides an interesting algorithmic view of $\ell_2$ regularization, and is in contrast to the conventional view that the $\ell_2$ regularization solution path is similar to the gradient flow of the empirical loss. New path-following algorithms based on homotopy methods and numerical ODE solvers are proposed to numerically approximate the solution path. In particular, we consider respectively Newton method and gradient descent method as the basis algorithm for the homotopy method, and establish their approximation error rates over the solution path. Importantly, our theory suggests novel schemes to choose grid points that guarantee an arbitrarily small suboptimality for the solution path. In terms of computational cost, we prove that in order to achieve an $\epsilon$-suboptimality for the entire solution path, the number of Newton steps required for the Newton method is $\mathcal O(\epsilon^{-1/2})$, while the number of gradient steps required for the gradient descent method is $\mathcal O\left(\epsilon^{-1} \ln(\epsilon^{-1})\right)$.
Finally, we use $\ell_2$-regularized logistic regression as an illustrating example to demonstrate the effectiveness of the proposed path-following algorithms.",Algorithm; Approximation; Gradient Descent; Logistic Regression; Logistics; Regression; Scheme,Regressions
139,Hoeffding's Inequality for General Markov Chains and Its Applications to Statistical Learning,"Jianqing Fan, Bai Jiang, Qiang Sun","(139):1−35, 2021.",https://jmlr.org/papers/v22/19-479.html,https://jmlr.org/papers/volume22/19-479/19-479.pdf,https://jmlr.org/papers/v22/19-479.bib,,,,,"This paper establishes Hoeffding's lemma and inequality for bounded functions of general-state-space and not necessarily reversible Markov chains. The sharpness of these results is characterized by the optimality of the ratio between variance proxies in the Markov-dependent and independent settings. The boundedness of functions is shown necessary for such results to hold in general. To showcase the usefulness of the new results, we apply them for non-asymptotic analyses of MCMC estimation, respondent-driven sampling and high-dimensional covariance matrix estimation on time series data with a Markovian nature. In addition to statistical problems, we also apply them to study the time-discounted rewards in econometric models and the multi-armed bandit problem with Markovian rewards arising from the field of machine learning.",Covariance Matrix; Econometrics; Machine Learning; Sampling; Time Series,
140,Generalization Properties of hyper-RKHS and its Applications,"Fanghui Liu, Lei Shi, Xiaolin Huang, Jie Yang, Johan A.K. Suykens","(140):1−38, 2021.",https://jmlr.org/papers/v22/19-482.html,https://jmlr.org/papers/volume22/19-482/19-482.pdf,https://jmlr.org/papers/v22/19-482.bib,,,,,"This paper generalizes regularized regression problems in a hyper-reproducing kernel Hilbert space (hyper-RKHS), illustrates its utility for kernel learning and out-of-sample extensions, and proves asymptotic convergence results for the introduced regression models in an approximation theory view. Algorithmically, we consider two regularized regression models with bivariate forms in this space, including kernel ridge regression (KRR) and support vector regression (SVR) endowed with hyper-RKHS, and further combine divide-and-conquer with Nystr\""{o}m approximation for scalability in large sample cases. This framework is general: the underlying kernel is learned from a broad class, and can be positive definite or not, which adapts to various requirements in kernel learning. Theoretically, we study the convergence behavior of regularized regression algorithms in hyper-RKHS and derive the learning rates, which goes beyond the classical analysis on RKHS due to the non-trivial independence of pairwise samples and the characterisation of hyper-RKHS. Experimentally, results on several benchmarks suggest that the employed framework is able to learn a general kernel function form an arbitrary similarity matrix, and thus achieves a satisfactory performance on classification tasks.",Algorithm; Analysis; Approximation; Classification; Regression; Ridge Regression; Utility,Regressions
141,Pseudo-Marginal Hamiltonian Monte Carlo,"Johan Alenlöv, Arnoud Doucet, Fredrik Lindsten","(141):1−45, 2021.",https://jmlr.org/papers/v22/19-486.html,https://jmlr.org/papers/volume22/19-486/19-486.pdf,https://jmlr.org/papers/v22/19-486.bib,,,,,"Bayesian inference in the presence of an intractable likelihood function is computationally challenging. When following a Markov chain Monte Carlo (MCMC) approach to approximate the posterior distribution in this context, one typically either uses MCMC schemes which target the joint posterior of the parameters and some auxiliary latent variables, or pseudo-marginal Metropolis-Hastings (MH) schemes. The latter mimic a MH algorithm targeting the marginal posterior of the parameters by approximating unbiasedly the intractable likelihood. However, in scenarios where the parameters and auxiliary variables are strongly correlated under the posterior and/or this posterior is multimodal, Gibbs sampling or Hamiltonian Monte Carlo (HMC) will perform poorly and the pseudo-marginal MH algorithm, as any other MH scheme, will be inefficient for high-dimensional parameters. We propose here an original MCMC algorithm, termed pseudo-marginal HMC, which combines the advantages of both HMC and pseudo-marginal schemes. Specifically, the PM-HMC method is controlled by a precision parameter $N$, controlling the approximation of the likelihood and, for any $N$, it samples the marginal posterior of the parameters. Additionally, as $N$ tends to infinity, its sample trajectories and acceptance probability converge to those of an ideal, but intractable, HMC algorithm which would have access to the intractable likelihood and its gradient.  We demonstrate through experiments that PM-HMC can outperform significantly both standard HMC and pseudo-marginal MH schemes.",Algorithm; Approximation; Bayesian Inference; Microsoft Access; Probability; Sampling; Scheme; Variable,
142,Inference for Multiple Heterogeneous Networks with a Common Invariant Subspace,"Jesús Arroyo, Avanti Athreya, Joshua Cape, Guodong Chen, Carey E. Priebe, Joshua T. Vogelstein","(142):1−49, 2021.",https://jmlr.org/papers/v22/19-558.html,https://jmlr.org/papers/volume22/19-558/19-558.pdf,https://jmlr.org/papers/v22/19-558.bib,https://github.com/jesusdaniel/mase,,,,"The development of models and methodology for the analysis of data from multiple heterogeneous networks is of importance both in statistical network theory and across a wide spectrum of application domains. Although single-graph analysis is well-studied, multiple graph inference is largely unexplored, in part because of the challenges inherent in appropriately modeling graph differences and yet retaining sufficient model simplicity to render estimation feasible. This paper addresses exactly this gap, by introducing a new model, the common subspace independent-edge multiple random graph model, which describes a heterogeneous collection of networks with a shared latent structure on the vertices but potentially different connectivity patterns for each graph. The model encompasses many popular network representations, including the stochastic blockmodel. The model is both flexible enough to meaningfully account for important graph differences, and tractable enough to allow for accurate inference in multiple networks. In particular, a joint spectral embedding of adjacency matrices---the multiple adjacency spectral embedding---leads to simultaneous consistent estimation of underlying parameters for each graph. Under mild additional assumptions, the estimates satisfy asymptotic normality and yield improvements for graph eigenvalue estimation. In both simulated and real data, the model and the embedding can be deployed for a number of subsequent network inference tasks, including dimensionality reduction, classification, hypothesis testing, and community detection. Specifically, when the embedding is applied to a data set of connectomes constructed through diffusion magnetic resonance imaging, the result is an accurate classification of brain scans by human subject and a meaningful determination of heterogeneity across scans of different individuals.",Analysis; Classification; Dimensionality Reduction; Graph; Hypothesis Testing; Inference; Methodology; Modelling; Network Theory; TestNG; Trend Estimation,
143,Non-attracting Regions of Local Minima in Deep and Wide Neural Networks,"Henning Petzka, Cristian Sminchisescu","(143):1−34, 2021.",https://jmlr.org/papers/v22/19-586.html,https://jmlr.org/papers/volume22/19-586/19-586.pdf,https://jmlr.org/papers/v22/19-586.bib,,,,,"Understanding the loss surface of neural networks is essential for the design of models with predictable performance and their success in applications. Experimental results suggest that sufficiently deep and wide neural networks are not negatively impacted by suboptimal local minima. Despite recent progress, the reason for this outcome is not fully understood. Could deep networks have very few, if at all, suboptimal local optima? or could all of them be equally good? We provide a construction to show that suboptimal local minima (i.e., non-global ones), even though degenerate, exist for fully connected neural networks with sigmoid activation functions. The local minima obtained by our construction belong to a connected set of local solutions that can be escaped from via a non-increasing path on the loss curve. For extremely wide neural networks of decreasing width after the wide layer, we prove that every suboptimal local minimum belongs to such a connected set.  This provides a partial explanation for the successful application of deep neural networks. In addition, we also characterize under what conditions the same construction leads to saddle points instead of local minima for deep neural networks.",Construction; Design; Neural Network,
144,Individual Fairness in Hindsight,"Swati Gupta, Vijay Kamble","(144):1−35, 2021.",https://jmlr.org/papers/v22/19-658.html,https://jmlr.org/papers/volume22/19-658/19-658.pdf,https://jmlr.org/papers/v22/19-658.bib,,,,,"The pervasive prevalence of algorithmic decision-making in societal domains necessitates that these algorithms satisfy reasonable notions of fairness. One compelling notion is that of individual fairness (IF), which advocates that similar individuals should be treated similarly. In this paper, we extend the notion of IF to online contextual decision-making in settings where there exists a common notion of conduciveness of decisions as perceived by the affected individuals. We introduce two definitions: (i) fairness-across-time (FT) and (ii) fairness-in-hindsight (FH). FT requires the treatment of individuals to be individually fair relative to the past as well as future, while FH only requires individual fairness of a decision at the time of the decision. We show that these two definitions can have drastically different implications when the principal needs to learn the utility model. Linear regret relative to optimal individually fair decisions is generally unavoidable under FT. On the other hand, we design a new algorithm: Cautious Fair Exploration (CaFE), which satisfies FH and achieves order-optimal sublinear regret guarantees for a broad range of settings.",Algorithm; Decision Making; Utility; Web Design,
145,On efficient multilevel Clustering via Wasserstein distances,"Viet Huynh, Nhat Ho, Nhan Dam, XuanLong Nguyen, Mikhail Yurochkin, Hung Bui, Dinh Phung","(145):1−43, 2021.",https://jmlr.org/papers/v22/19-782.html,https://jmlr.org/papers/volume22/19-782/19-782.pdf,https://jmlr.org/papers/v22/19-782.bib,,,,,"We propose a novel approach to the problem of multilevel clustering, which aims to simultaneously partition data in each group and discover grouping patterns among groups in a potentially large hierarchically structured corpus of data. Our method involves a joint optimization formulation over several spaces of discrete probability measures, which are endowed with Wasserstein distance metrics. We propose several variants of this problem, which admit fast optimization algorithms, by exploiting the connection to the problem of finding Wasserstein barycenters.  Consistency properties are established for the estimates of both local and global clusters. Finally, experimental results with both synthetic and real data are presented to demonstrate the flexibility and scalability of the proposed approach.",Algorithm; Clustering; Probability,
146,Nonparametric Modeling of Higher-Order Interactions via Hypergraphons,Krishnakumar Balasubramanian,"(146):1−35, 2021.",https://jmlr.org/papers/v22/19-941.html,https://jmlr.org/papers/volume22/19-941/19-941.pdf,https://jmlr.org/papers/v22/19-941.bib,,,,,"We study statistical and algorithmic aspects of using hypergraphons, that are limits of large hypergraphs, for modeling higher-order interactions. Although hypergraphons are extremely powerful from a modeling perspective, we consider a restricted class of Simple Lipschitz Hypergraphons (SLH), that are amenable to practically efficient estimation. We also provide rates of convergence for our estimator that are optimal for the class of SLH. Simulation results are provided to corroborate the theory.",Algorithm; Modelling,
147,Optimal Minimax Variable Selection for Large-Scale Matrix Linear Regression Model,"Meiling Hao, Lianqiang Qu, Dehan Kong, Liuquan Sun, Hongtu Zhu","(147):1−39, 2021.",https://jmlr.org/papers/v22/19-969.html,https://jmlr.org/papers/volume22/19-969/19-969.pdf,https://jmlr.org/papers/v22/19-969.bib,,,,,"Large-scale matrix linear regression models with high-dimensional responses and high-dimensional variables have been widely employed in various large-scale biomedical studies. In this article, we propose an optimal minimax variable selection approach for the matrix linear regression model when the dimensions of both the response matrix and predictors diverge at the exponential rate of the sample size. We develop an iterative hard-thresholding algorithm for fast computation and establish an optimal minimax theory for the parameter estimates. The finite sample performance of the method is examined via extensive simulation studies and a real data application from the Alzheimer's Disease Neuroimaging Initiative study is provided.",Algorithm; Linear Regression; Nonlinear Regression; Regression; Selection; Variable,Regressions
148,Statistical guarantees for local graph clustering,"Wooseok Ha, Kimon Fountoulakis, Michael W. Mahoney","(148):1−54, 2021.",https://jmlr.org/papers/v22/20-029.html,https://jmlr.org/papers/volume22/20-029/20-029.pdf,https://jmlr.org/papers/v22/20-029.bib,,,,,"Local graph clustering methods aim to find small clusters in very large graphs. These methods take as input a graph and a seed node, and they return as output a good cluster in a running time that depends on the size of the output cluster but that is independent of the size of the input graph. In this paper, we adopt a statistical perspective on local graph clustering, and we analyze the performance of the $\ell_1$-regularized PageRank method (Fountoulakis et al., 2019) for the recovery of a single target cluster, given a seed node inside the cluster. Assuming the target cluster has been generated by a random model, we present two results. In the first, we show that the optimal support of $\ell_1$-regularized PageRank recovers the full target cluster, with bounded false positives. In the second, we show that if the seed node is connected solely to the target cluster then the optimal support of $\ell_1$-regularized PageRank recovers exactly the target cluster. We also show empirically that $\ell_1$-regularized PageRank has a state-of-the-art performance on many real graphs, demonstrating the superiority of the method. From a computational perspective, we show that the solution path of $\ell_1$-regularized PageRank is monotonic. This allows for the application of the
forward stagewise algorithm, which approximates the entire solution path in running time that does not depend on the size of the whole graph. Finally, we show that $\ell_1$-regularized PageRank and approximate personalized PageRank (APPR) (Andersen et al., 2006), another very popular method for local graph clustering, are equivalent in the sense that we can lower and upper bound the output of one with the output of the other. Based on this relation, we establish for APPR similar results to those we establish for $\ell_1$-regularized PageRank.",Algorithm; Clustering; Graph; Node.js,
149,Hyperparameter Optimization via Sequential Uniform Designs,"Zebin Yang, Aijun Zhang","(149):1−47, 2021.",https://jmlr.org/papers/v22/20-058.html,https://jmlr.org/papers/volume22/20-058/20-058.pdf,https://jmlr.org/papers/v22/20-058.bib,https://github.com/SelfExplainML/SeqUD,,,,"Hyperparameter optimization (HPO) plays a central role in the automated machine learning (AutoML). It is a challenging task as the response surfaces of hyperparameters are generally unknown, hence essentially a global optimization problem. This paper reformulates HPO as a computer experiment and proposes a novel sequential uniform design (SeqUD) strategy with three-fold advantages: a) the hyperparameter space is adaptively explored with evenly spread design points, without the need of expensive meta-modeling and acquisition optimization; b) the batch-by-batch design points are sequentially generated with parallel processing support; c) a new augmented uniform design algorithm is developed for the efficient real-time generation of follow-up design points. Extensive experiments are conducted on both global optimization tasks and HPO applications. The numerical results show that the proposed SeqUD strategy outperforms benchmark HPO methods, and it can be therefore a promising and competitive alternative to existing AutoML tools.",Ad Design; Algorithm; Automated Machine Learning; Hyperparameter Optimization; Modelling; Processing,
150,Accelerating Ill-Conditioned Low-Rank Matrix Estimation via Scaled Gradient Descent,"Tian Tong, Cong Ma, Yuejie Chi","(150):1−63, 2021.",https://jmlr.org/papers/v22/20-1067.html,https://jmlr.org/papers/volume22/20-1067/20-1067.pdf,https://jmlr.org/papers/v22/20-1067.bib,https://github.com/Titan-Tong/ScaledGD,,,,"Low-rank matrix estimation is a canonical problem that finds numerous applications in signal processing, machine learning and imaging science. A popular approach in practice is to factorize the matrix into two compact low-rank factors, and then optimize these factors directly via simple iterative methods such as gradient descent and alternating minimization. Despite nonconvexity, recent literatures have shown that these simple heuristics in fact achieve linear convergence when initialized properly for a growing number of problems of interest. However, upon closer examination, existing approaches can still be computationally expensive especially for ill-conditioned matrices: the convergence rate of gradient descent depends linearly on the condition number of the low-rank matrix, while the per-iteration cost of alternating minimization is often prohibitive for large matrices. The goal of this paper is to set forth a competitive algorithmic approach dubbed Scaled Gradient Descent (ScaledGD) which can be viewed as preconditioned or diagonally-scaled gradient descent, where the preconditioners are adaptive and iteration-varying with a minimal computational overhead. With tailored variants for low-rank matrix sensing, robust principal component analysis and matrix completion, we theoretically show that ScaledGD achieves the best of both worlds: it converges linearly at a rate independent of the condition number of the low-rank matrix similar as alternating minimization, while maintaining the low per-iteration cost of gradient descent. Our analysis is also applicable to general loss functions that are restricted strongly convex and smooth over low-rank matrices. To the best of our knowledge, ScaledGD is the first algorithm that provably has such properties over a wide range of low-rank matrix estimation tasks. At the core of our analysis is the introduction of a new distance function that takes account of the preconditioners when measuring the distance between the iterates and the ground truth. Finally, numerical examples are provided to demonstrate the effectiveness of ScaledGD in accelerating  the convergence rate of ill-conditioned low-rank matrix estimation in a wide number of applications.",Algorithm; Forth; Gradient Descent; Literature; Machine Learning; Non-convexity; Principal Component Analysis (PCA); Signal Processing,
151,Universal consistency and rates of convergence of multiclass prototype algorithms in metric spaces,"László Györfi, Roi Weiss","(151):1−25, 2021.",https://jmlr.org/papers/v22/20-1081.html,https://jmlr.org/papers/volume22/20-1081/20-1081.pdf,https://jmlr.org/papers/v22/20-1081.bib,,,,,"We study universal consistency and convergence rates of simple nearest-neighbor prototype rules for the problem of multiclass classification in metric spaces. We first show that a novel data-dependent partitioning rule, named Proto-NN, is universally consistent in any metric space that admits a universally consistent rule. Proto-NN is a significant simplification of OptiNet, a recently proposed compression-based algorithm that, to date, was the only algorithm known to be universally consistent in such a general setting. Practically, Proto-NN is simpler to implement and enjoys reduced computational complexity. We then proceed to study convergence rates of the excess error probability. We first obtain rates for the standard $k$-NN rule under a margin condition and a new generalized-Lipschitz condition. The latter is an extension of a recently proposed modified-Lipschitz condition from $\mathbb R^d$ to metric spaces. Similarly to the modified-Lipschitz condition, the new condition avoids any boundness assumptions on the data distribution. While obtaining rates for Proto-NN is left open, we show that a second prototype rule that hybridizes between $k$-NN and Proto-NN achieves the same rates as $k$-NN while enjoying similar computational advantages as Proto-NN. However, as $k$-NN, this hybrid rule is not consistent in general.",Algorithm; Classification; Complexity; Probability,
152,Hardness of Identity Testing for Restricted Boltzmann Machines and Potts models,"Antonio Blanca, Zongchen Chen, Daniel Štefankovič, Eric Vigoda","(152):1−56, 2021.",https://jmlr.org/papers/v22/20-1162.html,https://jmlr.org/papers/volume22/20-1162/20-1162.pdf,https://jmlr.org/papers/v22/20-1162.bib,,,,,"We study the identity testing problem for restricted Boltzmann machines (RBMs), and more generally, for undirected graphical models. In this problem, given sample access to the Gibbs distribution corresponding to an unknown or hidden model $M^*$  and given an explicit model $M$, the goal is to distinguish if either $M = M^*$ or if the models are (statistically) far apart. We establish the computational hardness of identity testing for RBMs (i.e., mixed Ising models on bipartite graphs), even when there are no latent variables or an external field.  Specifically, we show that unless $RP=NP$, there is no polynomial-time identity testing algorithm for RBMs when $\beta d=\omega(\log{n})$, where $d$ is the maximum degree of the visible graph and $\beta$ is the largest edge weight (in absolute value); when $\beta d =O(\log{n})$ there is an efficient identity testing algorithm that utilizes the structure learning algorithm of Klivans and Meka (2017). We prove similar lower bounds for purely ferromagnetic RBMs with inconsistent external fields and for the ferromagnetic Potts model. To prove our results, we introduce a novel methodology to reduce the corresponding approximate counting problem to testing utilizing the phase transition exhibited by these models.",Algorithm; Graph; Graphical Model; Methodology; Microsoft Access; Restricted Boltzmann Machine (RBM); TestNG; Testing; Variable,
153,Factorization Machines with Regularization for Sparse Feature Interactions,"Kyohei Atarashi, Satoshi Oyama, Masahito Kurihara","(153):1−50, 2021.",https://jmlr.org/papers/v22/20-1170.html,https://jmlr.org/papers/volume22/20-1170/20-1170.pdf,https://jmlr.org/papers/v22/20-1170.bib,,,,,"Factorization machines (FMs) are machine learning predictive models based on second-order feature interactions and FMs with sparse regularization are called sparse FMs. Such regularizations enable feature selection, which selects the most relevant features for accurate prediction, and therefore they can contribute to the improvement of the model accuracy and interpretability. However, because FMs use second-order feature interactions, the selection of features often causes the loss of many relevant feature interactions in the resultant models. In such cases, FMs with regularization specially designed for feature interaction selection trying to achieve interaction-level sparsity may be preferred instead of those just for feature selection trying to achieve feature-level sparsity. In this paper, we present a new regularization scheme for feature interaction selection in FMs. For feature interaction selection, our proposed regularizer makes the feature interaction matrix sparse without a restriction on sparsity patterns imposed by the existing methods. We also describe efficient proximal algorithms for the proposed FMs and how our ideas can be applied or extended to feature selection and other related models such as higher-order FMs and the all-subsets model. The analysis and experimental results on synthetic and real-world datasets show the effectiveness of the proposed methods.",Accuracy; Algorithm; Analysis; Azure Machine Learning; Dataset; Feature Selection; Predictive Model; Scheme,
154,"Kernel Smoothing, Mean Shift, and Their Learning Theory with Directional Data","Yikun Zhang, Yen-Chi Chen","(154):1−92, 2021.",https://jmlr.org/papers/v22/20-1194.html,https://jmlr.org/papers/volume22/20-1194/20-1194.pdf,https://jmlr.org/papers/v22/20-1194.bib,https://github.com/zhangyk8/DirMS,,,,"Directional data consist of observations distributed on a (hyper)sphere, and appear in many applied fields, such as astronomy, ecology, and environmental science. This paper studies both statistical and computational problems of kernel smoothing for directional data. We generalize the classical mean shift algorithm to directional data, which allows us to identify local modes of the directional kernel density estimator (KDE). The statistical convergence rates of the directional KDE and its derivatives are derived, and the problem of mode estimation is examined. We also prove the ascending property of the directional mean shift algorithm and investigate a general problem of gradient ascent on the unit hypersphere. To demonstrate the applicability of the algorithm, we evaluate it as a mode clustering method on both simulated and real-world data sets.",Algorithm; Astronomy; Clustering; Derivative; Ecology; Environmental Science; Gastronomy; Gradient Descent; Mean Shift; Property; vSphere,
155,What Causes the Test Error? Going Beyond Bias-Variance via ANOVA,"Licong Lin, Edgar Dobriban","(155):1−82, 2021.",https://jmlr.org/papers/v22/20-1211.html,https://jmlr.org/papers/volume22/20-1211/20-1211.pdf,https://jmlr.org/papers/v22/20-1211.bib,,,,,"Modern machine learning methods are often overparametrized, allowing adaptation to the data at a fine level. This can seem puzzling; in the worst case, such models do not need to generalize.  This puzzle inspired a great amount of work, arguing when overparametrization reduces test error, in a phenomenon called `double descent'. Recent work aimed to understand in greater depth why overparametrization is helpful for generalization. This lead to discovering the unimodality of variance as a function of the level of parametrization, and to decomposing the variance into that arising from label noise, initialization, and randomness in the training data to understand the sources of the error. In this work we develop a deeper understanding of this area. Specifically, we propose using the analysis of variance (ANOVA) to decompose the variance in the test error in a symmetric way, for studying the generalization performance of certain two-layer linear and non-linear networks. The advantage of the analysis of variance is that it reveals the effects of initialization, label noise, and training data more clearly than prior approaches. Moreover, we also study the monotonicity and unimodality of the variance components. While prior work studied the unimodality of the overall variance, we study the properties of each term in the variance decomposition. One of our key insights is that often, the interaction between training samples and initialization can dominate the variance; surprisingly being larger than their marginal effect. Also, we characterize `phase transitions' where the variance changes from unimodal to monotone. On a technical level, we leverage advanced deterministic equivalent techniques for Haar random matrices, that---to our knowledge---have not yet been used in the area. We verify our results in numerical simulations and on empirical data examples.",Analysis of Covariance; Analysis of Variance (ANOVA); Machine Learning; Network; Training,
156,A Greedy Algorithm for Quantizing Neural Networks,"Eric Lybrand, Rayan Saab","(156):1−38, 2021.",https://jmlr.org/papers/v22/20-1233.html,https://jmlr.org/papers/volume22/20-1233/20-1233.pdf,https://jmlr.org/papers/v22/20-1233.bib,https://github.com/elybrand/quantized_neural_networks,,,,"We propose a new computationally efficient method for quantizing the weights of pre- trained neural networks that is general enough to handle both multi-layer perceptrons and convolutional neural networks. Our method deterministically quantizes layers in an iterative fashion with no complicated re-training required. Specifically, we quantize each neuron, or hidden unit, using a greedy path-following algorithm. This simple algorithm is equivalent to running a dynamical system, which we prove is stable for quantizing a single-layer neural network (or, alternatively, for quantizing the first layer of a multi-layer network) when the training data are Gaussian. We show that under these assumptions, the quantization error decays with the width of the layer, i.e., its level of over-parametrization. We provide numerical experiments, on multi-layer networks, to illustrate the performance of our methods on MNIST and CIFAR10 data, as well as for quantizing the VGG16 network using ImageNet data.",Algorithm; Convolutional Neural Network (CNN); Convolutional Neural Network (ConvNet); Perceptron; Table; Training,
157,The Ridgelet Prior: A Covariance Function Approach to Prior Specification for Bayesian Neural Networks,"Takuo Matsubara, Chris J. Oates, François-Xavier Briol","(157):1−57, 2021.",https://jmlr.org/papers/v22/20-1300.html,https://jmlr.org/papers/volume22/20-1300/20-1300.pdf,https://jmlr.org/papers/v22/20-1300.bib,,,,,"Bayesian neural networks attempt to combine the strong predictive performance of neural networks with formal quantification of uncertainty associated with the predictive output in the Bayesian framework. However, it remains unclear how to endow the parameters of the network with a prior distribution that is meaningful when lifted into the output space of the network. A possible solution is proposed that enables the user to posit an appropriate Gaussian process covariance function for the task at hand. Our approach constructs a prior distribution for the parameters of the network, called a ridgelet prior, that approximates the posited Gaussian process in the output space of the network. In contrast to existing work on the connection between neural networks and Gaussian processes, our analysis is non-asymptotic, with finite sample-size error bounds provided. This establishes the universality property that a Bayesian neural network can approximate any Gaussian process whose covariance function is sufficiently regular. Our experimental assessment is limited to a proof-of-concept, where we demonstrate that the ridgelet prior can out-perform an unstructured prior on regression problems for which a suitable Gaussian process prior can be provided.",Analysis; Bayesian; Covariance; Gaussian Process; Neural Network; Property; Regression; Uncertainty,Regressions
158,Information criteria for non-normalized models,"Takeru Matsuda, Masatoshi Uehara, Aapo Hyvarinen","(158):1−33, 2021.",https://jmlr.org/papers/v22/20-1366.html,https://jmlr.org/papers/volume22/20-1366/20-1366.pdf,https://jmlr.org/papers/v22/20-1366.bib,,,,,"Many statistical models are given in the form of non-normalized densities with an intractable normalization constant. Since maximum likelihood estimation is computationally intensive for these models, several estimation methods have been developed which do not require explicit computation of the normalization constant, such as noise contrastive estimation (NCE) and score matching. However, model selection methods for general nonnormalized models have not been proposed so far. In this study, we develop information criteria for non-normalized models estimated by NCE or score matching. They are approximately unbiased estimators of discrepancy measures for non-normalized models. Simulation results and applications to real data demonstrate that the proposed criteria enable selection of the appropriate non-normalized model in a data-driven manner.",Model Selection; Statistical Model,
159,When Does Gradient Descent with Logistic Loss Find Interpolating Two-Layer Networks?,"Niladri S. Chatterji, Philip M. Long, Peter L. Bartlett","(159):1−48, 2021.",https://jmlr.org/papers/v22/20-1372.html,https://jmlr.org/papers/volume22/20-1372/20-1372.pdf,https://jmlr.org/papers/v22/20-1372.bib,,,,,"We study the training of finite-width two-layer smoothed ReLU networks for binary classification using the logistic loss. We show that gradient descent drives the training loss to zero if the initial loss is small enough. When the data satisfies certain cluster and separation conditions and the network is wide enough, we show that one step of gradient descent reduces the loss sufficiently that the first result applies.",Classification; Gradient Descent; Logistics; Network; Training,
160,Are We Forgetting about Compositional Optimisers in Bayesian Optimisation?,"Antoine Grosnit, Alexander I. Cowen-Rivers, Rasul Tutunov, Ryan-Rhys Griffiths, Jun Wang, Haitham Bou-Ammar","(160):1−78, 2021.",https://jmlr.org/papers/v22/20-1422.html,https://jmlr.org/papers/volume22/20-1422/20-1422.pdf,https://jmlr.org/papers/v22/20-1422.bib,https://github.com/huawei-noah/noah-research/tree/CompBO/BO/HEBO/CompBO,,,,"Bayesian optimisation presents a sample-efficient methodology for global optimisation. Within this framework, a crucial performance-determining subroutine is the maximisation of the acquisition function, a task complicated by the fact that acquisition functions tend to be non-convex and thus nontrivial to optimise. In this paper, we undertake a comprehensive empirical study of approaches to maximise the acquisition function. Additionally, by deriving novel, yet mathematically equivalent, compositional forms for popular acquisition functions, we recast the maximisation task as a compositional optimisation problem, allowing us to benefit from the extensive literature in this field. We highlight the empirical advantages of the compositional approach to acquisition function maximisation across 3958 individual experiments comprising synthetic optimisation tasks as well as tasks from Bayesmark. Given the generality of the acquisition function maximisation subroutine, we posit that the adoption of compositional optimisers has the potential to yield performance improvements across all domains in which Bayesian optimisation is currently being applied. An open-source implementation is made available at https://github.com/huawei-noah/noah-research/tree/CompBO/BO/HEBO/CompBO.",Bayesian Optimization; Github; Literature; Methodology; Research; Tree,Github
161,MetaGrad: Adaptation using Multiple Learning Rates in Online Learning,"Tim van Erven, Wouter M. Koolen, Dirk van der Hoeven","(161):1−61, 2021.",https://jmlr.org/papers/v22/20-1444.html,https://jmlr.org/papers/volume22/20-1444/20-1444.pdf,https://jmlr.org/papers/v22/20-1444.bib,https://github.com/DirkvdH/Online-Appendix-MetaGrad,,,,"We provide a new adaptive method for online convex optimization, MetaGrad, that is robust to general convex losses but achieves faster rates for a broad class of special functions, including exp-concave and strongly convex functions, but also various types of stochastic and non-stochastic functions without any curvature. We prove this by drawing a connection to the Bernstein condition, which is known to imply fast rates in offline statistical learning. MetaGrad further adapts automatically to the size of the gradients. Its main feature is that it simultaneously considers multiple learning rates, which are weighted directly proportional to their empirical performance on the data using a new meta-algorithm. We provide three versions of MetaGrad. The full matrix version maintains a full covariance matrix and is applicable to learning tasks for which we can afford update time quadratic in the dimension. The other two versions provide speed-ups for high-dimensional learning tasks with an update time that is linear in the dimension: one is based on sketching, the other on running a separate copy of the basic algorithm per coordinate. We evaluate all versions of MetaGrad on benchmark online classification and regression tasks, on which they consistently outperform both online gradient descent and AdaGrad.",Algorithm; Classification and Regression Tree; Covariance Matrix; Curvature; Gradient Descent; Regression,Regressions
162,Counterfactual Mean Embeddings,"Krikamol Muandet, Motonobu Kanagawa, Sorawit Saengkyongam, Sanparith Marukatat","(162):1−71, 2021.",https://jmlr.org/papers/v22/20-185.html,https://jmlr.org/papers/volume22/20-185/20-185.pdf,https://jmlr.org/papers/v22/20-185.bib,https://github.com/sorawitj/counterfactual-mean-embedding,,,,"Counterfactual inference has become a ubiquitous tool in online advertisement, recommendation systems, medical diagnosis, and econometrics. Accurate modelling of outcome distributions associated with different interventions---known as counterfactual distributions---is crucial for the success of these applications. In this work, we propose to model counterfactual distributions using a novel Hilbert space representation called counterfactual mean embedding (CME). The CME embeds the associated counterfactual distribution into a reproducing kernel Hilbert space (RKHS) endowed with a positive definite kernel, which allows us to perform causal inference over the entire landscape of the counterfactual distribution. Based on this representation, we propose a  distributional treatment effect (DTE) which can quantify the causal effect over entire outcome distributions. Our approach is nonparametric as the CME can be estimated under the unconfoundedness assumption from observational data without requiring any parametric assumption about the underlying distributions. We also establish a rate of convergence of the proposed estimator which depends on the smoothness of the conditional mean and the Radon-Nikodym derivative of the underlying marginal distributions. Furthermore, our framework allows for more complex outcomes such as images, sequences, and graphs. Our experimental results on synthetic data and off-policy evaluation tasks demonstrate the advantages of the proposed estimator.",Derivative; Econometrics; Graph; Image; Inference; Modelling; Presentation; Recommendation System; Sequence,Presentation Skill
163,PeerReview4All: Fair and Accurate Reviewer Assignment in Peer Review,"Ivan Stelmakh, Nihar Shah, Aarti Singh","(163):1−66, 2021.",https://jmlr.org/papers/v22/20-190.html,https://jmlr.org/papers/volume22/20-190/20-190.pdf,https://jmlr.org/papers/v22/20-190.bib,,,,,"We consider the problem of automated assignment of papers to reviewers in conference peer review, with a focus on fairness and statistical accuracy. Our fairness objective is to maximize the review quality of the most disadvantaged paper, in contrast to the commonly used objective of maximizing the total  quality over all papers. We design an assignment algorithm based on an incremental max-flow procedure that we prove is near-optimally fair. Our statistical accuracy objective is to ensure correct recovery of the papers that should be accepted. We  provide a sharp minimax analysis of the accuracy of the peer-review process for a popular objective-score model as well as for a novel subjective-score model that we propose in the paper. Our analysis proves that our proposed assignment algorithm also leads to a near-optimal statistical accuracy. Finally, we design a novel experiment that allows for an objective comparison of various assignment algorithms, and overcomes the inherent difficulty posed by the absence of a ground truth in experiments on peer-review. The results of this experiment as well as of other experiments on synthetic and real data corroborate the theoretical guarantees of our algorithm.",Accuracy; Algorithm; Analysis; Objective-C; Web Design,
164,Improving Reproducibility in Machine Learning Research(A Report from the NeurIPS 2019 Reproducibility Program),"Joelle Pineau, Philippe Vincent-Lamarre, Koustuv Sinha, Vincent Lariviere, Alina Beygelzimer, Florence d'Alche-Buc, Emily Fox, Hugo Larochelle","(164):1−20, 2021.",https://jmlr.org/papers/v22/20-303.html,https://jmlr.org/papers/volume22/20-303/20-303.pdf,https://jmlr.org/papers/v22/20-303.bib,,,,,"One of the challenges in machine learning research is to ensure that presented and published results are sound and reliable. Reproducibility, that is obtaining similar results as presented in a paper or talk, using the same code and data (when available), is a necessary step to verify the reliability of research findings. Reproducibility is also an important step to promote open and accessible research, thereby allowing the scientific community to quickly integrate new findings and convert ideas to practice. Reproducibility also promotes the use of robust experimental workflows, which potentially reduce unintentional errors. In 2019, the Neural Information Processing Systems (NeurIPS) conference, the premier international conference for research in machine learning, introduced a reproducibility program, designed to improve the standards across the community for how we conduct, communicate, and evaluate machine learning research. The program contained three components: a code submission policy, a community-wide reproducibility challenge, and the inclusion of the Machine Learning Reproducibility checklist as part of the paper submission process. In this paper, we describe each of these components, how it was deployed, as well as what we were able to learn from this initiative.",Machine Learning; Processing; Research,
165,Implicit Self-Regularization in Deep Neural Networks: Evidence from Random Matrix Theory and Implications for Learning,"Charles H. Martin, Michael W. Mahoney","(165):1−73, 2021.",https://jmlr.org/papers/v22/20-410.html,https://jmlr.org/papers/volume22/20-410/20-410.pdf,https://jmlr.org/papers/v22/20-410.bib,,,,,"Random Matrix Theory (RMT) is applied to analyze the weight matrices of Deep Neural Networks (DNNs), including both production quality, pre-trained models such as AlexNet and Inception, and smaller models trained from scratch, such as LeNet5 and a miniature-AlexNet.  Empirical and theoretical results clearly indicate that the DNN training process itself implicitly implements a form of Self-Regularization, implicitly sculpting a more regularized energy or penalty landscape.  In particular, the empirical spectral density (ESD) of DNN layer matrices displays signatures of traditionally-regularized statistical models, even in the absence of exogenously specifying traditional forms of explicit regularization, such as Dropout or Weight Norm constraints.  Building on relatively recent results in RMT, most notably its extension to Universality classes of Heavy-Tailed matrices, and applying them to these empirical results, we develop a theory to identify 5+1 Phases of Training, corresponding to increasing amounts of Implicit Self-Regularization.  These phases can be observed during the training process as well as in the final learned DNNs.  For smaller and/or older DNNs, this Implicit Self-Regularization is like traditional Tikhonov regularization, in that there is a “size scale” separating signal from noise.  For state-of-the-art DNNs, however, we identify a novel form of Heavy-Tailed Self-Regularization, similar to the self-organization seen in the statistical physics of disordered systems (such as classical models of actual neural activity).  This results from correlations arising at all size scales, which for DNNs arises implicitly due to the training process itself.  This implicit Self-Regularization can depend strongly on the many knobs of the training process.  In particular, we demonstrate that we can cause a small model to exhibit all 5+1 phases of training simply by changing the batch size.  Our results suggest that large, well-trained DNN architectures should exhibit Heavy-Tailed Self-Regularization, and we discuss the theoretical and practical implications of this.",Architecture; Correlation; LeNet; Neural Network; Physics; Sales; Statistical Model; Training,
166,The ensmallen library for flexible numerical optimization,"Ryan R. Curtin, Marcus Edel, Rahul Ganesh Prabhu, Suryoday Basak, Zhihao Lou, Conrad Sanderson","(166):1−6, 2021.  (Machine Learning Open Source Software Paper)",https://jmlr.org/papers/v22/20-416.html,https://jmlr.org/papers/volume22/20-416/20-416.pdf,https://jmlr.org/papers/v22/20-416.bib,https://github.com/mlpack/ensmallen,,,,"We overview the ensmallen numerical optimization library, which provides a flexible C++ framework for mathematical optimization of user-supplied objective functions. Many types of objective functions are supported, including general, differentiable, separable, constrained, and categorical. A diverse set of pre-built optimizers is provided, including Quasi-Newton optimizers and many variants of Stochastic Gradient Descent. The underlying framework facilitates the implementation of new optimizers. Optimization of an objective function typically requires supplying only one or two C++ functions. Custom behavior can be easily specified via callback functions. Empirical comparisons show that ensmallen outperforms other frameworks while providing more functionality. The library is available at https://ensmallen.org and is distributed under the permissive BSD license.",C++; Gradient Descent; Mathematical Optimization; Objective-C,C++
167,Estimation and Optimization of Composite Outcomes,"Daniel J. Luckett, Eric B. Laber, Siyeon Kim, Michael R. Kosorok","(167):1−40, 2021.",https://jmlr.org/papers/v22/20-429.html,https://jmlr.org/papers/volume22/20-429/20-429.pdf,https://jmlr.org/papers/v22/20-429.bib,,,,,"There is tremendous interest in precision medicine as a means to improve patient outcomes by tailoring treatment to individual characteristics.  An individualized treatment rule formalizes precision medicine as a map from patient information to a  recommended treatment. A treatment rule is defined to be optimal if it maximizes the mean of a scalar outcome in a population of interest, e.g., symptom reduction. However, clinical and intervention scientists often seek to balance multiple and possibly competing outcomes, e.g., symptom reduction and the risk of an adverse event. One approach to precision medicine in this setting is to elicit a composite outcome which balances all competing outcomes; unfortunately, eliciting a composite outcome directly from patients is difficult without a high-quality instrument, and an expert-derived composite outcome may not account for heterogeneity in patient preferences. We propose a new paradigm for the study of precision  medicine using observational data that relies solely on the assumption  that clinicians are approximately (i.e., imperfectly) making decisions to maximize individual patient utility. Estimated composite outcomes are subsequently used to construct an estimator of an individualized treatment rule which maximizes the mean of patient-specific composite outcomes. The estimated composite outcomes and estimated optimal individualized treatment rule provide new insights into patient preference heterogeneity, clinician behavior, and the value of precision medicine in a given domain. We derive inference procedures for the proposed estimators under mild conditions and demonstrate their finite sample performance through a suite of simulation experiments and an illustrative application to data from a study of bipolar depression.",Inference; Medicine; Population; Scala; Scalr; Utility,
168,"Asymptotic Normality, Concentration, and Coverage of Generalized Posteriors",Jeffrey W. Miller,"(168):1−53, 2021.",https://jmlr.org/papers/v22/20-469.html,https://jmlr.org/papers/volume22/20-469/20-469.pdf,https://jmlr.org/papers/v22/20-469.bib,,,,,"Generalized likelihoods are commonly used to obtain consistent estimators with attractive computational and robustness properties. Formally, any generalized likelihood can be used to define a generalized posterior distribution, but an arbitrarily defined ""posterior"" cannot be expected to appropriately quantify uncertainty in any meaningful sense. In this article, we provide sufficient conditions under which generalized posteriors exhibit concentration, asymptotic normality (Bernstein-von Mises), an asymptotically correct Laplace approximation, and asymptotically correct frequentist coverage. We apply our results in detail to generalized posteriors for a wide array of generalized likelihoods, including pseudolikelihoods in general, the Gaussian Markov random field pseudolikelihood, the fully observed Boltzmann machine pseudolikelihood, the Ising model pseudolikelihood, the Cox proportional hazards partial likelihood, and a median-based likelihood for robust inference of location. Further, we show how our results can be used to easily establish the asymptotics of standard posteriors for exponential families and generalized linear models. We make no assumption of model correctness so that our results apply with or without misspecification.",Approximation; Array; Generalized Linear Model (GLM); Inference; Media; Uncertainty,
169,First-order Convergence Theory for Weakly-Convex-Weakly-Concave Min-max Problems,"Mingrui Liu, Hassan Rafique, Qihang Lin, Tianbao Yang","(169):1−34, 2021.",https://jmlr.org/papers/v22/20-533.html,https://jmlr.org/papers/volume22/20-533/20-533.pdf,https://jmlr.org/papers/v22/20-533.bib,,,,,"In this paper, we consider first-order convergence theory and algorithms for solving a class of non-convex non-concave min-max saddle-point problems, whose objective function is weakly convex in the variables of minimization and weakly concave in the variables of maximization. It has many important applications in machine learning including training Generative Adversarial Nets (GANs). We propose an algorithmic framework  motivated by the inexact proximal point method, where the weakly monotone variational inequality (VI) corresponding to the original min-max problem is solved through approximately solving a sequence of strongly monotone VIs constructed by adding a strongly monotone mapping to the original gradient mapping. We prove first-order convergence to  a nearly stationary  solution of the original min-max problem of the generic algorithmic framework and establish different rates by employing different algorithms for solving each strongly monotone VI. Experiments verify the convergence theory and also demonstrate the effectiveness of the proposed methods on training GANs.",Algorithm; Machine Learning; Mapping; Objective-C; Sequence; Training; Variable,
170,Black-Box Reductions for Zeroth-Order Gradient  Algorithms  to Achieve Lower  Query Complexity,"Bin Gu, Xiyuan Wei, Shangqian Gao, Ziran Xiong, Cheng Deng, Heng Huang","(170):1−47, 2021.",https://jmlr.org/papers/v22/20-611.html,https://jmlr.org/papers/volume22/20-611/20-611.pdf,https://jmlr.org/papers/v22/20-611.bib,,,,,"Zeroth-order (ZO) optimization has been the key technique for various machine learning applications especially for black-box adversarial attack, where models need to be learned in a gradient-free manner. Although many ZO algorithms have been proposed, the high function query complexities hinder their applications seriously. To address this challenging problem, we propose two stagewise black-box reduction frameworks for ZO algorithms under convex and non-convex settings respectively, which lower down the function query complexities of ZO algorithms. Moreover, our frameworks can directly derive the convergence results of ZO algorithms under convex and non-convex settings without extra analyses, as long as convergence results under strongly convex setting are given. To illustrate the advantages, we further study ZO-SVRG, ZO-SAGA and ZO-Varag under strongly-convex setting and use our frameworks to directly derive the convergence results under convex and non-convex settings. The function query complexities of these algorithms derived by our frameworks are lower than that of their vanilla counterparts without frameworks, or even lower than that of state-of-the-art algorithms. Finally we conduct numerical experiments to illustrate the superiority of our frameworks.",Algorithm; Box; Complexity; Machine Learning; jQuery,
171,Optimal Rates of Distributed Regression with Imperfect Kernels,"Hongwei Sun, Qiang Wu","(171):1−34, 2021.",https://jmlr.org/papers/v22/20-627.html,https://jmlr.org/papers/volume22/20-627/20-627.pdf,https://jmlr.org/papers/v22/20-627.bib,,,,,"Distributed machine learning systems have been receiving increasing attentions for their efficiency to process large scale data. Many distributed frameworks have been proposed for different machine learning tasks. In this paper, we study the distributed kernel regression via the divide and conquer approach. The learning process consists of three stages. Firstly, the data is partitioned into multiple subsets. Then a base kernel regression algorithm is applied to each subset to learn a local regression model. Finally the local models are averaged to generate the final regression model for the purpose of predictive analytics or statistical inference. This approach has been proved asymptotically minimax optimal if the kernel is perfectly selected so that the true regression function lies in the associated reproducing kernel Hilbert space. However, this is usually, if not always, impractical because kernels that can only be selected via prior knowledge or a tuning process are hardly perfect. Instead it is more common that the kernel is good enough but imperfect in the sense that the true regression can be well approximated by but does not lie exactly in the kernel space. We show distributed kernel regression can still achieve capacity independent optimal rate in this case. To this end, we first establish a general framework that allows to analyze distributed regression with response weighted base algorithms by bounding the error of such algorithms on a single data set, provided that the error bounds have factored the impact of unexplained variance of the response variable. Then we perform a leave one out analysis of the kernel ridge regression and bias corrected kernel ridge regression, which in combination with the aforementioned framework allows us to derive sharp error bounds and capacity independent optimal rates for the associated distributed kernel regression algorithms. As a byproduct of the thorough analysis, we also prove the kernel ridge regression can achieve rates faster than $O(N^{-1})$ (where $N$ is the sample size) in the noise free setting which, to our best knowledge, are first observed and novel in regression learning.",Algorithm; Analysis; Inference; Machine Learning; Predictive Analytics; Regression; Ridge Regression; Variable,Regressions
172,Unlinked Monotone Regression,"Fadoua Balabdaoui, Charles R. Doss, Cécile Durot","(172):1−60, 2021.",https://jmlr.org/papers/v22/20-689.html,https://jmlr.org/papers/volume22/20-689/20-689.pdf,https://jmlr.org/papers/v22/20-689.bib,,,,,"We consider so-called univariate unlinked (sometimes “decoupled,” or “shuffled”) regression when the unknown regression curve is monotone.  In standard monotone regression, one observes a pair $(X,Y)$ where a response $Y$ is linked to a  covariate $X$ through the model $Y= m_0(X) + \epsilon$, with $m_0$ the (unknown) monotone regression function and $\epsilon$ the unobserved error (assumed to be independent of $X$).  In the unlinked regression setting one gets only to observe a vector of realizations from both the response $Y$ and from the covariate $X$ where now $Y \stackrel{d}{=} m_0(X) + \epsilon$.  There is no (observed) pairing of $X$ and $Y$.  Despite this, it is actually still possible to derive a consistent non-parametric estimator of $m_0$ under the assumption of monotonicity of $m_0$ and knowledge of the distribution of the noise $\epsilon$.  In this paper, we establish an upper bound on the rate of convergence of such an estimator under minimal assumption on the distribution of the covariate $X$.  We discuss extensions to the case in which the distribution of the noise is unknown.  We develop a second order algorithm for its computation, and we demonstrate its use on synthetic data.  Finally, we apply our method (in a fully data driven way, without knowledge of the error distribution) on longitudinal data from the US Consumer Expenditure Survey.",Algorithm; Regression,Regressions
173,Replica Exchange for Non-Convex Optimization,"Jing Dong, Xin T. Tong","(173):1−59, 2021.",https://jmlr.org/papers/v22/20-697.html,https://jmlr.org/papers/volume22/20-697/20-697.pdf,https://jmlr.org/papers/v22/20-697.bib,,,,,"Gradient descent (GD) is known to converge quickly for convex objective functions, but it can be trapped at local minima. On the other hand, Langevin dynamics (LD) can explore the state space and find global minima, but in order to give accurate estimates, LD needs to run with a small discretization step size and weak stochastic force, which in general slow down its convergence. This paper shows that these two algorithms can “collaborate"" through a simple exchange mechanism, in which they swap their current positions if LD yields a lower objective function.  This idea can be seen as the singular limit of the replica-exchange technique from the sampling literature. We show that this new algorithm converges to the global minimum linearly with high probability, assuming the objective function is strongly convex in a neighborhood of the unique global minimum. By replacing gradients with stochastic gradients, and adding a proper threshold to the exchange mechanism, our algorithm can also be used in online settings. We also study non-swapping variants of the algorithm, which achieve similar performance. We further verify our theoretical results through some numerical experiments and observe superior performances of the proposed algorithm over running GD or LD alone.",Algorithm; Gradient Descent; Literature; Objective-C; Probability; Sampling,
174,Achieving Fairness in the Stochastic Multi-Armed Bandit Problem,"Vishakha Patil, Ganesh Ghalme, Vineet Nair, Y. Narahari","(174):1−31, 2021.",https://jmlr.org/papers/v22/20-704.html,https://jmlr.org/papers/volume22/20-704/20-704.pdf,https://jmlr.org/papers/v22/20-704.bib,,,,,"We study an interesting variant of the stochastic multi-armed bandit problem, which we call the Fair-MAB  problem, where, in addition to the objective of maximizing the sum of expected rewards, the algorithm also needs to ensure that at any time, each arm is pulled at least a pre-specified fraction of times. We investigate the interplay between learning and  fairness in terms of a pre-specified vector denoting the fractions of guaranteed pulls. We define a  fairness-aware regret, which we call $r$-Regret, that takes into account the above fairness constraints and extends the conventional notion of regret in a natural way. Our primary contribution is to obtain a complete characterization of a class of Fair-MAB algorithms via two parameters: the unfairness tolerance and the learning algorithm used as a black-box. For this class of algorithms, we provide a fairness guarantee that holds uniformly over time, irrespective of the chosen learning algorithm. Further, when the learning algorithm is UCB1, we show that our algorithm achieves constant $r$-Regret for a large enough time horizon. Finally, we analyze the cost of fairness in terms of the conventional notion of regret. We conclude by experimentally validating our theoretical results.",Algorithm; Box; Fraction; Objective-C,
175,Doubly infinite residual neural networks: a diffusion process approach,"Stefano Peluchetti, Stefano Favaro","(175):1−48, 2021.",https://jmlr.org/papers/v22/20-706.html,https://jmlr.org/papers/volume22/20-706/20-706.pdf,https://jmlr.org/papers/v22/20-706.bib,,,,,"Modern neural networks featuring a large number of layers (depth) and units per layer (width) have achieved a remarkable performance across many domains. While there exists a vast literature on the interplay between infinitely wide neural networks and Gaussian processes, a little is known about analogous interplays with respect to infinitely deep neural networks. Neural networks with independent and identically distributed (i.i.d.) initializations exhibit undesirable forward and backward propagation properties as the number of layers increases, e.g., vanishing dependency on the input, and perfectly correlated outputs for any two inputs. To overcome these drawbacks, Peluchetti and Favaro (2020) considered fully-connected residual networks (ResNets) with network's parameters initialized by means of distributions that shrink as the number of layers increases, thus establishing an interplay between infinitely deep ResNets and solutions to stochastic differential equations, i.e. diffusion processes, and showing that infinitely deep ResNets does not suffer from undesirable forward-propagation properties. In this paper, we review the results of Peluchetti and Favaro (2020), extending them to convolutional ResNets, and we establish analogous backward-propagation results, which directly relate to the problem of training fully-connected deep ResNets. Then, we investigate the more general setting of doubly infinite neural networks, where both network's width and network's depth grow unboundedly. We focus on doubly infinite fully-connected ResNets, for which we consider i.i.d. initializations. Under this setting, we show that the dynamics of quantities of interest converge, at initialization, to deterministic limits. This allow us to provide analytical expressions for inference, both in the case of weakly trained and fully trained ResNets. Our results highlight a limited expressive power of doubly infinite ResNets when the unscaled network's parameters are i.i.d. and the residual blocks are shallow.",Analytical; Gaussian Process; Inference; Literature; Neural Network; Training,
176,Locally Private k-Means Clustering,Uri Stemmer,"(176):1−30, 2021.",https://jmlr.org/papers/v22/20-721.html,https://jmlr.org/papers/volume22/20-721/20-721.pdf,https://jmlr.org/papers/v22/20-721.bib,,,,,"We design a new algorithm for the Euclidean $k$-means problem that operates in the local model of differential privacy. Unlike in the non-private literature, differentially private algorithms for the $k$-means objective incur both additive and multiplicative errors. Our algorithm significantly reduces the additive error while keeping the multiplicative error the same as in previous state-of-the-art results. Specifically, on a database of size $n$, our algorithm guarantees $O(1)$ multiplicative error and $\approx n^{1/2+a}$ additive error for an arbitrarily small constant $a>0$. All previous algorithms in the local model had additive error $\approx n^{2/3+a}$. Our techniques extend to $k$-median clustering. We show that the additive error we obtain is almost optimal in terms of its dependency on the database size $n$. Specifically, we give a simple lower bound showing that every locally-private algorithm for the $k$-means objective must have additive error at least $\approx\sqrt{n}$.",Algorithm; Database; Literature; Media; Objective-C; Privacy; Web Design; k-means Clustering,
177,"Prediction Under Latent Factor Regression: Adaptive PCR, Interpolating Predictors and Beyond","Xin Bing, Florentina Bunea, Seth Strimas-Mackey, Marten Wegkamp","(177):1−50, 2021.",https://jmlr.org/papers/v22/20-768.html,https://jmlr.org/papers/volume22/20-768/20-768.pdf,https://jmlr.org/papers/v22/20-768.bib,,,,,"This work is devoted to the finite sample prediction risk analysis of a class of linear predictors of a response $Y\in \mathbb{R}$ from a high-dimensional random vector $X\in \mathbb{R}^p$ when $(X,Y)$ follows a latent factor regression model generated by a unobservable latent vector $Z$ of dimension less than $p$. Our primary contribution is in establishing finite sample risk bounds for prediction with the ubiquitous Principal Component Regression (PCR) method, under the factor regression model, with the number of principal components adaptively selected from the data---a form of theoretical guarantee that is surprisingly lacking from the PCR literature. To accomplish this, we prove a master theorem that establishes a risk bound for a large class of predictors, including the PCR predictor as a special case. This approach has the benefit of providing a unified framework for the analysis of a wide range of linear prediction methods, under the factor regression setting. In particular, we use our main theorem to recover known risk bounds for the minimum-norm interpolating predictor, which has received renewed attention in the past two years, and a prediction method tailored to a subclass of factor regression models with identifiable parameters. This model-tailored method can be interpreted as prediction via clusters with latent centers. To address the problem of selecting among a set of candidate predictors, we analyze a simple model selection procedure based on data-splitting, providing an oracle inequality under the factor model to prove that the performance of the selected predictor is close to the optimal candidate. We conclude with a detailed simulation study to support and complement our theoretical results.",Interpreter; LeSS; Literature; Model Selection; Oracle; Polymerase chain reaction (PCR); Regression; Risk Analysis,Regressions
178,Conditional independences and causal relations implied by sets of equations,"Tineke Blom, Mirthe M. van Diepen, Joris M. Mooij","(178):1−62, 2021.",https://jmlr.org/papers/v22/20-863.html,https://jmlr.org/papers/volume22/20-863/20-863.pdf,https://jmlr.org/papers/v22/20-863.bib,,,,,"Real-world complex systems are often modelled by sets of equations with endogenous and exogenous variables. What can we say about the causal and probabilistic aspects of variables that appear in these equations without explicitly solving the equations? We make use of Simon's causal ordering algorithm (Simon, 1953) to construct a causal ordering graph and prove that it expresses the effects of soft and perfect interventions on the equations under certain unique solvability assumptions. We further construct a Markov ordering graph and prove that it encodes conditional independences in the distribution implied by the equations with independent random exogenous variables, under a similar unique solvability assumption. We discuss how this approach reveals and addresses some of the limitations of existing causal modelling frameworks, such as causal Bayesian networks and structural causal models.",Algorithm; Bayesian Networks; Graph; Modelling; Network; Variable,
179,A Sharp Blockwise Tensor Perturbation Bound for Orthogonal Iteration,"Yuetian Luo, Garvesh Raskutti, Ming Yuan, Anru R. Zhang","(179):1−48, 2021.",https://jmlr.org/papers/v22/20-919.html,https://jmlr.org/papers/volume22/20-919/20-919.pdf,https://jmlr.org/papers/v22/20-919.bib,,,,,"In this paper, we develop novel perturbation bounds for the higher-order orthogonal iteration (HOOI). Under mild regularity conditions, we establish blockwise tensor perturbation bounds for HOOI with guarantees for both tensor reconstruction in Hilbert-Schmidt norm $\|\widehat{\mathcal{T}} - \mathcal{T} \|_{\rm HS}$ and mode-$k$ singular subspace estimation in Schatten-$q$ norm $\| \sin \Theta (\widehat{U}_k, U_k) \|_q$ for any $q \geq 1$. We show the upper bounds of mode-$k$ singular subspace estimation are unilateral and converge linearly to a quantity characterized by blockwise errors of the perturbation and signal strength. For the tensor reconstruction error bound, we express the bound through a simple quantity $\xi$, which depends only on perturbation and the multilinear rank of the underlying signal. Rate matching deterministic lower bound for tensor reconstruction, which demonstrates the optimality of HOOI, is also provided. Furthermore, we prove that one-step HOOI (i.e., HOOI with only a single iteration) is also optimal in terms of tensor reconstruction and can be used to lower the computational cost. The perturbation results are also extended to the case that only partial modes of $\mathcal{T}$ have low-rank structure. We support our theoretical results by extensive numerical studies. Finally, we apply the novel perturbation bounds of HOOI on two applications, tensor denoising and tensor co-clustering, from machine learning and statistics, which demonstrates the superiority of the new perturbation results.",Clustering; Construction; Machine Learning; Statistics,Statistics
180,Improved Shrinkage Prediction under a Spiked Covariance Structure,"Trambak Banerjee, Gourab Mukherjee, Debashis Paul","(180):1−40, 2021.",https://jmlr.org/papers/v22/21-0006.html,https://jmlr.org/papers/volume22/21-0006/21-0006.pdf,https://jmlr.org/papers/v22/21-0006.bib,,,,,"We develop a novel shrinkage rule for prediction in a high-dimensional non-exchangeable hierarchical Gaussian model with an unknown spiked covariance structure. We propose a family of priors for the mean parameter, governed by a power hyper-parameter, which encompasses independent to highly dependent scenarios. Corresponding to popular loss functions such as quadratic, generalized absolute, and Linex losses, these prior models induce a wide class of shrinkage predictors that involve quadratic forms of smooth functions of the unknown covariance. By using uniformly consistent estimators of these quadratic forms, we propose an efficient procedure for evaluating these predictors which outperforms factor model based direct plug-in approaches. We further improve our predictors by considering possible reduction in their variability through a novel coordinate-wise shrinkage policy that only uses covariance level information and can be adaptively tuned using the sample eigen structure. Finally, we extend our disaggregate model based methodology to prediction in aggregate models. We propose an easy-to-implement functional substitution method for predicting linearly aggregated targets and establish asymptotic optimality of our proposed procedure. We present simulation experiments as well as real data examples illustrating the efficacy of the proposed method.",Covariance; Methodology,
181,Alibi Explain: Algorithms for Explaining Machine Learning Models,"Janis Klaise, Arnaud Van Looveren, Giovanni Vacanti, Alexandru Coca","(181):1−7, 2021.  (Machine Learning Open Source Software Paper)",https://jmlr.org/papers/v22/21-0017.html,https://jmlr.org/papers/volume22/21-0017/21-0017.pdf,https://jmlr.org/papers/v22/21-0017.bib,https://github.com/SeldonIO/alibi,,,,"We introduce Alibi Explain, an open-source Python library for explaining predictions of machine learning models (https://github.com/SeldonIO/alibi). The library features state-of-the-art explainability algorithms for classification and regression models. The algorithms cover both the model-agnostic (black-box) and model-specific (white-box) setting, cater for multiple data types (tabular, text, images) and explanation scope (local and global explanations). The library exposes a unified API enabling users to work with explanations in a consistent way. Alibi adheres to best development practices featuring extensive testing of code correctness and algorithm convergence in a continuous integration environment. The library comes with extensive documentation of both usage and theoretical background of methods, and a suite of worked end-to-end use cases. Alibi aims to be a production-ready toolkit with integrations into machine learning deployment platforms such as Seldon Core and KFServing, and distributed explanation capabilities using Ray.",Algorithm; Application Programming Interface (API); Box; Classification and Regression Tree; Continuous Integration (CI); Documentation; Github; Image; Machine Learning; Platform; Python; Regression; TestNG; Testing,Github; Python Programming; Regressions
182,A Probabilistic Interpretation of Self-Paced Learning with Applications to Reinforcement Learning,"Pascal Klink, Hany Abdulsamad, Boris Belousov, Carlo D'Eramo, Jan Peters, Joni Pajarinen","(182):1−52, 2021.  (Machine Learning Open Source Software Paper)",https://jmlr.org/papers/v22/21-0112.html,https://jmlr.org/papers/volume22/21-0112/21-0112.pdf,https://jmlr.org/papers/v22/21-0112.bib,https://github.com/psclklnk/pspl-code,,,,"Across machine learning, the use of curricula has shown strong empirical potential to improve learning from data by avoiding local optima of training objectives. For reinforcement learning (RL), curricula are especially interesting, as the underlying optimization has a strong tendency to get stuck in local optima due to the exploration-exploitation trade-off. Recently, a number of approaches for an automatic generation of curricula for RL have been shown to increase performance while requiring less expert knowledge compared to manually designed curricula. However, these approaches are seldomly investigated from a theoretical perspective, preventing a deeper understanding of their mechanics. In this paper, we present an approach for automated curriculum generation in RL with a clear theoretical underpinning. More precisely, we formalize the well-known self-paced learning paradigm as inducing a distribution over training tasks, which trades off between task complexity and the objective to match a desired task distribution. Experiments show that training on this induced distribution helps to avoid poor local optima across RL algorithms in different tasks with uninformative rewards and challenging exploration requirements.",Algorithm; Complexity; LeSS; Machine Learning; Mechanics; Objective-C; Reinforcement Learning; Trade; Training,Reinforcement
183,Benchmarking Unsupervised Object Representations for Video Sequences,"Marissa A. Weis, Kashyap Chitta, Yash Sharma, Wieland Brendel, Matthias Bethge, Andreas Geiger, Alexander S. Ecker","(183):1−61, 2021.",https://jmlr.org/papers/v22/21-0199.html,https://jmlr.org/papers/volume22/21-0199/21-0199.pdf,https://jmlr.org/papers/v22/21-0199.bib,https://eckerlab.org/code/weis2021/,,,,"Perceiving the world in terms of objects and tracking them through time is a crucial prerequisite for reasoning and scene understanding. Recently, several methods have been proposed for unsupervised learning of object-centric representations. However, since these models were evaluated on different downstream tasks, it remains unclear how they compare in terms of basic perceptual abilities such as detection, figure-ground segmentation and tracking of objects.  To close this gap, we design a benchmark with four data sets of varying complexity and seven additional test sets featuring challenging tracking scenarios relevant for natural videos. Using this benchmark, we compare the perceptual abilities of four object-centric approaches: ViMON, a video-extension of MONet, based on recurrent spatial attention, OP3, which exploits clustering via spatial mixture models, as well as TBA and SCALOR, which use explicit factorization via spatial transformers. Our results suggest that the architectures with unconstrained latent representations learn more powerful representations in terms of object detection, segmentation and tracking than the spatial transformer based architectures. We also observe that none of the methods are able to gracefully handle the most challenging tracking scenarios despite their synthetic nature, suggesting that our benchmark may provide fruitful guidance towards learning more robust object-centric video representations.",Architecture; Benchmarking; Clustering; Complexity; Exploit; Object Detection; Reasoning; Scalr; Sequence; Supervised Learning; Transformer; Unsupervised Learning; Video; Web Design,
184,mlr3pipelines - Flexible Machine Learning Pipelines in R,"Martin Binder, Florian Pfisterer, Michel Lang, Lennart Schneider, Lars Kotthoff, Bernd Bischl","(184):1−7, 2021.  (Machine Learning Open Source Software Paper)",https://jmlr.org/papers/v22/21-0281.html,https://jmlr.org/papers/volume22/21-0281/21-0281.pdf,https://jmlr.org/papers/v22/21-0281.bib,https://github.com/mlr-org/mlr3pipelines,,,,"Recent years have seen a proliferation of ML frameworks. Such systems make ML accessible to non-experts, especially when combined with powerful parameter tuning and AutoML techniques. Modern, applied ML extends beyond direct learning on clean data, however, and needs an expressive language for the construction of complex ML workflows beyond simple pre- and post-processing. We present mlr3pipelines, an R framework which can be used to define linear and complex non-linear ML workflows as directed acyclic graphs. The framework is part of the mlr3 ecosystem, leveraging convenient resampling, benchmarking, and tuning components.",Benchmarking; Construction; Graph; Machine Learning; Processing; R,R programming
185,Mode-wise Tensor Decompositions: Multi-dimensional Generalizations of CUR Decompositions,"HanQin Cai, Keaton Hamm, Longxiu Huang, Deanna Needell","(185):1−36, 2021.",https://jmlr.org/papers/v22/21-0287.html,https://jmlr.org/papers/volume22/21-0287/21-0287.pdf,https://jmlr.org/papers/v22/21-0287.bib,https://github.com/caesarcai/Modewise_Tensor_Decomp,,,,"Low rank tensor approximation is a fundamental tool in modern machine learning and data science. In this paper, we study the characterization, perturbation analysis, and an efficient sampling strategy for two primary tensor CUR approximations, namely Chidori and Fiber CUR. We characterize exact tensor CUR decompositions for low multilinear rank tensors. We also present theoretical error bounds of the tensor CUR approximations when (adversarial or Gaussian) noise appears. Moreover, we show that low cost uniform sampling is sufficient for tensor CUR approximations if the tensor has an incoherent structure. Empirical performance evaluations, with both synthetic and real-world datasets, establish the speed advantage of the tensor CUR approximations over other state-of-the-art low multilinear rank tensor approximations.",Analysis; Approximation; Data Science; Dataset; Machine Learning; Sampling,
